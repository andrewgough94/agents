Logging to /tmp/openai-2018-05-09-11-32-38-276102
---------------------------------
| avg reward         | 0.703    |
| explained_variance | -304     |
| fps                | 30       |
| learning rate      | 0.001    |
| nupdates           | 1        |
| policy_entropy     | 2.2      |
| total_timesteps    | 80       |
| value_loss         | 0.0528   |
---------------------------------
---------------------------------
| avg reward         | 1.44     |
| explained_variance | -0.108   |
| fps                | 1219     |
| learning rate      | 0.001    |
| nupdates           | 100      |
| policy_entropy     | 2.2      |
| total_timesteps    | 8000     |
| value_loss         | 0.0461   |
---------------------------------
---------------------------------
| avg reward         | 2.57     |
| explained_variance | -0.0351  |
| fps                | 1527     |
| learning rate      | 0.001    |
| nupdates           | 200      |
| policy_entropy     | 2.2      |
| total_timesteps    | 16000    |
| value_loss         | 0.251    |
---------------------------------
---------------------------------
| avg reward         | 3.3      |
| explained_variance | -0.0189  |
| fps                | 1667     |
| learning rate      | 0.001    |
| nupdates           | 300      |
| policy_entropy     | 2.2      |
| total_timesteps    | 24000    |
| value_loss         | 0.139    |
---------------------------------
---------------------------------
| avg reward         | 3.64     |
| explained_variance | 0.0148   |
| fps                | 1739     |
| learning rate      | 0.001    |
| nupdates           | 400      |
| policy_entropy     | 2.19     |
| total_timesteps    | 32000    |
| value_loss         | 0.131    |
---------------------------------
---------------------------------
| avg reward         | 3.35     |
| explained_variance | 0.0562   |
| fps                | 1798     |
| learning rate      | 0.001    |
| nupdates           | 500      |
| policy_entropy     | 2.17     |
| total_timesteps    | 40000    |
| value_loss         | 0.432    |
---------------------------------
---------------------------------
| avg reward         | 2.36     |
| explained_variance | -0.0159  |
| fps                | 1836     |
| learning rate      | 0.001    |
| nupdates           | 600      |
| policy_entropy     | 2.12     |
| total_timesteps    | 48000    |
| value_loss         | 0.0648   |
---------------------------------
---------------------------------
| avg reward         | 1.99     |
| explained_variance | 0.0853   |
| fps                | 1857     |
| learning rate      | 0.001    |
| nupdates           | 700      |
| policy_entropy     | 2.04     |
| total_timesteps    | 56000    |
| value_loss         | 0.114    |
---------------------------------
---------------------------------
| avg reward         | 3.63     |
| explained_variance | 0.0394   |
| fps                | 1871     |
| learning rate      | 0.001    |
| nupdates           | 800      |
| policy_entropy     | 1.74     |
| total_timesteps    | 64000    |
| value_loss         | 0.0588   |
---------------------------------
---------------------------------
| avg reward         | 1.18     |
| explained_variance | 0.201    |
| fps                | 1888     |
| learning rate      | 0.001    |
| nupdates           | 900      |
| policy_entropy     | 1.98     |
| total_timesteps    | 72000    |
| value_loss         | 0.0689   |
---------------------------------
---------------------------------
| avg reward         | 1.98     |
| explained_variance | 0.0936   |
| fps                | 1898     |
| learning rate      | 0.001    |
| nupdates           | 1000     |
| policy_entropy     | 1.92     |
| total_timesteps    | 80000    |
| value_loss         | 0.215    |
---------------------------------
---------------------------------
| avg reward         | 1.81     |
| explained_variance | 0.351    |
| fps                | 1906     |
| learning rate      | 0.001    |
| nupdates           | 1100     |
| policy_entropy     | 0.0743   |
| total_timesteps    | 88000    |
| value_loss         | 0.0452   |
---------------------------------
---------------------------------
| avg reward         | 6.58     |
| explained_variance | 0.0442   |
| fps                | 1916     |
| learning rate      | 0.001    |
| nupdates           | 1200     |
| policy_entropy     | 0.000115 |
| total_timesteps    | 96000    |
| value_loss         | 2.25     |
---------------------------------
---------------------------------
| avg reward         | -2.88    |
| explained_variance | 0.281    |
| fps                | 1921     |
| learning rate      | 0.001    |
| nupdates           | 1300     |
| policy_entropy     | 1.13e-18 |
| total_timesteps    | 104000   |
| value_loss         | 0.107    |
---------------------------------
---------------------------------
| avg reward         | 10.1     |
| explained_variance | -0.101   |
| fps                | 1929     |
| learning rate      | 0.001    |
| nupdates           | 1400     |
| policy_entropy     | 3.26e-09 |
| total_timesteps    | 112000   |
| value_loss         | 1.74     |
---------------------------------
---------------------------------
| avg reward         | 0.0144   |
| explained_variance | 0.672    |
| fps                | 1934     |
| learning rate      | 0.001    |
| nupdates           | 1500     |
| policy_entropy     | 5.71e-20 |
| total_timesteps    | 120000   |
| value_loss         | 0.0609   |
---------------------------------
---------------------------------
| avg reward         | 7.83     |
| explained_variance | 0.605    |
| fps                | 1942     |
| learning rate      | 0.001    |
| nupdates           | 1600     |
| policy_entropy     | 1.05e-21 |
| total_timesteps    | 128000   |
| value_loss         | 0.082    |
---------------------------------
---------------------------------
| avg reward         | 22.2     |
| explained_variance | -1.22    |
| fps                | 1945     |
| learning rate      | 0.001    |
| nupdates           | 1700     |
| policy_entropy     | 2.12e-15 |
| total_timesteps    | 136000   |
| value_loss         | 0.559    |
---------------------------------
---------------------------------
| avg reward         | -28.9    |
| explained_variance | -0.0189  |
| fps                | 1948     |
| learning rate      | 0.001    |
| nupdates           | 1800     |
| policy_entropy     | 0        |
| total_timesteps    | 144000   |
| value_loss         | 33.2     |
---------------------------------
---------------------------------
| avg reward         | 17.6     |
| explained_variance | 0.0337   |
| fps                | 1953     |
| learning rate      | 0.001    |
| nupdates           | 1900     |
| policy_entropy     | 0.000661 |
| total_timesteps    | 152000   |
| value_loss         | 20       |
---------------------------------
---------------------------------
| avg reward         | 12.1     |
| explained_variance | 0.42     |
| fps                | 1957     |
| learning rate      | 0.001    |
| nupdates           | 2000     |
| policy_entropy     | 4.72e-28 |
| total_timesteps    | 160000   |
| value_loss         | 0.217    |
---------------------------------
---------------------------------
| avg reward         | 5.76     |
| explained_variance | -0.913   |
| fps                | 1959     |
| learning rate      | 0.001    |
| nupdates           | 2100     |
| policy_entropy     | 0.00473  |
| total_timesteps    | 168000   |
| value_loss         | 0.792    |
---------------------------------
---------------------------------
| avg reward         | 18.2     |
| explained_variance | 0.489    |
| fps                | 1961     |
| learning rate      | 0.001    |
| nupdates           | 2200     |
| policy_entropy     | 0        |
| total_timesteps    | 176000   |
| value_loss         | 0.241    |
---------------------------------
---------------------------------
| avg reward         | -26.2    |
| explained_variance | 0.563    |
| fps                | 1963     |
| learning rate      | 0.001    |
| nupdates           | 2300     |
| policy_entropy     | 0        |
| total_timesteps    | 184000   |
| value_loss         | 0.745    |
---------------------------------
---------------------------------
| avg reward         | 28.9     |
| explained_variance | -3.94    |
| fps                | 1964     |
| learning rate      | 0.001    |
| nupdates           | 2400     |
| policy_entropy     | 1.3e-09  |
| total_timesteps    | 192000   |
| value_loss         | 2.15     |
---------------------------------
---------------------------------
| avg reward         | -13.9    |
| explained_variance | 0.563    |
| fps                | 1962     |
| learning rate      | 0.001    |
| nupdates           | 2500     |
| policy_entropy     | 0        |
| total_timesteps    | 200000   |
| value_loss         | 0.236    |
---------------------------------
---------------------------------
| avg reward         | -22.8    |
| explained_variance | 0.471    |
| fps                | 1965     |
| learning rate      | 0.001    |
| nupdates           | 2600     |
| policy_entropy     | 0        |
| total_timesteps    | 208000   |
| value_loss         | 0.523    |
---------------------------------
---------------------------------
| avg reward         | 24.6     |
| explained_variance | -7.85    |
| fps                | 1965     |
| learning rate      | 0.001    |
| nupdates           | 2700     |
| policy_entropy     | 0.00946  |
| total_timesteps    | 216000   |
| value_loss         | 5.39     |
---------------------------------
---------------------------------
| avg reward         | 16.4     |
| explained_variance | 0.746    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 2800     |
| policy_entropy     | 0        |
| total_timesteps    | 224000   |
| value_loss         | 0.165    |
---------------------------------
---------------------------------
| avg reward         | 52       |
| explained_variance | -49.2    |
| fps                | 1970     |
| learning rate      | 0.001    |
| nupdates           | 2900     |
| policy_entropy     | 0.0191   |
| total_timesteps    | 232000   |
| value_loss         | 42.1     |
---------------------------------
---------------------------------
| avg reward         | 20.4     |
| explained_variance | 0.316    |
| fps                | 1970     |
| learning rate      | 0.001    |
| nupdates           | 3000     |
| policy_entropy     | 0.013    |
| total_timesteps    | 240000   |
| value_loss         | 11.2     |
---------------------------------
---------------------------------
| avg reward         | -7.55    |
| explained_variance | 0.191    |
| fps                | 1971     |
| learning rate      | 0.001    |
| nupdates           | 3100     |
| policy_entropy     | 0.014    |
| total_timesteps    | 248000   |
| value_loss         | 2.13     |
---------------------------------
---------------------------------
| avg reward         | -16      |
| explained_variance | 0.562    |
| fps                | 1972     |
| learning rate      | 0.001    |
| nupdates           | 3200     |
| policy_entropy     | 0        |
| total_timesteps    | 256000   |
| value_loss         | 0.329    |
---------------------------------
---------------------------------
| avg reward         | -22.7    |
| explained_variance | -2.9     |
| fps                | 1973     |
| learning rate      | 0.001    |
| nupdates           | 3300     |
| policy_entropy     | 0.0289   |
| total_timesteps    | 264000   |
| value_loss         | 14.5     |
---------------------------------
---------------------------------
| avg reward         | 23       |
| explained_variance | -0.496   |
| fps                | 1974     |
| learning rate      | 0.001    |
| nupdates           | 3400     |
| policy_entropy     | 0.0314   |
| total_timesteps    | 272000   |
| value_loss         | 34.1     |
---------------------------------
---------------------------------
| avg reward         | 26       |
| explained_variance | -2.78    |
| fps                | 1974     |
| learning rate      | 0.001    |
| nupdates           | 3500     |
| policy_entropy     | 0.0621   |
| total_timesteps    | 280000   |
| value_loss         | 34.2     |
---------------------------------
---------------------------------
| avg reward         | -28.5    |
| explained_variance | -18.4    |
| fps                | 1977     |
| learning rate      | 0.001    |
| nupdates           | 3600     |
| policy_entropy     | 1.73e-16 |
| total_timesteps    | 288000   |
| value_loss         | 4.83     |
---------------------------------
---------------------------------
| avg reward         | -60.4    |
| explained_variance | -29      |
| fps                | 1979     |
| learning rate      | 0.001    |
| nupdates           | 3700     |
| policy_entropy     | 1.43e-12 |
| total_timesteps    | 296000   |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| avg reward         | -31      |
| explained_variance | -16.4    |
| fps                | 1979     |
| learning rate      | 0.001    |
| nupdates           | 3800     |
| policy_entropy     | 4.37e-06 |
| total_timesteps    | 304000   |
| value_loss         | 6.38     |
---------------------------------
---------------------------------
| avg reward         | 45.8     |
| explained_variance | 0.167    |
| fps                | 1971     |
| learning rate      | 0.001    |
| nupdates           | 3900     |
| policy_entropy     | 2.5e-14  |
| total_timesteps    | 312000   |
| value_loss         | 1.79     |
---------------------------------
---------------------------------
| avg reward         | -20.8    |
| explained_variance | -2.83    |
| fps                | 1969     |
| learning rate      | 0.001    |
| nupdates           | 4000     |
| policy_entropy     | 0.0308   |
| total_timesteps    | 320000   |
| value_loss         | 11.7     |
---------------------------------
---------------------------------
| avg reward         | -58.3    |
| explained_variance | -24.9    |
| fps                | 1966     |
| learning rate      | 0.001    |
| nupdates           | 4100     |
| policy_entropy     | 1.06e-11 |
| total_timesteps    | 328000   |
| value_loss         | 20.1     |
---------------------------------
---------------------------------
| avg reward         | 19.9     |
| explained_variance | 0.377    |
| fps                | 1969     |
| learning rate      | 0.001    |
| nupdates           | 4200     |
| policy_entropy     | 0.0188   |
| total_timesteps    | 336000   |
| value_loss         | 9.8      |
---------------------------------
---------------------------------
| avg reward         | 59.5     |
| explained_variance | -102     |
| fps                | 1970     |
| learning rate      | 0.001    |
| nupdates           | 4300     |
| policy_entropy     | 0.0635   |
| total_timesteps    | 344000   |
| value_loss         | 124      |
---------------------------------
---------------------------------
| avg reward         | -41      |
| explained_variance | 0.272    |
| fps                | 1970     |
| learning rate      | 0.001    |
| nupdates           | 4400     |
| policy_entropy     | 0        |
| total_timesteps    | 352000   |
| value_loss         | 1.59     |
---------------------------------
---------------------------------
| avg reward         | -32.8    |
| explained_variance | 0.601    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 4500     |
| policy_entropy     | 0        |
| total_timesteps    | 360000   |
| value_loss         | 0.753    |
---------------------------------
---------------------------------
| avg reward         | -46.3    |
| explained_variance | 0.544    |
| fps                | 1966     |
| learning rate      | 0.001    |
| nupdates           | 4600     |
| policy_entropy     | 0        |
| total_timesteps    | 368000   |
| value_loss         | 1.59     |
---------------------------------
---------------------------------
| avg reward         | 66.2     |
| explained_variance | 0.565    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 4700     |
| policy_entropy     | 0        |
| total_timesteps    | 376000   |
| value_loss         | 2.82     |
---------------------------------
---------------------------------
| avg reward         | 66       |
| explained_variance | 0.672    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 4800     |
| policy_entropy     | 0        |
| total_timesteps    | 384000   |
| value_loss         | 2.54     |
---------------------------------
---------------------------------
| avg reward         | 3.05     |
| explained_variance | 0.736    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 4900     |
| policy_entropy     | 0.000251 |
| total_timesteps    | 392000   |
| value_loss         | 0.32     |
---------------------------------
---------------------------------
| avg reward         | 12.1     |
| explained_variance | -1.27    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 5000     |
| policy_entropy     | 0.0505   |
| total_timesteps    | 400000   |
| value_loss         | 4.92     |
---------------------------------
---------------------------------
| avg reward         | -23.8    |
| explained_variance | -24.9    |
| fps                | 1968     |
| learning rate      | 0.001    |
| nupdates           | 5100     |
| policy_entropy     | 0.0318   |
| total_timesteps    | 408000   |
| value_loss         | 7.37     |
---------------------------------
---------------------------------
| avg reward         | 32.9     |
| explained_variance | 0.496    |
| fps                | 1967     |
| learning rate      | 0.001    |
| nupdates           | 5200     |
| policy_entropy     | 0        |
| total_timesteps    | 416000   |
| value_loss         | 0.82     |
---------------------------------
---------------------------------
| avg reward         | 16.9     |
| explained_variance | 0.232    |
| fps                | 1968     |
| learning rate      | 0.001    |
| nupdates           | 5300     |
| policy_entropy     | 0        |
| total_timesteps    | 424000   |
| value_loss         | 9.36     |
---------------------------------
---------------------------------
| avg reward         | -64      |
| explained_variance | 0.415    |
| fps                | 1969     |
| learning rate      | 0.001    |
| nupdates           | 5400     |
| policy_entropy     | 0        |
| total_timesteps    | 432000   |
| value_loss         | 2.8      |
---------------------------------
---------------------------------
| avg reward         | 7.08     |
| explained_variance | -0.11    |
| fps                | 1970     |
| learning rate      | 0.001    |
| nupdates           | 5500     |
| policy_entropy     | 0.0538   |
| total_timesteps    | 440000   |
| value_loss         | 1.24     |
---------------------------------
---------------------------------
| avg reward         | 31.8     |
| explained_variance | -3.29    |
| fps                | 1972     |
| learning rate      | 0.001    |
| nupdates           | 5600     |
| policy_entropy     | 0.0814   |
| total_timesteps    | 448000   |
| value_loss         | 59.5     |
---------------------------------
---------------------------------
| avg reward         | -31.6    |
| explained_variance | 0.337    |
| fps                | 1972     |
| learning rate      | 0.001    |
| nupdates           | 5700     |
| policy_entropy     | 0        |
| total_timesteps    | 456000   |
| value_loss         | 0.871    |
---------------------------------
---------------------------------
| avg reward         | 87.2     |
| explained_variance | -2.62    |
| fps                | 1973     |
| learning rate      | 0.001    |
| nupdates           | 5800     |
| policy_entropy     | 0.0412   |
| total_timesteps    | 464000   |
| value_loss         | 186      |
---------------------------------
---------------------------------
| avg reward         | -25.4    |
| explained_variance | 0.839    |
| fps                | 1974     |
| learning rate      | 0.001    |
| nupdates           | 5900     |
| policy_entropy     | 0        |
| total_timesteps    | 472000   |
| value_loss         | 0.636    |
---------------------------------
---------------------------------
| avg reward         | 77.4     |
| explained_variance | 0.593    |
| fps                | 1975     |
| learning rate      | 0.001    |
| nupdates           | 6000     |
| policy_entropy     | 1.46e-13 |
| total_timesteps    | 480000   |
| value_loss         | 3.83     |
---------------------------------
---------------------------------
| avg reward         | -68.9    |
| explained_variance | -0.817   |
| fps                | 1974     |
| learning rate      | 0.001    |
| nupdates           | 6100     |
| policy_entropy     | 0.0969   |
| total_timesteps    | 488000   |
| value_loss         | 489      |
---------------------------------
---------------------------------
| avg reward         | 60.7     |
| explained_variance | -0.654   |
| fps                | 1975     |
| learning rate      | 0.001    |
| nupdates           | 6200     |
| policy_entropy     | 0.113    |
| total_timesteps    | 496000   |
| value_loss         | 315      |
---------------------------------
---------------------------------
| avg reward         | 33       |
| explained_variance | 0.372    |
| fps                | 1976     |
| learning rate      | 0.001    |
| nupdates           | 6300     |
| policy_entropy     | 0.0214   |
| total_timesteps    | 504000   |
| value_loss         | 27.1     |
---------------------------------
---------------------------------
| avg reward         | 46       |
| explained_variance | 0.19     |
| fps                | 1978     |
| learning rate      | 0.001    |
| nupdates           | 6400     |
| policy_entropy     | 0.0359   |
| total_timesteps    | 512000   |
| value_loss         | 59       |
---------------------------------
---------------------------------
| avg reward         | 31.4     |
| explained_variance | 0.525    |
| fps                | 1979     |
| learning rate      | 0.001    |
| nupdates           | 6500     |
| policy_entropy     | 0.0351   |
| total_timesteps    | 520000   |
| value_loss         | 17.9     |
---------------------------------
---------------------------------
| avg reward         | 0.403    |
| explained_variance | 0.81     |
| fps                | 1980     |
| learning rate      | 0.001    |
| nupdates           | 6600     |
| policy_entropy     | 0        |
| total_timesteps    | 528000   |
| value_loss         | 0.26     |
---------------------------------
---------------------------------
| avg reward         | -127     |
| explained_variance | 0.167    |
| fps                | 1981     |
| learning rate      | 0.001    |
| nupdates           | 6700     |
| policy_entropy     | 0        |
| total_timesteps    | 536000   |
| value_loss         | 10       |
---------------------------------
---------------------------------
| avg reward         | 22.6     |
| explained_variance | 0.307    |
| fps                | 1981     |
| learning rate      | 0.001    |
| nupdates           | 6800     |
| policy_entropy     | 0.0218   |
| total_timesteps    | 544000   |
| value_loss         | 31.4     |
---------------------------------
---------------------------------
| avg reward         | 101      |
| explained_variance | -0.275   |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 6900     |
| policy_entropy     | 0.0743   |
| total_timesteps    | 552000   |
| value_loss         | 433      |
---------------------------------
---------------------------------
| avg reward         | -27.6    |
| explained_variance | 0.702    |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 7000     |
| policy_entropy     | 0        |
| total_timesteps    | 560000   |
| value_loss         | 1.19     |
---------------------------------
---------------------------------
| avg reward         | 137      |
| explained_variance | -1.5     |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 7100     |
| policy_entropy     | 0.0379   |
| total_timesteps    | 568000   |
| value_loss         | 620      |
---------------------------------
---------------------------------
| avg reward         | -4.47    |
| explained_variance | 0.922    |
| fps                | 1984     |
| learning rate      | 0.001    |
| nupdates           | 7200     |
| policy_entropy     | 0        |
| total_timesteps    | 576000   |
| value_loss         | 0.261    |
---------------------------------
---------------------------------
| avg reward         | 105      |
| explained_variance | 0.558    |
| fps                | 1983     |
| learning rate      | 0.001    |
| nupdates           | 7300     |
| policy_entropy     | 0        |
| total_timesteps    | 584000   |
| value_loss         | 7.26     |
---------------------------------
---------------------------------
| avg reward         | 136      |
| explained_variance | 0.413    |
| fps                | 1983     |
| learning rate      | 0.001    |
| nupdates           | 7400     |
| policy_entropy     | 0.0355   |
| total_timesteps    | 592000   |
| value_loss         | 404      |
---------------------------------
---------------------------------
| avg reward         | -73.5    |
| explained_variance | -54.3    |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 7500     |
| policy_entropy     | 0.0333   |
| total_timesteps    | 600000   |
| value_loss         | 102      |
---------------------------------
---------------------------------
| avg reward         | 73.1     |
| explained_variance | 0.765    |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 7600     |
| policy_entropy     | 0        |
| total_timesteps    | 608000   |
| value_loss         | 3.71     |
---------------------------------
---------------------------------
| avg reward         | 76.4     |
| explained_variance | 0.763    |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 7700     |
| policy_entropy     | 0        |
| total_timesteps    | 616000   |
| value_loss         | 3.75     |
---------------------------------
---------------------------------
| avg reward         | 21.3     |
| explained_variance | -0.225   |
| fps                | 1982     |
| learning rate      | 0.001    |
| nupdates           | 7800     |
| policy_entropy     | 0.168    |
| total_timesteps    | 624000   |
| value_loss         | 79.2     |
---------------------------------
---------------------------------
| avg reward         | -121     |
| explained_variance | 0.589    |
| fps                | 1983     |
| learning rate      | 0.001    |
| nupdates           | 7900     |
| policy_entropy     | 0        |
| total_timesteps    | 632000   |
| value_loss         | 9.08     |
---------------------------------
---------------------------------
| avg reward         | 84.1     |
| explained_variance | -1.63    |
| fps                | 1984     |
| learning rate      | 0.001    |
| nupdates           | 8000     |
| policy_entropy     | 0.0349   |
| total_timesteps    | 640000   |
| value_loss         | 257      |
---------------------------------
---------------------------------
| avg reward         | 94       |
| explained_variance | 0.151    |
| fps                | 1985     |
| learning rate      | 0.001    |
| nupdates           | 8100     |
| policy_entropy     | 0        |
| total_timesteps    | 648000   |
| value_loss         | 299      |
---------------------------------
---------------------------------
| avg reward         | 139      |
| explained_variance | 0.701    |
| fps                | 1984     |
| learning rate      | 0.001    |
| nupdates           | 8200     |
| policy_entropy     | 0        |
| total_timesteps    | 656000   |
| value_loss         | 12.1     |
---------------------------------
---------------------------------
| avg reward         | 113      |
| explained_variance | 0.382    |
| fps                | 1984     |
| learning rate      | 0.001    |
| nupdates           | 8300     |
| policy_entropy     | 0        |
| total_timesteps    | 664000   |
| value_loss         | 9.71     |
---------------------------------
---------------------------------
| avg reward         | 111      |
| explained_variance | 0.821    |
| fps                | 1984     |
| learning rate      | 0.001    |
| nupdates           | 8400     |
| policy_entropy     | 0        |
| total_timesteps    | 672000   |
| value_loss         | 7.25     |
---------------------------------
---------------------------------
| avg reward         | 54.1     |
| explained_variance | -1.72    |
| fps                | 1985     |
| learning rate      | 0.001    |
| nupdates           | 8500     |
| policy_entropy     | 0.0327   |
| total_timesteps    | 680000   |
| value_loss         | 77.6     |
---------------------------------
---------------------------------
| avg reward         | -125     |
| explained_variance | 0.514    |
| fps                | 1985     |
| learning rate      | 0.001    |
| nupdates           | 8600     |
| policy_entropy     | 0        |
| total_timesteps    | 688000   |
| value_loss         | 10.1     |
---------------------------------
---------------------------------
| avg reward         | -194     |
| explained_variance | -0.609   |
| fps                | 1986     |
| learning rate      | 0.001    |
| nupdates           | 8700     |
| policy_entropy     | 0.0582   |
| total_timesteps    | 696000   |
| value_loss         | 4.47e+03 |
---------------------------------
---------------------------------
| avg reward         | -19.6    |
| explained_variance | 0.933    |
| fps                | 1986     |
| learning rate      | 0.001    |
| nupdates           | 8800     |
| policy_entropy     | 0        |
| total_timesteps    | 704000   |
| value_loss         | 0.923    |
---------------------------------
---------------------------------
| avg reward         | 41.4     |
| explained_variance | 0.493    |
| fps                | 1986     |
| learning rate      | 0.001    |
| nupdates           | 8900     |
| policy_entropy     | 0.0172   |
| total_timesteps    | 712000   |
| value_loss         | 33.8     |
---------------------------------
---------------------------------
| avg reward         | -82.9    |
| explained_variance | -1.03    |
| fps                | 1985     |
| learning rate      | 0.001    |
| nupdates           | 9000     |
| policy_entropy     | 2.73e-38 |
| total_timesteps    | 720000   |
| value_loss         | 199      |
---------------------------------
---------------------------------
| avg reward         | 166      |
| explained_variance | 0.282    |
| fps                | 1986     |
| learning rate      | 0.001    |
| nupdates           | 9100     |
| policy_entropy     | 0.0176   |
| total_timesteps    | 728000   |
| value_loss         | 749      |
---------------------------------
---------------------------------
| avg reward         | -308     |
| explained_variance | -17.2    |
| fps                | 1986     |
| learning rate      | 0.001    |
| nupdates           | 9200     |
| policy_entropy     | 0        |
| total_timesteps    | 736000   |
| value_loss         | 325      |
---------------------------------
---------------------------------
| avg reward         | 294      |
| explained_variance | 0.21     |
| fps                | 1986     |
| learning rate      | 0.001    |
| nupdates           | 9300     |
| policy_entropy     | 0.0171   |
| total_timesteps    | 744000   |
| value_loss         | 2.6e+03  |
---------------------------------
---------------------------------
| avg reward         | 108      |
| explained_variance | 0.87     |
| fps                | 1987     |
| learning rate      | 0.001    |
| nupdates           | 9400     |
| policy_entropy     | 0        |
| total_timesteps    | 752000   |
| value_loss         | 7.58     |
---------------------------------
---------------------------------
| avg reward         | 196      |
| explained_variance | 0.831    |
| fps                | 1987     |
| learning rate      | 0.001    |
| nupdates           | 9500     |
| policy_entropy     | 0        |
| total_timesteps    | 760000   |
| value_loss         | 22.3     |
---------------------------------
---------------------------------
| avg reward         | -182     |
| explained_variance | 0.534    |
| fps                | 1987     |
| learning rate      | 0.001    |
| nupdates           | 9600     |
| policy_entropy     | 0        |
| total_timesteps    | 768000   |
| value_loss         | 22.1     |
---------------------------------
---------------------------------
| avg reward         | -288     |
| explained_variance | -2.78    |
| fps                | 1988     |
| learning rate      | 0.001    |
| nupdates           | 9700     |
| policy_entropy     | 0.0522   |
| total_timesteps    | 776000   |
| value_loss         | 4.07e+03 |
---------------------------------
---------------------------------
| avg reward         | -173     |
| explained_variance | -51      |
| fps                | 1988     |
| learning rate      | 0.001    |
| nupdates           | 9800     |
| policy_entropy     | 0.0107   |
| total_timesteps    | 784000   |
| value_loss         | 329      |
---------------------------------
---------------------------------
| avg reward         | 199      |
| explained_variance | 0.13     |
| fps                | 1989     |
| learning rate      | 0.001    |
| nupdates           | 9900     |
| policy_entropy     | 0.0156   |
| total_timesteps    | 792000   |
| value_loss         | 2.97e+03 |
---------------------------------
---------------------------------
| avg reward         | 129      |
| explained_variance | -0.263   |
| fps                | 1989     |
| learning rate      | 0.001    |
| nupdates           | 10000    |
| policy_entropy     | 0.0513   |
| total_timesteps    | 800000   |
| value_loss         | 1.82e+03 |
---------------------------------
---------------------------------
| avg reward         | 62.3     |
| explained_variance | 0.751    |
| fps                | 1989     |
| learning rate      | 0.001    |
| nupdates           | 10100    |
| policy_entropy     | 0        |
| total_timesteps    | 808000   |
| value_loss         | 3.48     |
---------------------------------
---------------------------------
| avg reward         | -25.3    |
| explained_variance | -0.449   |
| fps                | 1989     |
| learning rate      | 0.001    |
| nupdates           | 10200    |
| policy_entropy     | 0.0291   |
| total_timesteps    | 816000   |
| value_loss         | 15.8     |
---------------------------------
---------------------------------
| avg reward         | -76.1    |
| explained_variance | -1.69    |
| fps                | 1990     |
| learning rate      | 0.001    |
| nupdates           | 10300    |
| policy_entropy     | 0.0248   |
| total_timesteps    | 824000   |
| value_loss         | 232      |
---------------------------------
---------------------------------
| avg reward         | 84.7     |
| explained_variance | -0.543   |
| fps                | 1990     |
| learning rate      | 0.001    |
| nupdates           | 10400    |
| policy_entropy     | 0.0655   |
| total_timesteps    | 832000   |
| value_loss         | 1.02e+03 |
---------------------------------
---------------------------------
| avg reward         | -113     |
| explained_variance | 0.833    |
| fps                | 1990     |
| learning rate      | 0.001    |
| nupdates           | 10500    |
| policy_entropy     | 0        |
| total_timesteps    | 840000   |
| value_loss         | 7.2      |
---------------------------------
---------------------------------
| avg reward         | -162     |
| explained_variance | 0.189    |
| fps                | 1990     |
| learning rate      | 0.001    |
| nupdates           | 10600    |
| policy_entropy     | 0.0434   |
| total_timesteps    | 848000   |
| value_loss         | 1.65e+03 |
---------------------------------
---------------------------------
| avg reward         | 131      |
| explained_variance | 0.0746   |
| fps                | 1990     |
| learning rate      | 0.001    |
| nupdates           | 10700    |
| policy_entropy     | 0        |
| total_timesteps    | 856000   |
| value_loss         | 622      |
---------------------------------
---------------------------------
| avg reward         | 199      |
| explained_variance | 0.257    |
| fps                | 1991     |
| learning rate      | 0.001    |
| nupdates           | 10800    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 864000   |
| value_loss         | 1.14e+03 |
---------------------------------
---------------------------------
| avg reward         | 121      |
| explained_variance | -5.75    |
| fps                | 1991     |
| learning rate      | 0.001    |
| nupdates           | 10900    |
| policy_entropy     | 3.92e-28 |
| total_timesteps    | 872000   |
| value_loss         | 95.2     |
---------------------------------
---------------------------------
| avg reward         | 172      |
| explained_variance | 0.733    |
| fps                | 1991     |
| learning rate      | 0.001    |
| nupdates           | 11000    |
| policy_entropy     | 0        |
| total_timesteps    | 880000   |
| value_loss         | 17.7     |
---------------------------------
---------------------------------
| avg reward         | -91.3    |
| explained_variance | -16.8    |
| fps                | 1991     |
| learning rate      | 0.001    |
| nupdates           | 11100    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 888000   |
| value_loss         | 97.7     |
---------------------------------
---------------------------------
| avg reward         | 133      |
| explained_variance | 0.9      |
| fps                | 1991     |
| learning rate      | 0.001    |
| nupdates           | 11200    |
| policy_entropy     | 0        |
| total_timesteps    | 896000   |
| value_loss         | 9        |
---------------------------------
---------------------------------
| avg reward         | -65.2    |
| explained_variance | -1.8     |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 11300    |
| policy_entropy     | 0.0279   |
| total_timesteps    | 904000   |
| value_loss         | 103      |
---------------------------------
---------------------------------
| avg reward         | 58       |
| explained_variance | -1.06    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 11400    |
| policy_entropy     | 0        |
| total_timesteps    | 912000   |
| value_loss         | 18.4     |
---------------------------------
---------------------------------
| avg reward         | -164     |
| explained_variance | 0.671    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 11500    |
| policy_entropy     | 0        |
| total_timesteps    | 920000   |
| value_loss         | 15.4     |
---------------------------------
---------------------------------
| avg reward         | 272      |
| explained_variance | 0.648    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 11600    |
| policy_entropy     | 0        |
| total_timesteps    | 928000   |
| value_loss         | 41.1     |
---------------------------------
---------------------------------
| avg reward         | -312     |
| explained_variance | -25.7    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 11700    |
| policy_entropy     | 0        |
| total_timesteps    | 936000   |
| value_loss         | 513      |
---------------------------------
---------------------------------
| avg reward         | -23.6    |
| explained_variance | 0.658    |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 11800    |
| policy_entropy     | 0        |
| total_timesteps    | 944000   |
| value_loss         | 3.06     |
---------------------------------
---------------------------------
| avg reward         | 194      |
| explained_variance | 0.663    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 11900    |
| policy_entropy     | 0        |
| total_timesteps    | 952000   |
| value_loss         | 24.5     |
---------------------------------
---------------------------------
| avg reward         | 129      |
| explained_variance | 0.0689   |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 12000    |
| policy_entropy     | 0        |
| total_timesteps    | 960000   |
| value_loss         | 622      |
---------------------------------
---------------------------------
| avg reward         | -135     |
| explained_variance | -0.382   |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 12100    |
| policy_entropy     | 0.0439   |
| total_timesteps    | 968000   |
| value_loss         | 1.29e+03 |
---------------------------------
---------------------------------
| avg reward         | 282      |
| explained_variance | 0.625    |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 12200    |
| policy_entropy     | 0        |
| total_timesteps    | 976000   |
| value_loss         | 63       |
---------------------------------
---------------------------------
| avg reward         | 199      |
| explained_variance | 0.804    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 12300    |
| policy_entropy     | 0        |
| total_timesteps    | 984000   |
| value_loss         | 19.2     |
---------------------------------
---------------------------------
| avg reward         | 135      |
| explained_variance | -2.61    |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 12400    |
| policy_entropy     | 0.0238   |
| total_timesteps    | 992000   |
| value_loss         | 504      |
---------------------------------
---------------------------------
| avg reward         | 23.2     |
| explained_variance | 0.636    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 12500    |
| policy_entropy     | 0        |
| total_timesteps    | 1000000  |
| value_loss         | 2.53     |
---------------------------------
---------------------------------
| avg reward         | -338     |
| explained_variance | 0.274    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 12600    |
| policy_entropy     | 0        |
| total_timesteps    | 1008000  |
| value_loss         | 72.9     |
---------------------------------
---------------------------------
| avg reward         | -212     |
| explained_variance | -78.5    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 12700    |
| policy_entropy     | 0.0245   |
| total_timesteps    | 1016000  |
| value_loss         | 800      |
---------------------------------
---------------------------------
| avg reward         | 258      |
| explained_variance | 0.237    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 12800    |
| policy_entropy     | 0.0149   |
| total_timesteps    | 1024000  |
| value_loss         | 1.95e+03 |
---------------------------------
---------------------------------
| avg reward         | -284     |
| explained_variance | 0.525    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 12900    |
| policy_entropy     | 0        |
| total_timesteps    | 1032000  |
| value_loss         | 49.9     |
---------------------------------
---------------------------------
| avg reward         | -267     |
| explained_variance | 0.146    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 13000    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 1040000  |
| value_loss         | 2.3e+03  |
---------------------------------
---------------------------------
| avg reward         | 148      |
| explained_variance | 0.931    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 13100    |
| policy_entropy     | 0        |
| total_timesteps    | 1048000  |
| value_loss         | 10.2     |
---------------------------------
---------------------------------
| avg reward         | -206     |
| explained_variance | 0.661    |
| fps                | 1992     |
| learning rate      | 0.001    |
| nupdates           | 13200    |
| policy_entropy     | 0        |
| total_timesteps    | 1056000  |
| value_loss         | 25       |
---------------------------------
---------------------------------
| avg reward         | -330     |
| explained_variance | 0.205    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13300    |
| policy_entropy     | 0        |
| total_timesteps    | 1064000  |
| value_loss         | 60.8     |
---------------------------------
---------------------------------
| avg reward         | 76.7     |
| explained_variance | 0.87     |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13400    |
| policy_entropy     | 0        |
| total_timesteps    | 1072000  |
| value_loss         | 6.46     |
---------------------------------
---------------------------------
| avg reward         | -414     |
| explained_variance | 0.321    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13500    |
| policy_entropy     | 0        |
| total_timesteps    | 1080000  |
| value_loss         | 97.9     |
---------------------------------
---------------------------------
| avg reward         | 163      |
| explained_variance | -15.4    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13600    |
| policy_entropy     | 0.027    |
| total_timesteps    | 1088000  |
| value_loss         | 531      |
---------------------------------
---------------------------------
| avg reward         | 116      |
| explained_variance | 0.831    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13700    |
| policy_entropy     | 0        |
| total_timesteps    | 1096000  |
| value_loss         | 9.58     |
---------------------------------
---------------------------------
| avg reward         | -168     |
| explained_variance | 0.689    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13800    |
| policy_entropy     | 0        |
| total_timesteps    | 1104000  |
| value_loss         | 17.2     |
---------------------------------
---------------------------------
| avg reward         | 62       |
| explained_variance | 0.253    |
| fps                | 1993     |
| learning rate      | 0.001    |
| nupdates           | 13900    |
| policy_entropy     | 0.0153   |
| total_timesteps    | 1112000  |
| value_loss         | 257      |
---------------------------------
---------------------------------
| avg reward         | 163      |
| explained_variance | -17.2    |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 14000    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 1120000  |
| value_loss         | 354      |
---------------------------------
---------------------------------
| avg reward         | -124     |
| explained_variance | 0.617    |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 14100    |
| policy_entropy     | 0        |
| total_timesteps    | 1128000  |
| value_loss         | 9.69     |
---------------------------------
---------------------------------
| avg reward         | -111     |
| explained_variance | -3.09    |
| fps                | 1994     |
| learning rate      | 0.001    |
| nupdates           | 14200    |
| policy_entropy     | 0.0302   |
| total_timesteps    | 1136000  |
| value_loss         | 346      |
---------------------------------
---------------------------------
| avg reward         | -79.8    |
| explained_variance | 0.162    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 14300    |
| policy_entropy     | 0.0488   |
| total_timesteps    | 1144000  |
| value_loss         | 777      |
---------------------------------
---------------------------------
| avg reward         | 169      |
| explained_variance | -1.47    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 14400    |
| policy_entropy     | 0.0302   |
| total_timesteps    | 1152000  |
| value_loss         | 960      |
---------------------------------
---------------------------------
| avg reward         | 257      |
| explained_variance | 0.719    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 14500    |
| policy_entropy     | 0        |
| total_timesteps    | 1160000  |
| value_loss         | 44.6     |
---------------------------------
---------------------------------
| avg reward         | -64.4    |
| explained_variance | 0.103    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 14600    |
| policy_entropy     | 0.0449   |
| total_timesteps    | 1168000  |
| value_loss         | 534      |
---------------------------------
---------------------------------
| avg reward         | 205      |
| explained_variance | -14      |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 14700    |
| policy_entropy     | 0.013    |
| total_timesteps    | 1176000  |
| value_loss         | 559      |
---------------------------------
---------------------------------
| avg reward         | 149      |
| explained_variance | 0.777    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 14800    |
| policy_entropy     | 0        |
| total_timesteps    | 1184000  |
| value_loss         | 17.2     |
---------------------------------
---------------------------------
| avg reward         | -263     |
| explained_variance | 0.471    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 14900    |
| policy_entropy     | 0        |
| total_timesteps    | 1192000  |
| value_loss         | 35.3     |
---------------------------------
---------------------------------
| avg reward         | -84.9    |
| explained_variance | 0.858    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 15000    |
| policy_entropy     | 0        |
| total_timesteps    | 1200000  |
| value_loss         | 4.9      |
---------------------------------
---------------------------------
| avg reward         | 617      |
| explained_variance | -3.66    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 15100    |
| policy_entropy     | 0.0293   |
| total_timesteps    | 1208000  |
| value_loss         | 1.17e+04 |
---------------------------------
---------------------------------
| avg reward         | 389      |
| explained_variance | 0.61     |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 15200    |
| policy_entropy     | 0        |
| total_timesteps    | 1216000  |
| value_loss         | 119      |
---------------------------------
---------------------------------
| avg reward         | 91.9     |
| explained_variance | 0.947    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 15300    |
| policy_entropy     | 0        |
| total_timesteps    | 1224000  |
| value_loss         | 4.63     |
---------------------------------
---------------------------------
| avg reward         | -292     |
| explained_variance | -2.72    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 15400    |
| policy_entropy     | 0.024    |
| total_timesteps    | 1232000  |
| value_loss         | 2.13e+03 |
---------------------------------
---------------------------------
| avg reward         | -41.3    |
| explained_variance | 0.922    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 15500    |
| policy_entropy     | 0        |
| total_timesteps    | 1240000  |
| value_loss         | 5.19     |
---------------------------------
---------------------------------
| avg reward         | -138     |
| explained_variance | -1.89    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 15600    |
| policy_entropy     | 0.0209   |
| total_timesteps    | 1248000  |
| value_loss         | 444      |
---------------------------------
---------------------------------
| avg reward         | -398     |
| explained_variance | 0.589    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 15700    |
| policy_entropy     | 0        |
| total_timesteps    | 1256000  |
| value_loss         | 90.1     |
---------------------------------
---------------------------------
| avg reward         | -38.7    |
| explained_variance | -0.231   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 15800    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 1264000  |
| value_loss         | 93.6     |
---------------------------------
---------------------------------
| avg reward         | -244     |
| explained_variance | 0.481    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 15900    |
| policy_entropy     | 0        |
| total_timesteps    | 1272000  |
| value_loss         | 36.4     |
---------------------------------
---------------------------------
| avg reward         | -77.9    |
| explained_variance | -3.49    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16000    |
| policy_entropy     | 0.0194   |
| total_timesteps    | 1280000  |
| value_loss         | 122      |
---------------------------------
---------------------------------
| avg reward         | 156      |
| explained_variance | 0.929    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16100    |
| policy_entropy     | 0        |
| total_timesteps    | 1288000  |
| value_loss         | 15.1     |
---------------------------------
---------------------------------
| avg reward         | -381     |
| explained_variance | -0.469   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16200    |
| policy_entropy     | 0.00787  |
| total_timesteps    | 1296000  |
| value_loss         | 7.53e+03 |
---------------------------------
---------------------------------
| avg reward         | -87.8    |
| explained_variance | 0.168    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16300    |
| policy_entropy     | 0.0329   |
| total_timesteps    | 1304000  |
| value_loss         | 546      |
---------------------------------
---------------------------------
| avg reward         | -16.7    |
| explained_variance | -0.231   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16400    |
| policy_entropy     | 0.0669   |
| total_timesteps    | 1312000  |
| value_loss         | 42.5     |
---------------------------------
---------------------------------
| avg reward         | -114     |
| explained_variance | 0.313    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16500    |
| policy_entropy     | 0.0212   |
| total_timesteps    | 1320000  |
| value_loss         | 340      |
---------------------------------
---------------------------------
| avg reward         | -272     |
| explained_variance | -0.0302  |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16600    |
| policy_entropy     | 0        |
| total_timesteps    | 1328000  |
| value_loss         | 2.96e+03 |
---------------------------------
---------------------------------
| avg reward         | 154      |
| explained_variance | 0.0469   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16700    |
| policy_entropy     | 0.0358   |
| total_timesteps    | 1336000  |
| value_loss         | 801      |
---------------------------------
---------------------------------
| avg reward         | -316     |
| explained_variance | 0.264    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16800    |
| policy_entropy     | 0        |
| total_timesteps    | 1344000  |
| value_loss         | 67       |
---------------------------------
---------------------------------
| avg reward         | -116     |
| explained_variance | -0.756   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 16900    |
| policy_entropy     | 0.0298   |
| total_timesteps    | 1352000  |
| value_loss         | 1.02e+03 |
---------------------------------
---------------------------------
| avg reward         | 20.8     |
| explained_variance | 0.0166   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 17000    |
| policy_entropy     | 0.00584  |
| total_timesteps    | 1360000  |
| value_loss         | 10.6     |
---------------------------------
---------------------------------
| avg reward         | 178      |
| explained_variance | 0.869    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 17100    |
| policy_entropy     | 0        |
| total_timesteps    | 1368000  |
| value_loss         | 20       |
---------------------------------
---------------------------------
| avg reward         | -304     |
| explained_variance | -0.0191  |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 17200    |
| policy_entropy     | 0        |
| total_timesteps    | 1376000  |
| value_loss         | 3.64e+03 |
---------------------------------
---------------------------------
| avg reward         | 182      |
| explained_variance | -11.8    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 17300    |
| policy_entropy     | 0.0161   |
| total_timesteps    | 1384000  |
| value_loss         | 454      |
---------------------------------
---------------------------------
| avg reward         | 171      |
| explained_variance | 0.321    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 17400    |
| policy_entropy     | 0.016    |
| total_timesteps    | 1392000  |
| value_loss         | 775      |
---------------------------------
---------------------------------
| avg reward         | 73.4     |
| explained_variance | 0.479    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 17500    |
| policy_entropy     | 0.0407   |
| total_timesteps    | 1400000  |
| value_loss         | 254      |
---------------------------------
---------------------------------
| avg reward         | -98.6    |
| explained_variance | 0.634    |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 17600    |
| policy_entropy     | 0        |
| total_timesteps    | 1408000  |
| value_loss         | 6.31     |
---------------------------------
---------------------------------
| avg reward         | 168      |
| explained_variance | -2.58    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 17700    |
| policy_entropy     | 0.128    |
| total_timesteps    | 1416000  |
| value_loss         | 3.64e+03 |
---------------------------------
---------------------------------
| avg reward         | -157     |
| explained_variance | -8.56    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 17800    |
| policy_entropy     | 0.0171   |
| total_timesteps    | 1424000  |
| value_loss         | 307      |
---------------------------------
---------------------------------
| avg reward         | -219     |
| explained_variance | 0.74     |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 17900    |
| policy_entropy     | 0        |
| total_timesteps    | 1432000  |
| value_loss         | 37.5     |
---------------------------------
---------------------------------
| avg reward         | 301      |
| explained_variance | -41.5    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18000    |
| policy_entropy     | 0.0641   |
| total_timesteps    | 1440000  |
| value_loss         | 3.45e+03 |
---------------------------------
---------------------------------
| avg reward         | 394      |
| explained_variance | -2.8     |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18100    |
| policy_entropy     | 0.0328   |
| total_timesteps    | 1448000  |
| value_loss         | 4.02e+03 |
---------------------------------
---------------------------------
| avg reward         | -80.6    |
| explained_variance | 0.902    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18200    |
| policy_entropy     | 0        |
| total_timesteps    | 1456000  |
| value_loss         | 4.67     |
---------------------------------
---------------------------------
| avg reward         | 228      |
| explained_variance | 0.865    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18300    |
| policy_entropy     | 0        |
| total_timesteps    | 1464000  |
| value_loss         | 40.5     |
---------------------------------
---------------------------------
| avg reward         | -243     |
| explained_variance | 0.821    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18400    |
| policy_entropy     | 0        |
| total_timesteps    | 1472000  |
| value_loss         | 29.4     |
---------------------------------
---------------------------------
| avg reward         | -134     |
| explained_variance | 0.814    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18500    |
| policy_entropy     | 0        |
| total_timesteps    | 1480000  |
| value_loss         | 16       |
---------------------------------
---------------------------------
| avg reward         | -158     |
| explained_variance | 0.719    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 18600    |
| policy_entropy     | 0        |
| total_timesteps    | 1488000  |
| value_loss         | 30.9     |
---------------------------------
---------------------------------
| avg reward         | -300     |
| explained_variance | 0.759    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18700    |
| policy_entropy     | 0        |
| total_timesteps    | 1496000  |
| value_loss         | 59.7     |
---------------------------------
---------------------------------
| avg reward         | -169     |
| explained_variance | 0.866    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 18800    |
| policy_entropy     | 0        |
| total_timesteps    | 1504000  |
| value_loss         | 17.9     |
---------------------------------
---------------------------------
| avg reward         | 106      |
| explained_variance | 0.277    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 18900    |
| policy_entropy     | 0        |
| total_timesteps    | 1512000  |
| value_loss         | 333      |
---------------------------------
---------------------------------
| avg reward         | -95.3    |
| explained_variance | -0.452   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 19000    |
| policy_entropy     | 0.0506   |
| total_timesteps    | 1520000  |
| value_loss         | 716      |
---------------------------------
---------------------------------
| avg reward         | 56.3     |
| explained_variance | -1.41    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 19100    |
| policy_entropy     | 0.0349   |
| total_timesteps    | 1528000  |
| value_loss         | 95.9     |
---------------------------------
---------------------------------
| avg reward         | 285      |
| explained_variance | -23.4    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19200    |
| policy_entropy     | 0.0446   |
| total_timesteps    | 1536000  |
| value_loss         | 2.16e+03 |
---------------------------------
---------------------------------
| avg reward         | 81.2     |
| explained_variance | -1.34    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 19300    |
| policy_entropy     | 0.0193   |
| total_timesteps    | 1544000  |
| value_loss         | 101      |
---------------------------------
---------------------------------
| avg reward         | -86.9    |
| explained_variance | 0.793    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19400    |
| policy_entropy     | 0        |
| total_timesteps    | 1552000  |
| value_loss         | 8.4      |
---------------------------------
---------------------------------
| avg reward         | -234     |
| explained_variance | -0.0467  |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19500    |
| policy_entropy     | 0        |
| total_timesteps    | 1560000  |
| value_loss         | 5.01e+03 |
---------------------------------
---------------------------------
| avg reward         | -256     |
| explained_variance | 0.76     |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19600    |
| policy_entropy     | 0        |
| total_timesteps    | 1568000  |
| value_loss         | 38       |
---------------------------------
---------------------------------
| avg reward         | 303      |
| explained_variance | -7.36    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19700    |
| policy_entropy     | 0.00709  |
| total_timesteps    | 1576000  |
| value_loss         | 622      |
---------------------------------
---------------------------------
| avg reward         | 93.3     |
| explained_variance | -1.4     |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19800    |
| policy_entropy     | 0.067    |
| total_timesteps    | 1584000  |
| value_loss         | 564      |
---------------------------------
---------------------------------
| avg reward         | -75.5    |
| explained_variance | 0.719    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 19900    |
| policy_entropy     | 0        |
| total_timesteps    | 1592000  |
| value_loss         | 18.3     |
---------------------------------
---------------------------------
| avg reward         | -35.6    |
| explained_variance | 0.598    |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 20000    |
| policy_entropy     | 0        |
| total_timesteps    | 1600000  |
| value_loss         | 23.1     |
---------------------------------
---------------------------------
| avg reward         | 116      |
| explained_variance | 0.61     |
| fps                | 1995     |
| learning rate      | 0.001    |
| nupdates           | 20100    |
| policy_entropy     | 0.0277   |
| total_timesteps    | 1608000  |
| value_loss         | 262      |
---------------------------------
---------------------------------
| avg reward         | -622     |
| explained_variance | 0.369    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20200    |
| policy_entropy     | 0.026    |
| total_timesteps    | 1616000  |
| value_loss         | 9.02e+03 |
---------------------------------
---------------------------------
| avg reward         | -322     |
| explained_variance | -1.49    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20300    |
| policy_entropy     | 0.0272   |
| total_timesteps    | 1624000  |
| value_loss         | 3.5e+03  |
---------------------------------
---------------------------------
| avg reward         | 441      |
| explained_variance | -21.3    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20400    |
| policy_entropy     | 0.0375   |
| total_timesteps    | 1632000  |
| value_loss         | 3.93e+03 |
---------------------------------
---------------------------------
| avg reward         | -337     |
| explained_variance | -0.777   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20500    |
| policy_entropy     | 0.0289   |
| total_timesteps    | 1640000  |
| value_loss         | 7.02e+03 |
---------------------------------
---------------------------------
| avg reward         | 141      |
| explained_variance | 0.934    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20600    |
| policy_entropy     | 0        |
| total_timesteps    | 1648000  |
| value_loss         | 30.3     |
---------------------------------
---------------------------------
| avg reward         | -17.8    |
| explained_variance | 0.86     |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20700    |
| policy_entropy     | 0        |
| total_timesteps    | 1656000  |
| value_loss         | 17.9     |
---------------------------------
---------------------------------
| avg reward         | 254      |
| explained_variance | 0.363    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20800    |
| policy_entropy     | 0.0169   |
| total_timesteps    | 1664000  |
| value_loss         | 1.65e+03 |
---------------------------------
---------------------------------
| avg reward         | 307      |
| explained_variance | 0.842    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 20900    |
| policy_entropy     | 0        |
| total_timesteps    | 1672000  |
| value_loss         | 74.6     |
---------------------------------
---------------------------------
| avg reward         | -448     |
| explained_variance | -40.1    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 21000    |
| policy_entropy     | 0.0296   |
| total_timesteps    | 1680000  |
| value_loss         | 3.68e+03 |
---------------------------------
---------------------------------
| avg reward         | 260      |
| explained_variance | 0.84     |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 21100    |
| policy_entropy     | 0        |
| total_timesteps    | 1688000  |
| value_loss         | 78.2     |
---------------------------------
---------------------------------
| avg reward         | -370     |
| explained_variance | -0.761   |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 21200    |
| policy_entropy     | 0.0878   |
| total_timesteps    | 1696000  |
| value_loss         | 1.48e+04 |
---------------------------------
---------------------------------
| avg reward         | -102     |
| explained_variance | 0.916    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 21300    |
| policy_entropy     | 0        |
| total_timesteps    | 1704000  |
| value_loss         | 21.2     |
---------------------------------
---------------------------------
| avg reward         | 391      |
| explained_variance | -2.27    |
| fps                | 1996     |
| learning rate      | 0.001    |
| nupdates           | 21400    |
| policy_entropy     | 0.032    |
| total_timesteps    | 1712000  |
| value_loss         | 3.95e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.19e+03 |
| explained_variance | -31      |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 21500    |
| policy_entropy     | 0        |
| total_timesteps    | 1720000  |
| value_loss         | 1.45e+04 |
---------------------------------
---------------------------------
| avg reward         | -147     |
| explained_variance | -0.567   |
| fps                | 1997     |
| learning rate      | 0.001    |
| nupdates           | 21600    |
| policy_entropy     | 0.019    |
| total_timesteps    | 1728000  |
| value_loss         | 692      |
---------------------------------
---------------------------------
| avg reward         | -787     |
| explained_variance | -1.35    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 21700    |
| policy_entropy     | 0.018    |
| total_timesteps    | 1736000  |
| value_loss         | 1.92e+04 |
---------------------------------
---------------------------------
| avg reward         | -382     |
| explained_variance | -0.108   |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 21800    |
| policy_entropy     | 0        |
| total_timesteps    | 1744000  |
| value_loss         | 6.52e+03 |
---------------------------------
---------------------------------
| avg reward         | 575      |
| explained_variance | -8.8     |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 21900    |
| policy_entropy     | 0        |
| total_timesteps    | 1752000  |
| value_loss         | 3.11e+03 |
---------------------------------
---------------------------------
| avg reward         | 286      |
| explained_variance | -1.42    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 22000    |
| policy_entropy     | 0        |
| total_timesteps    | 1760000  |
| value_loss         | 2.12e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.02e+03 |
| explained_variance | 0.671    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 22100    |
| policy_entropy     | 0        |
| total_timesteps    | 1768000  |
| value_loss         | 621      |
---------------------------------
----------------------------------
| avg reward         | -1.08e+03 |
| explained_variance | -0.396    |
| fps                | 1998      |
| learning rate      | 0.001     |
| nupdates           | 22200     |
| policy_entropy     | 0         |
| total_timesteps    | 1776000   |
| value_loss         | 5.57e+04  |
----------------------------------
---------------------------------
| avg reward         | -577     |
| explained_variance | 0.149    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 22300    |
| policy_entropy     | 0        |
| total_timesteps    | 1784000  |
| value_loss         | 8.25e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.74e+03 |
| explained_variance | -2.15    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 22400    |
| policy_entropy     | 0        |
| total_timesteps    | 1792000  |
| value_loss         | 1.27e+05 |
---------------------------------
---------------------------------
| avg reward         | 281      |
| explained_variance | 0.936    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 22500    |
| policy_entropy     | 0        |
| total_timesteps    | 1800000  |
| value_loss         | 91.7     |
---------------------------------
----------------------------------
| avg reward         | -1.28e+03 |
| explained_variance | -1.23     |
| fps                | 1999      |
| learning rate      | 0.001     |
| nupdates           | 22600     |
| policy_entropy     | 0         |
| total_timesteps    | 1808000   |
| value_loss         | 4.86e+04  |
----------------------------------
---------------------------------
| avg reward         | -688     |
| explained_variance | -1.45    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 22700    |
| policy_entropy     | 0        |
| total_timesteps    | 1816000  |
| value_loss         | 1.47e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.58e+03 |
| explained_variance | -2.13    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 22800    |
| policy_entropy     | 0        |
| total_timesteps    | 1824000  |
| value_loss         | 5.29e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.69e+03 |
| explained_variance | 0.132     |
| fps                | 1998      |
| learning rate      | 0.001     |
| nupdates           | 22900     |
| policy_entropy     | 0         |
| total_timesteps    | 1832000   |
| value_loss         | 6.87e+04  |
----------------------------------
---------------------------------
| avg reward         | 409      |
| explained_variance | 0.223    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 23000    |
| policy_entropy     | 0        |
| total_timesteps    | 1840000  |
| value_loss         | 9.99e+03 |
---------------------------------
---------------------------------
| avg reward         | -266     |
| explained_variance | 0.875    |
| fps                | 1998     |
| learning rate      | 0.001    |
| nupdates           | 23100    |
| policy_entropy     | 0        |
| total_timesteps    | 1848000  |
| value_loss         | 65.7     |
---------------------------------
---------------------------------
| avg reward         | 693      |
| explained_variance | 0.781    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23200    |
| policy_entropy     | 0        |
| total_timesteps    | 1856000  |
| value_loss         | 401      |
---------------------------------
---------------------------------
| avg reward         | -151     |
| explained_variance | 0.944    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23300    |
| policy_entropy     | 0        |
| total_timesteps    | 1864000  |
| value_loss         | 48.5     |
---------------------------------
---------------------------------
| avg reward         | -521     |
| explained_variance | 0.884    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23400    |
| policy_entropy     | 0        |
| total_timesteps    | 1872000  |
| value_loss         | 215      |
---------------------------------
---------------------------------
| avg reward         | 850      |
| explained_variance | -0.173   |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23500    |
| policy_entropy     | 0        |
| total_timesteps    | 1880000  |
| value_loss         | 4.16e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.94e+03 |
| explained_variance | 0.24      |
| fps                | 1999      |
| learning rate      | 0.001     |
| nupdates           | 23600     |
| policy_entropy     | 0         |
| total_timesteps    | 1888000   |
| value_loss         | 2.18e+03  |
----------------------------------
---------------------------------
| avg reward         | 935      |
| explained_variance | -0.876   |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23700    |
| policy_entropy     | 0        |
| total_timesteps    | 1896000  |
| value_loss         | 2.31e+04 |
---------------------------------
---------------------------------
| avg reward         | -1.5e+03 |
| explained_variance | 0.638    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23800    |
| policy_entropy     | 0        |
| total_timesteps    | 1904000  |
| value_loss         | 1.22e+03 |
---------------------------------
---------------------------------
| avg reward         | 678      |
| explained_variance | 0.902    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 23900    |
| policy_entropy     | 0        |
| total_timesteps    | 1912000  |
| value_loss         | 348      |
---------------------------------
---------------------------------
| avg reward         | -341     |
| explained_variance | 0.777    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 24000    |
| policy_entropy     | 0        |
| total_timesteps    | 1920000  |
| value_loss         | 158      |
---------------------------------
---------------------------------
| avg reward         | -921     |
| explained_variance | -28.2    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 24100    |
| policy_entropy     | 0        |
| total_timesteps    | 1928000  |
| value_loss         | 1.03e+04 |
---------------------------------
---------------------------------
| avg reward         | 338      |
| explained_variance | 0.859    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 24200    |
| policy_entropy     | 0        |
| total_timesteps    | 1936000  |
| value_loss         | 211      |
---------------------------------
---------------------------------
| avg reward         | 927      |
| explained_variance | 0.133    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 24300    |
| policy_entropy     | 0        |
| total_timesteps    | 1944000  |
| value_loss         | 3.03e+04 |
---------------------------------
---------------------------------
| avg reward         | -634     |
| explained_variance | -0.018   |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 24400    |
| policy_entropy     | 0        |
| total_timesteps    | 1952000  |
| value_loss         | 1.42e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.24e+03 |
| explained_variance | 0.884    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 24500    |
| policy_entropy     | 0        |
| total_timesteps    | 1960000  |
| value_loss         | 1.05e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.83e+03 |
| explained_variance | -28.6     |
| fps                | 2000      |
| learning rate      | 0.001     |
| nupdates           | 24600     |
| policy_entropy     | 0         |
| total_timesteps    | 1968000   |
| value_loss         | 2.08e+04  |
----------------------------------
---------------------------------
| avg reward         | -712     |
| explained_variance | 0.843    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 24700    |
| policy_entropy     | 0        |
| total_timesteps    | 1976000  |
| value_loss         | 294      |
---------------------------------
----------------------------------
| avg reward         | -1.95e+03 |
| explained_variance | 0.126     |
| fps                | 2000      |
| learning rate      | 0.001     |
| nupdates           | 24800     |
| policy_entropy     | 0         |
| total_timesteps    | 1984000   |
| value_loss         | 9.04e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.04e+03 |
| explained_variance | -2.09    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 24900    |
| policy_entropy     | 0        |
| total_timesteps    | 1992000  |
| value_loss         | 4.74e+04 |
---------------------------------
---------------------------------
| avg reward         | -24.8    |
| explained_variance | 0.954    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 25000    |
| policy_entropy     | 0        |
| total_timesteps    | 2000000  |
| value_loss         | 60.6     |
---------------------------------
----------------------------------
| avg reward         | -1.66e+03 |
| explained_variance | -1.55     |
| fps                | 1999      |
| learning rate      | 0.001     |
| nupdates           | 25100     |
| policy_entropy     | 0.0283    |
| total_timesteps    | 2008000   |
| value_loss         | 1.88e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.24e+03 |
| explained_variance | -58.1     |
| fps                | 1999      |
| learning rate      | 0.001     |
| nupdates           | 25200     |
| policy_entropy     | 0.0144    |
| total_timesteps    | 2016000   |
| value_loss         | 2.32e+04  |
----------------------------------
---------------------------------
| avg reward         | -252     |
| explained_variance | 0.889    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 25300    |
| policy_entropy     | 0        |
| total_timesteps    | 2024000  |
| value_loss         | 69.7     |
---------------------------------
---------------------------------
| avg reward         | 1.59e+03 |
| explained_variance | 0.104    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 25400    |
| policy_entropy     | 0        |
| total_timesteps    | 2032000  |
| value_loss         | 8.88e+04 |
---------------------------------
---------------------------------
| avg reward         | 898      |
| explained_variance | -2.23    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 25500    |
| policy_entropy     | 0.0139   |
| total_timesteps    | 2040000  |
| value_loss         | 2.1e+04  |
---------------------------------
---------------------------------
| avg reward         | 1.49e+03 |
| explained_variance | 0.706    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 25600    |
| policy_entropy     | 0        |
| total_timesteps    | 2048000  |
| value_loss         | 1.34e+03 |
---------------------------------
----------------------------------
| avg reward         | -2.05e+03 |
| explained_variance | -67.9     |
| fps                | 2000      |
| learning rate      | 0.001     |
| nupdates           | 25700     |
| policy_entropy     | 0.0135    |
| total_timesteps    | 2056000   |
| value_loss         | 6.47e+04  |
----------------------------------
---------------------------------
| avg reward         | 480      |
| explained_variance | 0.936    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 25800    |
| policy_entropy     | 0        |
| total_timesteps    | 2064000  |
| value_loss         | 231      |
---------------------------------
---------------------------------
| avg reward         | 991      |
| explained_variance | -0.281   |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 25900    |
| policy_entropy     | 0.0289   |
| total_timesteps    | 2072000  |
| value_loss         | 4.42e+04 |
---------------------------------
---------------------------------
| avg reward         | -276     |
| explained_variance | -0.659   |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 26000    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 2080000  |
| value_loss         | 6.28e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.18e+03 |
| explained_variance | 0.774     |
| fps                | 2000      |
| learning rate      | 0.001     |
| nupdates           | 26100     |
| policy_entropy     | 0         |
| total_timesteps    | 2088000   |
| value_loss         | 728       |
----------------------------------
---------------------------------
| avg reward         | 1.09e+03 |
| explained_variance | 0.156    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 26200    |
| policy_entropy     | 0        |
| total_timesteps    | 2096000  |
| value_loss         | 4.06e+04 |
---------------------------------
---------------------------------
| avg reward         | -683     |
| explained_variance | 0.775    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 26300    |
| policy_entropy     | 0        |
| total_timesteps    | 2104000  |
| value_loss         | 239      |
---------------------------------
---------------------------------
| avg reward         | 2.22e+03 |
| explained_variance | -1.38    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 26400    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 2112000  |
| value_loss         | 1.56e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.18e+03 |
| explained_variance | -46.6    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 26500    |
| policy_entropy     | 0.0294   |
| total_timesteps    | 2120000  |
| value_loss         | 4.62e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.24e+03 |
| explained_variance | 0.727     |
| fps                | 2001      |
| learning rate      | 0.001     |
| nupdates           | 26600     |
| policy_entropy     | 0         |
| total_timesteps    | 2128000   |
| value_loss         | 1.01e+03  |
----------------------------------
---------------------------------
| avg reward         | -789     |
| explained_variance | 0.822    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 26700    |
| policy_entropy     | 0        |
| total_timesteps    | 2136000  |
| value_loss         | 309      |
---------------------------------
---------------------------------
| avg reward         | 1.06e+03 |
| explained_variance | -0.423   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 26800    |
| policy_entropy     | 0.038    |
| total_timesteps    | 2144000  |
| value_loss         | 7.94e+04 |
---------------------------------
---------------------------------
| avg reward         | 112      |
| explained_variance | 0.819    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 26900    |
| policy_entropy     | 0        |
| total_timesteps    | 2152000  |
| value_loss         | 115      |
---------------------------------
---------------------------------
| avg reward         | -619     |
| explained_variance | 0.692    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 27000    |
| policy_entropy     | 0        |
| total_timesteps    | 2160000  |
| value_loss         | 290      |
---------------------------------
---------------------------------
| avg reward         | 720      |
| explained_variance | 0.656    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27100    |
| policy_entropy     | 0        |
| total_timesteps    | 2168000  |
| value_loss         | 571      |
---------------------------------
---------------------------------
| avg reward         | 784      |
| explained_variance | -2.57    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 27200    |
| policy_entropy     | 0.0311   |
| total_timesteps    | 2176000  |
| value_loss         | 1.7e+04  |
---------------------------------
---------------------------------
| avg reward         | 702      |
| explained_variance | 0.351    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27300    |
| policy_entropy     | 0.0143   |
| total_timesteps    | 2184000  |
| value_loss         | 1.31e+04 |
---------------------------------
---------------------------------
| avg reward         | -638     |
| explained_variance | 0.662    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27400    |
| policy_entropy     | 0        |
| total_timesteps    | 2192000  |
| value_loss         | 305      |
---------------------------------
---------------------------------
| avg reward         | 674      |
| explained_variance | 0.856    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27500    |
| policy_entropy     | 0        |
| total_timesteps    | 2200000  |
| value_loss         | 323      |
---------------------------------
---------------------------------
| avg reward         | 905      |
| explained_variance | -16.3    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27600    |
| policy_entropy     | 0.0266   |
| total_timesteps    | 2208000  |
| value_loss         | 1.56e+04 |
---------------------------------
---------------------------------
| avg reward         | 800      |
| explained_variance | 0.803    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27700    |
| policy_entropy     | 0        |
| total_timesteps    | 2216000  |
| value_loss         | 509      |
---------------------------------
----------------------------------
| avg reward         | -1.33e+03 |
| explained_variance | -42.7     |
| fps                | 2000      |
| learning rate      | 0.001     |
| nupdates           | 27800     |
| policy_entropy     | 0.011     |
| total_timesteps    | 2224000   |
| value_loss         | 2.04e+04  |
----------------------------------
---------------------------------
| avg reward         | -720     |
| explained_variance | -15.7    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 27900    |
| policy_entropy     | 0.025    |
| total_timesteps    | 2232000  |
| value_loss         | 8.55e+03 |
---------------------------------
---------------------------------
| avg reward         | 125      |
| explained_variance | 0.743    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28000    |
| policy_entropy     | 0.0254   |
| total_timesteps    | 2240000  |
| value_loss         | 311      |
---------------------------------
---------------------------------
| avg reward         | 250      |
| explained_variance | 0.00273  |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28100    |
| policy_entropy     | 0.0111   |
| total_timesteps    | 2248000  |
| value_loss         | 2.68e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.15e+03 |
| explained_variance | 0.714     |
| fps                | 2000      |
| learning rate      | 0.001     |
| nupdates           | 28200     |
| policy_entropy     | 0         |
| total_timesteps    | 2256000   |
| value_loss         | 670       |
----------------------------------
---------------------------------
| avg reward         | 645      |
| explained_variance | -6.13    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28300    |
| policy_entropy     | 0.0661   |
| total_timesteps    | 2264000  |
| value_loss         | 2.51e+04 |
---------------------------------
---------------------------------
| avg reward         | 391      |
| explained_variance | -2.57    |
| fps                | 1999     |
| learning rate      | 0.001    |
| nupdates           | 28400    |
| policy_entropy     | 0.0285   |
| total_timesteps    | 2272000  |
| value_loss         | 3.27e+03 |
---------------------------------
---------------------------------
| avg reward         | -993     |
| explained_variance | -0.011   |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28500    |
| policy_entropy     | 0        |
| total_timesteps    | 2280000  |
| value_loss         | 3.81e+04 |
---------------------------------
---------------------------------
| avg reward         | 458      |
| explained_variance | 0.384    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28600    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 2288000  |
| value_loss         | 5.53e+03 |
---------------------------------
---------------------------------
| avg reward         | 288      |
| explained_variance | -0.458   |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28700    |
| policy_entropy     | 0.0297   |
| total_timesteps    | 2296000  |
| value_loss         | 2.82e+03 |
---------------------------------
---------------------------------
| avg reward         | -640     |
| explained_variance | 0.802    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28800    |
| policy_entropy     | 0        |
| total_timesteps    | 2304000  |
| value_loss         | 271      |
---------------------------------
---------------------------------
| avg reward         | -387     |
| explained_variance | 0.655    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 28900    |
| policy_entropy     | 0        |
| total_timesteps    | 2312000  |
| value_loss         | 251      |
---------------------------------
---------------------------------
| avg reward         | 822      |
| explained_variance | -1.27    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 29000    |
| policy_entropy     | 0.0262   |
| total_timesteps    | 2320000  |
| value_loss         | 2.33e+04 |
---------------------------------
---------------------------------
| avg reward         | 595      |
| explained_variance | 0.325    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 29100    |
| policy_entropy     | 0.0243   |
| total_timesteps    | 2328000  |
| value_loss         | 2.1e+04  |
---------------------------------
---------------------------------
| avg reward         | 669      |
| explained_variance | -3.51    |
| fps                | 2000     |
| learning rate      | 0.001    |
| nupdates           | 29200    |
| policy_entropy     | 0        |
| total_timesteps    | 2336000  |
| value_loss         | 3.6e+03  |
---------------------------------
---------------------------------
| avg reward         | -60.8    |
| explained_variance | 0.833    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29300    |
| policy_entropy     | 0.025    |
| total_timesteps    | 2344000  |
| value_loss         | 86.9     |
---------------------------------
---------------------------------
| avg reward         | 440      |
| explained_variance | -0.521   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29400    |
| policy_entropy     | 0.0401   |
| total_timesteps    | 2352000  |
| value_loss         | 1.33e+04 |
---------------------------------
---------------------------------
| avg reward         | 586      |
| explained_variance | 0.819    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29500    |
| policy_entropy     | 0        |
| total_timesteps    | 2360000  |
| value_loss         | 355      |
---------------------------------
---------------------------------
| avg reward         | 384      |
| explained_variance | 0.822    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29600    |
| policy_entropy     | 0        |
| total_timesteps    | 2368000  |
| value_loss         | 180      |
---------------------------------
---------------------------------
| avg reward         | -376     |
| explained_variance | -1.06    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29700    |
| policy_entropy     | 0.0525   |
| total_timesteps    | 2376000  |
| value_loss         | 1.5e+04  |
---------------------------------
---------------------------------
| avg reward         | -616     |
| explained_variance | 0.803    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29800    |
| policy_entropy     | 0        |
| total_timesteps    | 2384000  |
| value_loss         | 356      |
---------------------------------
---------------------------------
| avg reward         | -563     |
| explained_variance | 0.0657   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 29900    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 2392000  |
| value_loss         | 1.15e+04 |
---------------------------------
---------------------------------
| avg reward         | -411     |
| explained_variance | -4.68    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30000    |
| policy_entropy     | 0.0681   |
| total_timesteps    | 2400000  |
| value_loss         | 9.68e+03 |
---------------------------------
---------------------------------
| avg reward         | 786      |
| explained_variance | -1.18    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30100    |
| policy_entropy     | 0.0304   |
| total_timesteps    | 2408000  |
| value_loss         | 2.04e+04 |
---------------------------------
---------------------------------
| avg reward         | 161      |
| explained_variance | -0.171   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30200    |
| policy_entropy     | 0.0307   |
| total_timesteps    | 2416000  |
| value_loss         | 556      |
---------------------------------
---------------------------------
| avg reward         | -249     |
| explained_variance | -1.25    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30300    |
| policy_entropy     | 0.0302   |
| total_timesteps    | 2424000  |
| value_loss         | 1.8e+03  |
---------------------------------
---------------------------------
| avg reward         | 357      |
| explained_variance | 0.765    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30400    |
| policy_entropy     | 0        |
| total_timesteps    | 2432000  |
| value_loss         | 202      |
---------------------------------
---------------------------------
| avg reward         | 292      |
| explained_variance | 0.915    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 30500    |
| policy_entropy     | 0        |
| total_timesteps    | 2440000  |
| value_loss         | 157      |
---------------------------------
---------------------------------
| avg reward         | 421      |
| explained_variance | 0.398    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 30600    |
| policy_entropy     | 0        |
| total_timesteps    | 2448000  |
| value_loss         | 4.54e+03 |
---------------------------------
---------------------------------
| avg reward         | 310      |
| explained_variance | -0.66    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30700    |
| policy_entropy     | 0.0303   |
| total_timesteps    | 2456000  |
| value_loss         | 4.21e+03 |
---------------------------------
---------------------------------
| avg reward         | -648     |
| explained_variance | 0.546    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 30800    |
| policy_entropy     | 0        |
| total_timesteps    | 2464000  |
| value_loss         | 255      |
---------------------------------
---------------------------------
| avg reward         | 527      |
| explained_variance | -1.16    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 30900    |
| policy_entropy     | 0.0311   |
| total_timesteps    | 2472000  |
| value_loss         | 9.19e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.21e+03 |
| explained_variance | 0.603     |
| fps                | 2002      |
| learning rate      | 0.001     |
| nupdates           | 31000     |
| policy_entropy     | 0         |
| total_timesteps    | 2480000   |
| value_loss         | 821       |
----------------------------------
---------------------------------
| avg reward         | -396     |
| explained_variance | -1.53    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 31100    |
| policy_entropy     | 0.0608   |
| total_timesteps    | 2488000  |
| value_loss         | 7.13e+03 |
---------------------------------
---------------------------------
| avg reward         | -863     |
| explained_variance | 0.776    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 31200    |
| policy_entropy     | 0        |
| total_timesteps    | 2496000  |
| value_loss         | 512      |
---------------------------------
---------------------------------
| avg reward         | -568     |
| explained_variance | 0.0102   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 31300    |
| policy_entropy     | 0.0286   |
| total_timesteps    | 2504000  |
| value_loss         | 1.09e+04 |
---------------------------------
---------------------------------
| avg reward         | 829      |
| explained_variance | 0.367    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 31400    |
| policy_entropy     | 0.0157   |
| total_timesteps    | 2512000  |
| value_loss         | 1.76e+04 |
---------------------------------
---------------------------------
| avg reward         | -653     |
| explained_variance | 0.282    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 31500    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 2520000  |
| value_loss         | 1.13e+04 |
---------------------------------
---------------------------------
| avg reward         | -596     |
| explained_variance | 0.77     |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 31600    |
| policy_entropy     | 0        |
| total_timesteps    | 2528000  |
| value_loss         | 318      |
---------------------------------
---------------------------------
| avg reward         | 812      |
| explained_variance | 0.742    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 31700    |
| policy_entropy     | 0        |
| total_timesteps    | 2536000  |
| value_loss         | 652      |
---------------------------------
---------------------------------
| avg reward         | 646      |
| explained_variance | 0.22     |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 31800    |
| policy_entropy     | 0        |
| total_timesteps    | 2544000  |
| value_loss         | 1.36e+04 |
---------------------------------
---------------------------------
| avg reward         | 82.4     |
| explained_variance | 0.589    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 31900    |
| policy_entropy     | 0.0382   |
| total_timesteps    | 2552000  |
| value_loss         | 376      |
---------------------------------
---------------------------------
| avg reward         | 417      |
| explained_variance | -4.3     |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 32000    |
| policy_entropy     | 0.0377   |
| total_timesteps    | 2560000  |
| value_loss         | 4.45e+03 |
---------------------------------
---------------------------------
| avg reward         | 871      |
| explained_variance | 0.807    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 32100    |
| policy_entropy     | 0        |
| total_timesteps    | 2568000  |
| value_loss         | 632      |
---------------------------------
---------------------------------
| avg reward         | 520      |
| explained_variance | 0.688    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 32200    |
| policy_entropy     | 0        |
| total_timesteps    | 2576000  |
| value_loss         | 576      |
---------------------------------
---------------------------------
| avg reward         | 570      |
| explained_variance | 0.854    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 32300    |
| policy_entropy     | 0        |
| total_timesteps    | 2584000  |
| value_loss         | 270      |
---------------------------------
---------------------------------
| avg reward         | 37       |
| explained_variance | 0.68     |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 32400    |
| policy_entropy     | 0.00861  |
| total_timesteps    | 2592000  |
| value_loss         | 298      |
---------------------------------
---------------------------------
| avg reward         | -654     |
| explained_variance | 0.848    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 32500    |
| policy_entropy     | 0        |
| total_timesteps    | 2600000  |
| value_loss         | 329      |
---------------------------------
---------------------------------
| avg reward         | -915     |
| explained_variance | 0.829    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 32600    |
| policy_entropy     | 0        |
| total_timesteps    | 2608000  |
| value_loss         | 642      |
---------------------------------
---------------------------------
| avg reward         | 977      |
| explained_variance | 0.904    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 32700    |
| policy_entropy     | 0        |
| total_timesteps    | 2616000  |
| value_loss         | 954      |
---------------------------------
---------------------------------
| avg reward         | -346     |
| explained_variance | -0.0282  |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 32800    |
| policy_entropy     | 0        |
| total_timesteps    | 2624000  |
| value_loss         | 1.1e+04  |
---------------------------------
---------------------------------
| avg reward         | -432     |
| explained_variance | -0.00201 |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 32900    |
| policy_entropy     | 0.0431   |
| total_timesteps    | 2632000  |
| value_loss         | 2.75e+04 |
---------------------------------
---------------------------------
| avg reward         | -218     |
| explained_variance | 0.623    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33000    |
| policy_entropy     | 0        |
| total_timesteps    | 2640000  |
| value_loss         | 187      |
---------------------------------
---------------------------------
| avg reward         | -151     |
| explained_variance | 0.304    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33100    |
| policy_entropy     | 0        |
| total_timesteps    | 2648000  |
| value_loss         | 103      |
---------------------------------
---------------------------------
| avg reward         | 11.8     |
| explained_variance | 0.0135   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33200    |
| policy_entropy     | 0        |
| total_timesteps    | 2656000  |
| value_loss         | 0.108    |
---------------------------------
---------------------------------
| avg reward         | -3.93    |
| explained_variance | -0.058   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 33300    |
| policy_entropy     | 0        |
| total_timesteps    | 2664000  |
| value_loss         | 0.725    |
---------------------------------
---------------------------------
| avg reward         | 5.72     |
| explained_variance | 0.264    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33400    |
| policy_entropy     | 0        |
| total_timesteps    | 2672000  |
| value_loss         | 0.051    |
---------------------------------
---------------------------------
| avg reward         | 13.8     |
| explained_variance | -0.213   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33500    |
| policy_entropy     | 0        |
| total_timesteps    | 2680000  |
| value_loss         | 8.32     |
---------------------------------
---------------------------------
| avg reward         | 42       |
| explained_variance | 0.205    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33600    |
| policy_entropy     | 0        |
| total_timesteps    | 2688000  |
| value_loss         | 0.783    |
---------------------------------
---------------------------------
| avg reward         | 39.2     |
| explained_variance | 0.387    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 33700    |
| policy_entropy     | 0        |
| total_timesteps    | 2696000  |
| value_loss         | 0.713    |
---------------------------------
---------------------------------
| avg reward         | -22      |
| explained_variance | 0.355    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 33800    |
| policy_entropy     | 0        |
| total_timesteps    | 2704000  |
| value_loss         | 0.455    |
---------------------------------
---------------------------------
| avg reward         | -3.11    |
| explained_variance | -0.444   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 33900    |
| policy_entropy     | 4.51e-28 |
| total_timesteps    | 2712000  |
| value_loss         | 0.693    |
---------------------------------
---------------------------------
| avg reward         | -27.5    |
| explained_variance | 0.0941   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34000    |
| policy_entropy     | 4.24e-34 |
| total_timesteps    | 2720000  |
| value_loss         | 17.7     |
---------------------------------
---------------------------------
| avg reward         | 11.2     |
| explained_variance | 0.165    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34100    |
| policy_entropy     | 0        |
| total_timesteps    | 2728000  |
| value_loss         | 3.25     |
---------------------------------
---------------------------------
| avg reward         | -16.7    |
| explained_variance | 0.692    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34200    |
| policy_entropy     | 0        |
| total_timesteps    | 2736000  |
| value_loss         | 0.17     |
---------------------------------
---------------------------------
| avg reward         | -44.4    |
| explained_variance | 0.161    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34300    |
| policy_entropy     | 0        |
| total_timesteps    | 2744000  |
| value_loss         | 1.62     |
---------------------------------
---------------------------------
| avg reward         | 37.5     |
| explained_variance | -0.986   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34400    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 2752000  |
| value_loss         | 65.1     |
---------------------------------
---------------------------------
| avg reward         | 40.4     |
| explained_variance | -1.81    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34500    |
| policy_entropy     | 1.91e-16 |
| total_timesteps    | 2760000  |
| value_loss         | 29.8     |
---------------------------------
---------------------------------
| avg reward         | 53.8     |
| explained_variance | 0.546    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 34600    |
| policy_entropy     | 0        |
| total_timesteps    | 2768000  |
| value_loss         | 1.44     |
---------------------------------
---------------------------------
| avg reward         | 26.8     |
| explained_variance | 0.476    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 34700    |
| policy_entropy     | 0        |
| total_timesteps    | 2776000  |
| value_loss         | 0.381    |
---------------------------------
---------------------------------
| avg reward         | -27.7    |
| explained_variance | 0.267    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 34800    |
| policy_entropy     | 0        |
| total_timesteps    | 2784000  |
| value_loss         | 0.604    |
---------------------------------
---------------------------------
| avg reward         | 4        |
| explained_variance | 0.575    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 34900    |
| policy_entropy     | 0        |
| total_timesteps    | 2792000  |
| value_loss         | 0.203    |
---------------------------------
---------------------------------
| avg reward         | 101      |
| explained_variance | 0.251    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35000    |
| policy_entropy     | 0        |
| total_timesteps    | 2800000  |
| value_loss         | 5.35     |
---------------------------------
---------------------------------
| avg reward         | -57.1    |
| explained_variance | -0.256   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35100    |
| policy_entropy     | 0        |
| total_timesteps    | 2808000  |
| value_loss         | 196      |
---------------------------------
---------------------------------
| avg reward         | -25.7    |
| explained_variance | 0.0684   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35200    |
| policy_entropy     | 4.47e-28 |
| total_timesteps    | 2816000  |
| value_loss         | 16.7     |
---------------------------------
---------------------------------
| avg reward         | 37.3     |
| explained_variance | 0.141    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35300    |
| policy_entropy     | 1.33e-17 |
| total_timesteps    | 2824000  |
| value_loss         | 30.1     |
---------------------------------
---------------------------------
| avg reward         | -15.6    |
| explained_variance | -29.2    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35400    |
| policy_entropy     | 5.47e-20 |
| total_timesteps    | 2832000  |
| value_loss         | 3.8      |
---------------------------------
---------------------------------
| avg reward         | -36.3    |
| explained_variance | 0.325    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35500    |
| policy_entropy     | 0        |
| total_timesteps    | 2840000  |
| value_loss         | 1.14     |
---------------------------------
---------------------------------
| avg reward         | -21.5    |
| explained_variance | -1.27    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35600    |
| policy_entropy     | 0        |
| total_timesteps    | 2848000  |
| value_loss         | 14.7     |
---------------------------------
---------------------------------
| avg reward         | 62.9     |
| explained_variance | 0.398    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35700    |
| policy_entropy     | 0        |
| total_timesteps    | 2856000  |
| value_loss         | 2.01     |
---------------------------------
---------------------------------
| avg reward         | 57.7     |
| explained_variance | 0.178    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35800    |
| policy_entropy     | 1.95e-23 |
| total_timesteps    | 2864000  |
| value_loss         | 75.3     |
---------------------------------
---------------------------------
| avg reward         | -57.2    |
| explained_variance | -0.445   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 35900    |
| policy_entropy     | 0        |
| total_timesteps    | 2872000  |
| value_loss         | 124      |
---------------------------------
---------------------------------
| avg reward         | 64       |
| explained_variance | 0.0423   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36000    |
| policy_entropy     | 0        |
| total_timesteps    | 2880000  |
| value_loss         | 150      |
---------------------------------
---------------------------------
| avg reward         | 11.9     |
| explained_variance | -1.23    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36100    |
| policy_entropy     | 1.47e-09 |
| total_timesteps    | 2888000  |
| value_loss         | 2.37     |
---------------------------------
---------------------------------
| avg reward         | 60.9     |
| explained_variance | 0.444    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36200    |
| policy_entropy     | 0        |
| total_timesteps    | 2896000  |
| value_loss         | 2.12     |
---------------------------------
---------------------------------
| avg reward         | 52.8     |
| explained_variance | 0.328    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36300    |
| policy_entropy     | 0        |
| total_timesteps    | 2904000  |
| value_loss         | 1.39     |
---------------------------------
---------------------------------
| avg reward         | 8.33     |
| explained_variance | 0.912    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36400    |
| policy_entropy     | 0        |
| total_timesteps    | 2912000  |
| value_loss         | 0.0727   |
---------------------------------
---------------------------------
| avg reward         | -64.9    |
| explained_variance | 0.155    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36500    |
| policy_entropy     | 2.15e-13 |
| total_timesteps    | 2920000  |
| value_loss         | 128      |
---------------------------------
---------------------------------
| avg reward         | 42.4     |
| explained_variance | 0.164    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36600    |
| policy_entropy     | 0.000125 |
| total_timesteps    | 2928000  |
| value_loss         | 87.9     |
---------------------------------
---------------------------------
| avg reward         | 45.9     |
| explained_variance | 0.459    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36700    |
| policy_entropy     | 9.73e-30 |
| total_timesteps    | 2936000  |
| value_loss         | 1.14     |
---------------------------------
---------------------------------
| avg reward         | -41.5    |
| explained_variance | -4.15    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36800    |
| policy_entropy     | 0.0172   |
| total_timesteps    | 2944000  |
| value_loss         | 57.9     |
---------------------------------
---------------------------------
| avg reward         | -29      |
| explained_variance | -61.5    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 36900    |
| policy_entropy     | 0.0082   |
| total_timesteps    | 2952000  |
| value_loss         | 11.2     |
---------------------------------
---------------------------------
| avg reward         | -1.22    |
| explained_variance | 0.647    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37000    |
| policy_entropy     | 0        |
| total_timesteps    | 2960000  |
| value_loss         | 0.0681   |
---------------------------------
---------------------------------
| avg reward         | 60.7     |
| explained_variance | -0.0731  |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37100    |
| policy_entropy     | 0.0013   |
| total_timesteps    | 2968000  |
| value_loss         | 311      |
---------------------------------
---------------------------------
| avg reward         | 40.2     |
| explained_variance | -8.31    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37200    |
| policy_entropy     | 0        |
| total_timesteps    | 2976000  |
| value_loss         | 5.08     |
---------------------------------
---------------------------------
| avg reward         | -14.6    |
| explained_variance | -1.58    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37300    |
| policy_entropy     | 0.000176 |
| total_timesteps    | 2984000  |
| value_loss         | 7.33     |
---------------------------------
---------------------------------
| avg reward         | 50.6     |
| explained_variance | -0.645   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37400    |
| policy_entropy     | 0.0277   |
| total_timesteps    | 2992000  |
| value_loss         | 141      |
---------------------------------
---------------------------------
| avg reward         | -21      |
| explained_variance | 0.523    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37500    |
| policy_entropy     | 0        |
| total_timesteps    | 3000000  |
| value_loss         | 0.525    |
---------------------------------
---------------------------------
| avg reward         | -68.3    |
| explained_variance | 0.183    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37600    |
| policy_entropy     | 0        |
| total_timesteps    | 3008000  |
| value_loss         | 3.31     |
---------------------------------
---------------------------------
| avg reward         | 80.9     |
| explained_variance | -20.8    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37700    |
| policy_entropy     | 0        |
| total_timesteps    | 3016000  |
| value_loss         | 21.8     |
---------------------------------
---------------------------------
| avg reward         | 13       |
| explained_variance | 0.239    |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37800    |
| policy_entropy     | 0        |
| total_timesteps    | 3024000  |
| value_loss         | 0.196    |
---------------------------------
---------------------------------
| avg reward         | -40.1    |
| explained_variance | 0.0889   |
| fps                | 2001     |
| learning rate      | 0.001    |
| nupdates           | 37900    |
| policy_entropy     | 0        |
| total_timesteps    | 3032000  |
| value_loss         | 1.19     |
---------------------------------
---------------------------------
| avg reward         | -54.2    |
| explained_variance | 0.138    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38000    |
| policy_entropy     | 0        |
| total_timesteps    | 3040000  |
| value_loss         | 2.5      |
---------------------------------
---------------------------------
| avg reward         | -20.9    |
| explained_variance | 0.085    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38100    |
| policy_entropy     | 0        |
| total_timesteps    | 3048000  |
| value_loss         | 0.68     |
---------------------------------
---------------------------------
| avg reward         | -11.2    |
| explained_variance | 0.559    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38200    |
| policy_entropy     | 0        |
| total_timesteps    | 3056000  |
| value_loss         | 0.196    |
---------------------------------
---------------------------------
| avg reward         | 36.9     |
| explained_variance | -1.47    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38300    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 3064000  |
| value_loss         | 44       |
---------------------------------
---------------------------------
| avg reward         | -67.7    |
| explained_variance | 0.4      |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38400    |
| policy_entropy     | 0.0183   |
| total_timesteps    | 3072000  |
| value_loss         | 106      |
---------------------------------
---------------------------------
| avg reward         | -66.1    |
| explained_variance | 0.136    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38500    |
| policy_entropy     | 0        |
| total_timesteps    | 3080000  |
| value_loss         | 3.01     |
---------------------------------
---------------------------------
| avg reward         | 70.8     |
| explained_variance | -0.649   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38600    |
| policy_entropy     | 0.0627   |
| total_timesteps    | 3088000  |
| value_loss         | 330      |
---------------------------------
---------------------------------
| avg reward         | 19.2     |
| explained_variance | -39.3    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 38700    |
| policy_entropy     | 0.0162   |
| total_timesteps    | 3096000  |
| value_loss         | 6.78     |
---------------------------------
---------------------------------
| avg reward         | -21.5    |
| explained_variance | -3.09    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 38800    |
| policy_entropy     | 0.0207   |
| total_timesteps    | 3104000  |
| value_loss         | 13       |
---------------------------------
---------------------------------
| avg reward         | 33       |
| explained_variance | 0.0527   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 38900    |
| policy_entropy     | 0        |
| total_timesteps    | 3112000  |
| value_loss         | 89.9     |
---------------------------------
---------------------------------
| avg reward         | 18.5     |
| explained_variance | 0.101    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39000    |
| policy_entropy     | 0.0133   |
| total_timesteps    | 3120000  |
| value_loss         | 26       |
---------------------------------
---------------------------------
| avg reward         | -72.7    |
| explained_variance | -100     |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39100    |
| policy_entropy     | 0.0219   |
| total_timesteps    | 3128000  |
| value_loss         | 94.1     |
---------------------------------
---------------------------------
| avg reward         | 28.5     |
| explained_variance | 0.222    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39200    |
| policy_entropy     | 0.0124   |
| total_timesteps    | 3136000  |
| value_loss         | 23.7     |
---------------------------------
---------------------------------
| avg reward         | 87.3     |
| explained_variance | 0.435    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39300    |
| policy_entropy     | 0        |
| total_timesteps    | 3144000  |
| value_loss         | 4.14     |
---------------------------------
---------------------------------
| avg reward         | 15.3     |
| explained_variance | 0.601    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39400    |
| policy_entropy     | 0        |
| total_timesteps    | 3152000  |
| value_loss         | 0.206    |
---------------------------------
---------------------------------
| avg reward         | -53.8    |
| explained_variance | 0.264    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39500    |
| policy_entropy     | 0        |
| total_timesteps    | 3160000  |
| value_loss         | 2.64     |
---------------------------------
---------------------------------
| avg reward         | 24.5     |
| explained_variance | -17.7    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39600    |
| policy_entropy     | 0.0185   |
| total_timesteps    | 3168000  |
| value_loss         | 9.44     |
---------------------------------
---------------------------------
| avg reward         | -120     |
| explained_variance | 0.223    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 39700    |
| policy_entropy     | 0        |
| total_timesteps    | 3176000  |
| value_loss         | 9.58     |
---------------------------------
---------------------------------
| avg reward         | -5       |
| explained_variance | 0.112    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 39800    |
| policy_entropy     | 0        |
| total_timesteps    | 3184000  |
| value_loss         | 0.388    |
---------------------------------
---------------------------------
| avg reward         | -89.5    |
| explained_variance | 0.267    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 39900    |
| policy_entropy     | 0.0145   |
| total_timesteps    | 3192000  |
| value_loss         | 187      |
---------------------------------
---------------------------------
| avg reward         | -21.4    |
| explained_variance | -31.8    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40000    |
| policy_entropy     | 0.0399   |
| total_timesteps    | 3200000  |
| value_loss         | 16.9     |
---------------------------------
---------------------------------
| avg reward         | 45.2     |
| explained_variance | -0.179   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40100    |
| policy_entropy     | 0.0188   |
| total_timesteps    | 3208000  |
| value_loss         | 83.1     |
---------------------------------
---------------------------------
| avg reward         | -85      |
| explained_variance | -3.06    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40200    |
| policy_entropy     | 0.0192   |
| total_timesteps    | 3216000  |
| value_loss         | 191      |
---------------------------------
---------------------------------
| avg reward         | -119     |
| explained_variance | -0.154   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40300    |
| policy_entropy     | 0        |
| total_timesteps    | 3224000  |
| value_loss         | 595      |
---------------------------------
---------------------------------
| avg reward         | 171      |
| explained_variance | -24.6    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40400    |
| policy_entropy     | 5.59e-38 |
| total_timesteps    | 3232000  |
| value_loss         | 137      |
---------------------------------
---------------------------------
| avg reward         | 63.3     |
| explained_variance | -29.1    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 40500    |
| policy_entropy     | 0.00415  |
| total_timesteps    | 3240000  |
| value_loss         | 23.7     |
---------------------------------
---------------------------------
| avg reward         | 108      |
| explained_variance | -0.799   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 40600    |
| policy_entropy     | 0.0452   |
| total_timesteps    | 3248000  |
| value_loss         | 1.17e+03 |
---------------------------------
---------------------------------
| avg reward         | 96.9     |
| explained_variance | -0.286   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40700    |
| policy_entropy     | 0.0366   |
| total_timesteps    | 3256000  |
| value_loss         | 564      |
---------------------------------
---------------------------------
| avg reward         | 51.1     |
| explained_variance | 0.523    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 40800    |
| policy_entropy     | 0        |
| total_timesteps    | 3264000  |
| value_loss         | 1.57     |
---------------------------------
---------------------------------
| avg reward         | -75      |
| explained_variance | -0.449   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 40900    |
| policy_entropy     | 0.00736  |
| total_timesteps    | 3272000  |
| value_loss         | 288      |
---------------------------------
---------------------------------
| avg reward         | 28.2     |
| explained_variance | 0.103    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41000    |
| policy_entropy     | 0        |
| total_timesteps    | 3280000  |
| value_loss         | 27.1     |
---------------------------------
---------------------------------
| avg reward         | 59.4     |
| explained_variance | -0.401   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41100    |
| policy_entropy     | 0.0371   |
| total_timesteps    | 3288000  |
| value_loss         | 168      |
---------------------------------
---------------------------------
| avg reward         | -169     |
| explained_variance | -0.0262  |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41200    |
| policy_entropy     | 0        |
| total_timesteps    | 3296000  |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| avg reward         | -29.5    |
| explained_variance | -0.143   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41300    |
| policy_entropy     | 8.57e-24 |
| total_timesteps    | 3304000  |
| value_loss         | 34.7     |
---------------------------------
---------------------------------
| avg reward         | 25.8     |
| explained_variance | -5.62    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41400    |
| policy_entropy     | 2.68e-14 |
| total_timesteps    | 3312000  |
| value_loss         | 5.09     |
---------------------------------
---------------------------------
| avg reward         | 90.2     |
| explained_variance | 0.506    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41500    |
| policy_entropy     | 0        |
| total_timesteps    | 3320000  |
| value_loss         | 4.25     |
---------------------------------
---------------------------------
| avg reward         | -141     |
| explained_variance | 0.231    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 41600    |
| policy_entropy     | 0        |
| total_timesteps    | 3328000  |
| value_loss         | 13.4     |
---------------------------------
---------------------------------
| avg reward         | -45.7    |
| explained_variance | -49.3    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41700    |
| policy_entropy     | 0        |
| total_timesteps    | 3336000  |
| value_loss         | 30.7     |
---------------------------------
---------------------------------
| avg reward         | -240     |
| explained_variance | -1.22    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41800    |
| policy_entropy     | 0        |
| total_timesteps    | 3344000  |
| value_loss         | 1.68e+03 |
---------------------------------
---------------------------------
| avg reward         | 91.7     |
| explained_variance | 0.528    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 41900    |
| policy_entropy     | 0        |
| total_timesteps    | 3352000  |
| value_loss         | 4.64     |
---------------------------------
---------------------------------
| avg reward         | -115     |
| explained_variance | -0.803   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42000    |
| policy_entropy     | 0        |
| total_timesteps    | 3360000  |
| value_loss         | 933      |
---------------------------------
---------------------------------
| avg reward         | -144     |
| explained_variance | 0.168    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42100    |
| policy_entropy     | 0        |
| total_timesteps    | 3368000  |
| value_loss         | 12.1     |
---------------------------------
---------------------------------
| avg reward         | -34.4    |
| explained_variance | 0.426    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42200    |
| policy_entropy     | 0        |
| total_timesteps    | 3376000  |
| value_loss         | 0.943    |
---------------------------------
---------------------------------
| avg reward         | -105     |
| explained_variance | -0.309   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42300    |
| policy_entropy     | 0        |
| total_timesteps    | 3384000  |
| value_loss         | 517      |
---------------------------------
---------------------------------
| avg reward         | 94       |
| explained_variance | 0.337    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42400    |
| policy_entropy     | 0        |
| total_timesteps    | 3392000  |
| value_loss         | 5.01     |
---------------------------------
---------------------------------
| avg reward         | -67.6    |
| explained_variance | 0.243    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42500    |
| policy_entropy     | 0        |
| total_timesteps    | 3400000  |
| value_loss         | 3.04     |
---------------------------------
---------------------------------
| avg reward         | 33.1     |
| explained_variance | 0.289    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42600    |
| policy_entropy     | 0        |
| total_timesteps    | 3408000  |
| value_loss         | 0.505    |
---------------------------------
---------------------------------
| avg reward         | 63.8     |
| explained_variance | 0.448    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42700    |
| policy_entropy     | 0        |
| total_timesteps    | 3416000  |
| value_loss         | 2.31     |
---------------------------------
---------------------------------
| avg reward         | 60.9     |
| explained_variance | 0.444    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42800    |
| policy_entropy     | 0        |
| total_timesteps    | 3424000  |
| value_loss         | 2.21     |
---------------------------------
---------------------------------
| avg reward         | -40.1    |
| explained_variance | 0.0225   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 42900    |
| policy_entropy     | 0        |
| total_timesteps    | 3432000  |
| value_loss         | 61       |
---------------------------------
---------------------------------
| avg reward         | -22.9    |
| explained_variance | 0.238    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 43000    |
| policy_entropy     | 0        |
| total_timesteps    | 3440000  |
| value_loss         | 0.655    |
---------------------------------
---------------------------------
| avg reward         | 53.6     |
| explained_variance | 0.537    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 43100    |
| policy_entropy     | 0        |
| total_timesteps    | 3448000  |
| value_loss         | 1.56     |
---------------------------------
---------------------------------
| avg reward         | 24       |
| explained_variance | -17.4    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 43200    |
| policy_entropy     | 0.0094   |
| total_timesteps    | 3456000  |
| value_loss         | 6.74     |
---------------------------------
---------------------------------
| avg reward         | -54.4    |
| explained_variance | -0.0028  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43300    |
| policy_entropy     | 0        |
| total_timesteps    | 3464000  |
| value_loss         | 115      |
---------------------------------
---------------------------------
| avg reward         | -89.1    |
| explained_variance | -3.08    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43400    |
| policy_entropy     | 0.0219   |
| total_timesteps    | 3472000  |
| value_loss         | 210      |
---------------------------------
---------------------------------
| avg reward         | -29.3    |
| explained_variance | -48.3    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43500    |
| policy_entropy     | 0.00941  |
| total_timesteps    | 3480000  |
| value_loss         | 11.7     |
---------------------------------
---------------------------------
| avg reward         | -89.3    |
| explained_variance | -40      |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43600    |
| policy_entropy     | 0        |
| total_timesteps    | 3488000  |
| value_loss         | 48.3     |
---------------------------------
---------------------------------
| avg reward         | -30.2    |
| explained_variance | -0.0248  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43700    |
| policy_entropy     | 0        |
| total_timesteps    | 3496000  |
| value_loss         | 36.2     |
---------------------------------
---------------------------------
| avg reward         | -11.2    |
| explained_variance | -0.0807  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43800    |
| policy_entropy     | 0        |
| total_timesteps    | 3504000  |
| value_loss         | 5.36     |
---------------------------------
---------------------------------
| avg reward         | 45.8     |
| explained_variance | 0.102    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 43900    |
| policy_entropy     | 0        |
| total_timesteps    | 3512000  |
| value_loss         | 1.37     |
---------------------------------
---------------------------------
| avg reward         | 32.1     |
| explained_variance | -0.287   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44000    |
| policy_entropy     | 0.0491   |
| total_timesteps    | 3520000  |
| value_loss         | 62.8     |
---------------------------------
---------------------------------
| avg reward         | 11.6     |
| explained_variance | -2.29    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44100    |
| policy_entropy     | 0        |
| total_timesteps    | 3528000  |
| value_loss         | 0.782    |
---------------------------------
---------------------------------
| avg reward         | 38.7     |
| explained_variance | -0.203   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44200    |
| policy_entropy     | 0.055    |
| total_timesteps    | 3536000  |
| value_loss         | 151      |
---------------------------------
---------------------------------
| avg reward         | -2.26    |
| explained_variance | 0.53     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44300    |
| policy_entropy     | 0.0264   |
| total_timesteps    | 3544000  |
| value_loss         | 0.352    |
---------------------------------
---------------------------------
| avg reward         | -22.7    |
| explained_variance | -0.0736  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44400    |
| policy_entropy     | 0        |
| total_timesteps    | 3552000  |
| value_loss         | 0.653    |
---------------------------------
---------------------------------
| avg reward         | -32.2    |
| explained_variance | -21.5    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44500    |
| policy_entropy     | 0.00959  |
| total_timesteps    | 3560000  |
| value_loss         | 8.03     |
---------------------------------
---------------------------------
| avg reward         | -53.2    |
| explained_variance | -132     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44600    |
| policy_entropy     | 0.0356   |
| total_timesteps    | 3568000  |
| value_loss         | 56.6     |
---------------------------------
---------------------------------
| avg reward         | 27.7     |
| explained_variance | 0.274    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44700    |
| policy_entropy     | 0        |
| total_timesteps    | 3576000  |
| value_loss         | 0.417    |
---------------------------------
---------------------------------
| avg reward         | -14.8    |
| explained_variance | 0.0388   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44800    |
| policy_entropy     | 0        |
| total_timesteps    | 3584000  |
| value_loss         | 0.408    |
---------------------------------
---------------------------------
| avg reward         | -15.9    |
| explained_variance | -8.18    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 44900    |
| policy_entropy     | 8.11e-23 |
| total_timesteps    | 3592000  |
| value_loss         | 1.94     |
---------------------------------
---------------------------------
| avg reward         | 59       |
| explained_variance | 0.494    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45000    |
| policy_entropy     | 0        |
| total_timesteps    | 3600000  |
| value_loss         | 1.82     |
---------------------------------
---------------------------------
| avg reward         | -6.81    |
| explained_variance | 0.188    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45100    |
| policy_entropy     | 0.0159   |
| total_timesteps    | 3608000  |
| value_loss         | 1.82     |
---------------------------------
---------------------------------
| avg reward         | 20.4     |
| explained_variance | -1.24    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45200    |
| policy_entropy     | 0.0334   |
| total_timesteps    | 3616000  |
| value_loss         | 12.9     |
---------------------------------
---------------------------------
| avg reward         | -27.7    |
| explained_variance | 0.358    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45300    |
| policy_entropy     | 0        |
| total_timesteps    | 3624000  |
| value_loss         | 0.843    |
---------------------------------
---------------------------------
| avg reward         | -46.6    |
| explained_variance | -1.73    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45400    |
| policy_entropy     | 0.0249   |
| total_timesteps    | 3632000  |
| value_loss         | 78.1     |
---------------------------------
---------------------------------
| avg reward         | 113      |
| explained_variance | -63.8    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45500    |
| policy_entropy     | 0.0177   |
| total_timesteps    | 3640000  |
| value_loss         | 160      |
---------------------------------
---------------------------------
| avg reward         | 95.9     |
| explained_variance | 0.52     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45600    |
| policy_entropy     | 4.82e-18 |
| total_timesteps    | 3648000  |
| value_loss         | 4.73     |
---------------------------------
---------------------------------
| avg reward         | 51.7     |
| explained_variance | -4.51    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45700    |
| policy_entropy     | 0.0448   |
| total_timesteps    | 3656000  |
| value_loss         | 96.6     |
---------------------------------
---------------------------------
| avg reward         | -88.7    |
| explained_variance | 0.0543   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45800    |
| policy_entropy     | 0        |
| total_timesteps    | 3664000  |
| value_loss         | 5.48     |
---------------------------------
---------------------------------
| avg reward         | -80.8    |
| explained_variance | 0.226    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 45900    |
| policy_entropy     | 0.0166   |
| total_timesteps    | 3672000  |
| value_loss         | 195      |
---------------------------------
---------------------------------
| avg reward         | -25.3    |
| explained_variance | 0.618    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46000    |
| policy_entropy     | 0        |
| total_timesteps    | 3680000  |
| value_loss         | 0.533    |
---------------------------------
---------------------------------
| avg reward         | 35.4     |
| explained_variance | 0.577    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46100    |
| policy_entropy     | 0        |
| total_timesteps    | 3688000  |
| value_loss         | 0.558    |
---------------------------------
---------------------------------
| avg reward         | -15.8    |
| explained_variance | -31.7    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46200    |
| policy_entropy     | 0.0208   |
| total_timesteps    | 3696000  |
| value_loss         | 3.9      |
---------------------------------
---------------------------------
| avg reward         | -63.9    |
| explained_variance | 0.404    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46300    |
| policy_entropy     | 0.027    |
| total_timesteps    | 3704000  |
| value_loss         | 96.9     |
---------------------------------
---------------------------------
| avg reward         | 64.1     |
| explained_variance | -0.258   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46400    |
| policy_entropy     | 0.0626   |
| total_timesteps    | 3712000  |
| value_loss         | 251      |
---------------------------------
---------------------------------
| avg reward         | -29.3    |
| explained_variance | 0.208    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46500    |
| policy_entropy     | 0        |
| total_timesteps    | 3720000  |
| value_loss         | 0.789    |
---------------------------------
---------------------------------
| avg reward         | 28.6     |
| explained_variance | 0.809    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46600    |
| policy_entropy     | 0        |
| total_timesteps    | 3728000  |
| value_loss         | 0.499    |
---------------------------------
---------------------------------
| avg reward         | 36.1     |
| explained_variance | 0.706    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46700    |
| policy_entropy     | 0        |
| total_timesteps    | 3736000  |
| value_loss         | 0.678    |
---------------------------------
---------------------------------
| avg reward         | 12.8     |
| explained_variance | 0.0432   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46800    |
| policy_entropy     | 0        |
| total_timesteps    | 3744000  |
| value_loss         | 6.23     |
---------------------------------
---------------------------------
| avg reward         | 68.7     |
| explained_variance | -99.3    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 46900    |
| policy_entropy     | 0.0507   |
| total_timesteps    | 3752000  |
| value_loss         | 111      |
---------------------------------
---------------------------------
| avg reward         | 35.1     |
| explained_variance | 0.403    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47000    |
| policy_entropy     | 0.0301   |
| total_timesteps    | 3760000  |
| value_loss         | 26.3     |
---------------------------------
---------------------------------
| avg reward         | 24.6     |
| explained_variance | 0.624    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47100    |
| policy_entropy     | 0        |
| total_timesteps    | 3768000  |
| value_loss         | 0.471    |
---------------------------------
---------------------------------
| avg reward         | -150     |
| explained_variance | -106     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47200    |
| policy_entropy     | 1.58e-16 |
| total_timesteps    | 3776000  |
| value_loss         | 380      |
---------------------------------
---------------------------------
| avg reward         | -59.7    |
| explained_variance | 0.0783   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47300    |
| policy_entropy     | 1.47e-07 |
| total_timesteps    | 3784000  |
| value_loss         | 232      |
---------------------------------
---------------------------------
| avg reward         | -15.8    |
| explained_variance | 0.623    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47400    |
| policy_entropy     | 0        |
| total_timesteps    | 3792000  |
| value_loss         | 0.368    |
---------------------------------
---------------------------------
| avg reward         | 85       |
| explained_variance | 0.412    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47500    |
| policy_entropy     | 0        |
| total_timesteps    | 3800000  |
| value_loss         | 3.62     |
---------------------------------
---------------------------------
| avg reward         | 117      |
| explained_variance | 0.33     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47600    |
| policy_entropy     | 0        |
| total_timesteps    | 3808000  |
| value_loss         | 7.45     |
---------------------------------
---------------------------------
| avg reward         | -67.8    |
| explained_variance | -3.04    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47700    |
| policy_entropy     | 0.0307   |
| total_timesteps    | 3816000  |
| value_loss         | 121      |
---------------------------------
---------------------------------
| avg reward         | -57.5    |
| explained_variance | 0.209    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47800    |
| policy_entropy     | 0        |
| total_timesteps    | 3824000  |
| value_loss         | 2.28     |
---------------------------------
---------------------------------
| avg reward         | -69.9    |
| explained_variance | -0.114   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 47900    |
| policy_entropy     | 0        |
| total_timesteps    | 3832000  |
| value_loss         | 3.83     |
---------------------------------
---------------------------------
| avg reward         | 172      |
| explained_variance | 0.27     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48000    |
| policy_entropy     | 0        |
| total_timesteps    | 3840000  |
| value_loss         | 17       |
---------------------------------
---------------------------------
| avg reward         | 16.2     |
| explained_variance | -0.587   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48100    |
| policy_entropy     | 0.0302   |
| total_timesteps    | 3848000  |
| value_loss         | 6.91     |
---------------------------------
---------------------------------
| avg reward         | 114      |
| explained_variance | 0.649    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48200    |
| policy_entropy     | 0        |
| total_timesteps    | 3856000  |
| value_loss         | 6.58     |
---------------------------------
---------------------------------
| avg reward         | 192      |
| explained_variance | -1.5     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48300    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 3864000  |
| value_loss         | 1.21e+03 |
---------------------------------
---------------------------------
| avg reward         | -133     |
| explained_variance | 0.428    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48400    |
| policy_entropy     | 0        |
| total_timesteps    | 3872000  |
| value_loss         | 11.5     |
---------------------------------
---------------------------------
| avg reward         | 30.5     |
| explained_variance | -3.81    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48500    |
| policy_entropy     | 2.11e-23 |
| total_timesteps    | 3880000  |
| value_loss         | 5.08     |
---------------------------------
---------------------------------
| avg reward         | 41.9     |
| explained_variance | 0.674    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48600    |
| policy_entropy     | 0        |
| total_timesteps    | 3888000  |
| value_loss         | 1.2      |
---------------------------------
---------------------------------
| avg reward         | -113     |
| explained_variance | 0.209    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48700    |
| policy_entropy     | 0.016    |
| total_timesteps    | 3896000  |
| value_loss         | 393      |
---------------------------------
---------------------------------
| avg reward         | 193      |
| explained_variance | 0.273    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48800    |
| policy_entropy     | 0.0305   |
| total_timesteps    | 3904000  |
| value_loss         | 844      |
---------------------------------
---------------------------------
| avg reward         | 202      |
| explained_variance | 0.488    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 48900    |
| policy_entropy     | 0        |
| total_timesteps    | 3912000  |
| value_loss         | 24.2     |
---------------------------------
---------------------------------
| avg reward         | -118     |
| explained_variance | 0.0118   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49000    |
| policy_entropy     | 0        |
| total_timesteps    | 3920000  |
| value_loss         | 9.7      |
---------------------------------
---------------------------------
| avg reward         | -233     |
| explained_variance | 0.169    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49100    |
| policy_entropy     | 0        |
| total_timesteps    | 3928000  |
| value_loss         | 31.1     |
---------------------------------
---------------------------------
| avg reward         | 155      |
| explained_variance | -2.67    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49200    |
| policy_entropy     | 0.0293   |
| total_timesteps    | 3936000  |
| value_loss         | 573      |
---------------------------------
---------------------------------
| avg reward         | -264     |
| explained_variance | -2.75    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49300    |
| policy_entropy     | 0.0211   |
| total_timesteps    | 3944000  |
| value_loss         | 1.69e+03 |
---------------------------------
---------------------------------
| avg reward         | 214      |
| explained_variance | -0.383   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49400    |
| policy_entropy     | 0.0564   |
| total_timesteps    | 3952000  |
| value_loss         | 2.3e+03  |
---------------------------------
---------------------------------
| avg reward         | 282      |
| explained_variance | -67.3    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49500    |
| policy_entropy     | 0.0102   |
| total_timesteps    | 3960000  |
| value_loss         | 888      |
---------------------------------
---------------------------------
| avg reward         | -80      |
| explained_variance | 0.0791   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 49600    |
| policy_entropy     | 0        |
| total_timesteps    | 3968000  |
| value_loss         | 4.53     |
---------------------------------
---------------------------------
| avg reward         | -196     |
| explained_variance | 0.044    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 49700    |
| policy_entropy     | 0        |
| total_timesteps    | 3976000  |
| value_loss         | 1.42e+03 |
---------------------------------
---------------------------------
| avg reward         | -102     |
| explained_variance | -2.94    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 49800    |
| policy_entropy     | 0.0253   |
| total_timesteps    | 3984000  |
| value_loss         | 266      |
---------------------------------
---------------------------------
| avg reward         | -48.2    |
| explained_variance | -2.92    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 49900    |
| policy_entropy     | 0.0259   |
| total_timesteps    | 3992000  |
| value_loss         | 61.2     |
---------------------------------
---------------------------------
| avg reward         | -128     |
| explained_variance | 0.222    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 50000    |
| policy_entropy     | 0.0123   |
| total_timesteps    | 4000000  |
| value_loss         | 491      |
---------------------------------
---------------------------------
| avg reward         | -73      |
| explained_variance | 0.463    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 50100    |
| policy_entropy     | 0        |
| total_timesteps    | 4008000  |
| value_loss         | 2.94     |
---------------------------------
---------------------------------
| avg reward         | -179     |
| explained_variance | 0.0789   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 50200    |
| policy_entropy     | 0        |
| total_timesteps    | 4016000  |
| value_loss         | 19.4     |
---------------------------------
---------------------------------
| avg reward         | 152      |
| explained_variance | -2.87    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 50300    |
| policy_entropy     | 0.0258   |
| total_timesteps    | 4024000  |
| value_loss         | 588      |
---------------------------------
---------------------------------
| avg reward         | 48.5     |
| explained_variance | 0.836    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 50400    |
| policy_entropy     | 0        |
| total_timesteps    | 4032000  |
| value_loss         | 1.41     |
---------------------------------
---------------------------------
| avg reward         | -196     |
| explained_variance | 0.11     |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 50500    |
| policy_entropy     | 0        |
| total_timesteps    | 4040000  |
| value_loss         | 23.5     |
---------------------------------
---------------------------------
| avg reward         | -246     |
| explained_variance | 0.167    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 50600    |
| policy_entropy     | 0        |
| total_timesteps    | 4048000  |
| value_loss         | 37.3     |
---------------------------------
---------------------------------
| avg reward         | -308     |
| explained_variance | -0.556   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 50700    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 4056000  |
| value_loss         | 6.27e+03 |
---------------------------------
---------------------------------
| avg reward         | 147      |
| explained_variance | 0.465    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 50800    |
| policy_entropy     | 0        |
| total_timesteps    | 4064000  |
| value_loss         | 11.9     |
---------------------------------
---------------------------------
| avg reward         | -219     |
| explained_variance | 0.235    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 50900    |
| policy_entropy     | 0.0176   |
| total_timesteps    | 4072000  |
| value_loss         | 1.4e+03  |
---------------------------------
---------------------------------
| avg reward         | -36.9    |
| explained_variance | -11.6    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 51000    |
| policy_entropy     | 0.0296   |
| total_timesteps    | 4080000  |
| value_loss         | 21.8     |
---------------------------------
---------------------------------
| avg reward         | -247     |
| explained_variance | -70      |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 51100    |
| policy_entropy     | 0        |
| total_timesteps    | 4088000  |
| value_loss         | 526      |
---------------------------------
---------------------------------
| avg reward         | 97.1     |
| explained_variance | 0.654    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 51200    |
| policy_entropy     | 0        |
| total_timesteps    | 4096000  |
| value_loss         | 5.91     |
---------------------------------
---------------------------------
| avg reward         | 87.3     |
| explained_variance | 0.161    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 51300    |
| policy_entropy     | 0.0176   |
| total_timesteps    | 4104000  |
| value_loss         | 482      |
---------------------------------
---------------------------------
| avg reward         | 56.7     |
| explained_variance | 0.711    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 51400    |
| policy_entropy     | 0        |
| total_timesteps    | 4112000  |
| value_loss         | 3.27     |
---------------------------------
---------------------------------
| avg reward         | 72.7     |
| explained_variance | 0.63     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 51500    |
| policy_entropy     | 0        |
| total_timesteps    | 4120000  |
| value_loss         | 3.37     |
---------------------------------
---------------------------------
| avg reward         | -44      |
| explained_variance | 0.276    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 51600    |
| policy_entropy     | 0.0174   |
| total_timesteps    | 4128000  |
| value_loss         | 57       |
---------------------------------
---------------------------------
| avg reward         | -250     |
| explained_variance | -0.5     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 51700    |
| policy_entropy     | 0.0257   |
| total_timesteps    | 4136000  |
| value_loss         | 4.75e+03 |
---------------------------------
---------------------------------
| avg reward         | 155      |
| explained_variance | -0.451   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 51800    |
| policy_entropy     | 0.0273   |
| total_timesteps    | 4144000  |
| value_loss         | 1.78e+03 |
---------------------------------
---------------------------------
| avg reward         | -295     |
| explained_variance | 0.345    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 51900    |
| policy_entropy     | 0.0242   |
| total_timesteps    | 4152000  |
| value_loss         | 1.96e+03 |
---------------------------------
---------------------------------
| avg reward         | -267     |
| explained_variance | -102     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 52000    |
| policy_entropy     | 0.0245   |
| total_timesteps    | 4160000  |
| value_loss         | 1.3e+03  |
---------------------------------
---------------------------------
| avg reward         | -114     |
| explained_variance | 0.259    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 52100    |
| policy_entropy     | 0        |
| total_timesteps    | 4168000  |
| value_loss         | 8.29     |
---------------------------------
---------------------------------
| avg reward         | -314     |
| explained_variance | 0.192    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 52200    |
| policy_entropy     | 0        |
| total_timesteps    | 4176000  |
| value_loss         | 55.3     |
---------------------------------
---------------------------------
| avg reward         | -163     |
| explained_variance | -107     |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 52300    |
| policy_entropy     | 0.0092   |
| total_timesteps    | 4184000  |
| value_loss         | 432      |
---------------------------------
---------------------------------
| avg reward         | 318      |
| explained_variance | 0.414    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 52400    |
| policy_entropy     | 0        |
| total_timesteps    | 4192000  |
| value_loss         | 63.8     |
---------------------------------
---------------------------------
| avg reward         | -186     |
| explained_variance | -3.17    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 52500    |
| policy_entropy     | 0.0147   |
| total_timesteps    | 4200000  |
| value_loss         | 931      |
---------------------------------
---------------------------------
| avg reward         | 164      |
| explained_variance | 0.472    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 52600    |
| policy_entropy     | 0        |
| total_timesteps    | 4208000  |
| value_loss         | 16.2     |
---------------------------------
---------------------------------
| avg reward         | 160      |
| explained_variance | 0.366    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 52700    |
| policy_entropy     | 0        |
| total_timesteps    | 4216000  |
| value_loss         | 14.7     |
---------------------------------
---------------------------------
| avg reward         | 224      |
| explained_variance | 0.569    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 52800    |
| policy_entropy     | 0        |
| total_timesteps    | 4224000  |
| value_loss         | 32.9     |
---------------------------------
---------------------------------
| avg reward         | 106      |
| explained_variance | -0.854   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 52900    |
| policy_entropy     | 0.0449   |
| total_timesteps    | 4232000  |
| value_loss         | 1.19e+03 |
---------------------------------
---------------------------------
| avg reward         | 319      |
| explained_variance | 0.503    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53000    |
| policy_entropy     | 0        |
| total_timesteps    | 4240000  |
| value_loss         | 57.8     |
---------------------------------
---------------------------------
| avg reward         | 189      |
| explained_variance | -66.9    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53100    |
| policy_entropy     | 0.0254   |
| total_timesteps    | 4248000  |
| value_loss         | 616      |
---------------------------------
---------------------------------
| avg reward         | -419     |
| explained_variance | -2.77    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53200    |
| policy_entropy     | 0.0275   |
| total_timesteps    | 4256000  |
| value_loss         | 4.27e+03 |
---------------------------------
---------------------------------
| avg reward         | -377     |
| explained_variance | -2.71    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53300    |
| policy_entropy     | 0.0275   |
| total_timesteps    | 4264000  |
| value_loss         | 3.41e+03 |
---------------------------------
---------------------------------
| avg reward         | 136      |
| explained_variance | -2.45    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53400    |
| policy_entropy     | 0.0254   |
| total_timesteps    | 4272000  |
| value_loss         | 439      |
---------------------------------
---------------------------------
| avg reward         | 97.1     |
| explained_variance | -0.231   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53500    |
| policy_entropy     | 0.0534   |
| total_timesteps    | 4280000  |
| value_loss         | 425      |
---------------------------------
---------------------------------
| avg reward         | 229      |
| explained_variance | 0.677    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53600    |
| policy_entropy     | 0        |
| total_timesteps    | 4288000  |
| value_loss         | 27.4     |
---------------------------------
---------------------------------
| avg reward         | 13.1     |
| explained_variance | -0.17    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53700    |
| policy_entropy     | 0        |
| total_timesteps    | 4296000  |
| value_loss         | 2.13     |
---------------------------------
---------------------------------
| avg reward         | -364     |
| explained_variance | 0.238    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53800    |
| policy_entropy     | 0        |
| total_timesteps    | 4304000  |
| value_loss         | 72.1     |
---------------------------------
---------------------------------
| avg reward         | 222      |
| explained_variance | -0.367   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 53900    |
| policy_entropy     | 0.0556   |
| total_timesteps    | 4312000  |
| value_loss         | 2.43e+03 |
---------------------------------
---------------------------------
| avg reward         | 232      |
| explained_variance | -44.1    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54000    |
| policy_entropy     | 0.0104   |
| total_timesteps    | 4320000  |
| value_loss         | 582      |
---------------------------------
---------------------------------
| avg reward         | -441     |
| explained_variance | 0.165    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54100    |
| policy_entropy     | 0        |
| total_timesteps    | 4328000  |
| value_loss         | 110      |
---------------------------------
---------------------------------
| avg reward         | 282      |
| explained_variance | 0.388    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54200    |
| policy_entropy     | 0.02     |
| total_timesteps    | 4336000  |
| value_loss         | 1.74e+03 |
---------------------------------
---------------------------------
| avg reward         | -269     |
| explained_variance | -0.407   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54300    |
| policy_entropy     | 0.0377   |
| total_timesteps    | 4344000  |
| value_loss         | 4.29e+03 |
---------------------------------
---------------------------------
| avg reward         | -123     |
| explained_variance | 0.259    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54400    |
| policy_entropy     | 0.0392   |
| total_timesteps    | 4352000  |
| value_loss         | 917      |
---------------------------------
---------------------------------
| avg reward         | 89.4     |
| explained_variance | 0.0906   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54500    |
| policy_entropy     | 0.0154   |
| total_timesteps    | 4360000  |
| value_loss         | 601      |
---------------------------------
---------------------------------
| avg reward         | -77.1    |
| explained_variance | -23.2    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54600    |
| policy_entropy     | 0.0288   |
| total_timesteps    | 4368000  |
| value_loss         | 104      |
---------------------------------
---------------------------------
| avg reward         | 285      |
| explained_variance | 0.584    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54700    |
| policy_entropy     | 0        |
| total_timesteps    | 4376000  |
| value_loss         | 40.1     |
---------------------------------
---------------------------------
| avg reward         | 422      |
| explained_variance | 0.0181   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 54800    |
| policy_entropy     | 0        |
| total_timesteps    | 4384000  |
| value_loss         | 6.71e+03 |
---------------------------------
---------------------------------
| avg reward         | -492     |
| explained_variance | -1.37    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 54900    |
| policy_entropy     | 2.15e-05 |
| total_timesteps    | 4392000  |
| value_loss         | 1.52e+04 |
---------------------------------
---------------------------------
| avg reward         | 427      |
| explained_variance | -12.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55000    |
| policy_entropy     | 0        |
| total_timesteps    | 4400000  |
| value_loss         | 591      |
---------------------------------
---------------------------------
| avg reward         | -394     |
| explained_variance | 0.317    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55100    |
| policy_entropy     | 0        |
| total_timesteps    | 4408000  |
| value_loss         | 97.1     |
---------------------------------
---------------------------------
| avg reward         | -467     |
| explained_variance | -75.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55200    |
| policy_entropy     | 0        |
| total_timesteps    | 4416000  |
| value_loss         | 2.19e+03 |
---------------------------------
---------------------------------
| avg reward         | 171      |
| explained_variance | 0.247    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55300    |
| policy_entropy     | 0        |
| total_timesteps    | 4424000  |
| value_loss         | 796      |
---------------------------------
---------------------------------
| avg reward         | -327     |
| explained_variance | -77.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55400    |
| policy_entropy     | 0        |
| total_timesteps    | 4432000  |
| value_loss         | 1.27e+03 |
---------------------------------
---------------------------------
| avg reward         | -533     |
| explained_variance | -3.48    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55500    |
| policy_entropy     | 0        |
| total_timesteps    | 4440000  |
| value_loss         | 8.25e+03 |
---------------------------------
---------------------------------
| avg reward         | -47.7    |
| explained_variance | -0.39    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55600    |
| policy_entropy     | 0        |
| total_timesteps    | 4448000  |
| value_loss         | 53.9     |
---------------------------------
---------------------------------
| avg reward         | 190      |
| explained_variance | 0.202    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55700    |
| policy_entropy     | 0        |
| total_timesteps    | 4456000  |
| value_loss         | 1.03e+03 |
---------------------------------
---------------------------------
| avg reward         | 66.4     |
| explained_variance | -4.4     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 55800    |
| policy_entropy     | 0        |
| total_timesteps    | 4464000  |
| value_loss         | 51.7     |
---------------------------------
---------------------------------
| avg reward         | -508     |
| explained_variance | -1.97    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 55900    |
| policy_entropy     | 0        |
| total_timesteps    | 4472000  |
| value_loss         | 4.97e+03 |
---------------------------------
---------------------------------
| avg reward         | 24       |
| explained_variance | 0.323    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56000    |
| policy_entropy     | 0        |
| total_timesteps    | 4480000  |
| value_loss         | 21.5     |
---------------------------------
---------------------------------
| avg reward         | -332     |
| explained_variance | 0.0655   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56100    |
| policy_entropy     | 0        |
| total_timesteps    | 4488000  |
| value_loss         | 66.3     |
---------------------------------
---------------------------------
| avg reward         | 363      |
| explained_variance | -41.2    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56200    |
| policy_entropy     | 0        |
| total_timesteps    | 4496000  |
| value_loss         | 1.8e+03  |
---------------------------------
---------------------------------
| avg reward         | 51.4     |
| explained_variance | 0.874    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 56300    |
| policy_entropy     | 0        |
| total_timesteps    | 4504000  |
| value_loss         | 2.01     |
---------------------------------
---------------------------------
| avg reward         | 466      |
| explained_variance | -2.41    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56400    |
| policy_entropy     | 0.00806  |
| total_timesteps    | 4512000  |
| value_loss         | 4.84e+03 |
---------------------------------
---------------------------------
| avg reward         | 185      |
| explained_variance | 0.743    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56500    |
| policy_entropy     | 0        |
| total_timesteps    | 4520000  |
| value_loss         | 18.6     |
---------------------------------
---------------------------------
| avg reward         | 624      |
| explained_variance | 0.0243   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56600    |
| policy_entropy     | 0        |
| total_timesteps    | 4528000  |
| value_loss         | 1.47e+04 |
---------------------------------
---------------------------------
| avg reward         | -215     |
| explained_variance | -78.8    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56700    |
| policy_entropy     | 0.0163   |
| total_timesteps    | 4536000  |
| value_loss         | 709      |
---------------------------------
---------------------------------
| avg reward         | 496      |
| explained_variance | 0.365    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 56800    |
| policy_entropy     | 0        |
| total_timesteps    | 4544000  |
| value_loss         | 152      |
---------------------------------
---------------------------------
| avg reward         | -453     |
| explained_variance | -24.6    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 56900    |
| policy_entropy     | 0        |
| total_timesteps    | 4552000  |
| value_loss         | 726      |
---------------------------------
---------------------------------
| avg reward         | -766     |
| explained_variance | 0.00125  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57000    |
| policy_entropy     | 0        |
| total_timesteps    | 4560000  |
| value_loss         | 352      |
---------------------------------
---------------------------------
| avg reward         | 192      |
| explained_variance | -1.84    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57100    |
| policy_entropy     | 1.43e-31 |
| total_timesteps    | 4568000  |
| value_loss         | 743      |
---------------------------------
---------------------------------
| avg reward         | 195      |
| explained_variance | -0.0647  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57200    |
| policy_entropy     | 2.12e-05 |
| total_timesteps    | 4576000  |
| value_loss         | 1.11e+03 |
---------------------------------
---------------------------------
| avg reward         | 737      |
| explained_variance | -0.0888  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57300    |
| policy_entropy     | 0        |
| total_timesteps    | 4584000  |
| value_loss         | 2.2e+04  |
---------------------------------
---------------------------------
| avg reward         | 568      |
| explained_variance | 0.463    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57400    |
| policy_entropy     | 0        |
| total_timesteps    | 4592000  |
| value_loss         | 205      |
---------------------------------
---------------------------------
| avg reward         | 244      |
| explained_variance | 0.246    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57500    |
| policy_entropy     | 2.38e-09 |
| total_timesteps    | 4600000  |
| value_loss         | 1.28e+03 |
---------------------------------
---------------------------------
| avg reward         | 312      |
| explained_variance | 0.0792   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57600    |
| policy_entropy     | 0        |
| total_timesteps    | 4608000  |
| value_loss         | 3.49e+03 |
---------------------------------
---------------------------------
| avg reward         | -309     |
| explained_variance | 0.181    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57700    |
| policy_entropy     | 8.49e-07 |
| total_timesteps    | 4616000  |
| value_loss         | 2.91e+03 |
---------------------------------
---------------------------------
| avg reward         | 453      |
| explained_variance | -2.52    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57800    |
| policy_entropy     | 0.0108   |
| total_timesteps    | 4624000  |
| value_loss         | 9.44e+03 |
---------------------------------
---------------------------------
| avg reward         | 510      |
| explained_variance | 0.222    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 57900    |
| policy_entropy     | 4.01e-12 |
| total_timesteps    | 4632000  |
| value_loss         | 5.88e+03 |
---------------------------------
---------------------------------
| avg reward         | 102      |
| explained_variance | -1.76    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58000    |
| policy_entropy     | 0.000408 |
| total_timesteps    | 4640000  |
| value_loss         | 211      |
---------------------------------
---------------------------------
| avg reward         | 436      |
| explained_variance | -4.58    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58100    |
| policy_entropy     | 6.76e-26 |
| total_timesteps    | 4648000  |
| value_loss         | 7.15e+03 |
---------------------------------
---------------------------------
| avg reward         | 154      |
| explained_variance | 0.691    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58200    |
| policy_entropy     | 0        |
| total_timesteps    | 4656000  |
| value_loss         | 18.1     |
---------------------------------
---------------------------------
| avg reward         | 299      |
| explained_variance | 0.658    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58300    |
| policy_entropy     | 0        |
| total_timesteps    | 4664000  |
| value_loss         | 63.6     |
---------------------------------
---------------------------------
| avg reward         | -368     |
| explained_variance | 0.284    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58400    |
| policy_entropy     | 0        |
| total_timesteps    | 4672000  |
| value_loss         | 81       |
---------------------------------
---------------------------------
| avg reward         | -311     |
| explained_variance | 0.00836  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58500    |
| policy_entropy     | 0        |
| total_timesteps    | 4680000  |
| value_loss         | 3.7e+03  |
---------------------------------
---------------------------------
| avg reward         | -408     |
| explained_variance | 0.18     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58600    |
| policy_entropy     | 0.0056   |
| total_timesteps    | 4688000  |
| value_loss         | 9.92e+03 |
---------------------------------
---------------------------------
| avg reward         | 5.53     |
| explained_variance | 0.749    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58700    |
| policy_entropy     | 0.0258   |
| total_timesteps    | 4696000  |
| value_loss         | 2.55     |
---------------------------------
---------------------------------
| avg reward         | -142     |
| explained_variance | -2.49    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58800    |
| policy_entropy     | 4.24e-11 |
| total_timesteps    | 4704000  |
| value_loss         | 497      |
---------------------------------
---------------------------------
| avg reward         | -527     |
| explained_variance | -2.55    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 58900    |
| policy_entropy     | 0.00111  |
| total_timesteps    | 4712000  |
| value_loss         | 6.38e+03 |
---------------------------------
---------------------------------
| avg reward         | -164     |
| explained_variance | 0.0433   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59000    |
| policy_entropy     | 0        |
| total_timesteps    | 4720000  |
| value_loss         | 996      |
---------------------------------
---------------------------------
| avg reward         | 645      |
| explained_variance | 0.0381   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59100    |
| policy_entropy     | 0        |
| total_timesteps    | 4728000  |
| value_loss         | 1.55e+04 |
---------------------------------
---------------------------------
| avg reward         | -148     |
| explained_variance | 0.53     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59200    |
| policy_entropy     | 0        |
| total_timesteps    | 4736000  |
| value_loss         | 15.9     |
---------------------------------
---------------------------------
| avg reward         | -566     |
| explained_variance | 0.192    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59300    |
| policy_entropy     | 0        |
| total_timesteps    | 4744000  |
| value_loss         | 182      |
---------------------------------
---------------------------------
| avg reward         | -550     |
| explained_variance | 0.107    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59400    |
| policy_entropy     | 0        |
| total_timesteps    | 4752000  |
| value_loss         | 168      |
---------------------------------
---------------------------------
| avg reward         | -548     |
| explained_variance | 0.396    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59500    |
| policy_entropy     | 0        |
| total_timesteps    | 4760000  |
| value_loss         | 169      |
---------------------------------
---------------------------------
| avg reward         | -356     |
| explained_variance | 0.106    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59600    |
| policy_entropy     | 0.0412   |
| total_timesteps    | 4768000  |
| value_loss         | 1.51e+04 |
---------------------------------
---------------------------------
| avg reward         | 687      |
| explained_variance | 0.0429   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59700    |
| policy_entropy     | 0        |
| total_timesteps    | 4776000  |
| value_loss         | 1.75e+04 |
---------------------------------
---------------------------------
| avg reward         | 25.4     |
| explained_variance | 0.144    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59800    |
| policy_entropy     | 0.0158   |
| total_timesteps    | 4784000  |
| value_loss         | 10.5     |
---------------------------------
---------------------------------
| avg reward         | 293      |
| explained_variance | 0.73     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 59900    |
| policy_entropy     | 0        |
| total_timesteps    | 4792000  |
| value_loss         | 50.6     |
---------------------------------
---------------------------------
| avg reward         | -428     |
| explained_variance | 0.234    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 60000    |
| policy_entropy     | 0        |
| total_timesteps    | 4800000  |
| value_loss         | 103      |
---------------------------------
---------------------------------
| avg reward         | 194      |
| explained_variance | 0.818    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 60100    |
| policy_entropy     | 0        |
| total_timesteps    | 4808000  |
| value_loss         | 22.9     |
---------------------------------
---------------------------------
| avg reward         | 533      |
| explained_variance | 0.587    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 60200    |
| policy_entropy     | 0        |
| total_timesteps    | 4816000  |
| value_loss         | 181      |
---------------------------------
---------------------------------
| avg reward         | 130      |
| explained_variance | 0.781    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 60300    |
| policy_entropy     | 0        |
| total_timesteps    | 4824000  |
| value_loss         | 11.5     |
---------------------------------
---------------------------------
| avg reward         | 648      |
| explained_variance | -2.51    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 60400    |
| policy_entropy     | 0.0154   |
| total_timesteps    | 4832000  |
| value_loss         | 9.7e+03  |
---------------------------------
---------------------------------
| avg reward         | -656     |
| explained_variance | 0.118    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 60500    |
| policy_entropy     | 0        |
| total_timesteps    | 4840000  |
| value_loss         | 258      |
---------------------------------
---------------------------------
| avg reward         | -473     |
| explained_variance | -0.172   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 60600    |
| policy_entropy     | 0.0342   |
| total_timesteps    | 4848000  |
| value_loss         | 7.74e+03 |
---------------------------------
---------------------------------
| avg reward         | 385      |
| explained_variance | 0.413    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 60700    |
| policy_entropy     | 0        |
| total_timesteps    | 4856000  |
| value_loss         | 97.3     |
---------------------------------
---------------------------------
| avg reward         | -493     |
| explained_variance | -32.6    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 60800    |
| policy_entropy     | 0        |
| total_timesteps    | 4864000  |
| value_loss         | 1.16e+03 |
---------------------------------
---------------------------------
| avg reward         | -121     |
| explained_variance | 0.776    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 60900    |
| policy_entropy     | 0        |
| total_timesteps    | 4872000  |
| value_loss         | 8.81     |
---------------------------------
---------------------------------
| avg reward         | 127      |
| explained_variance | -2.32    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61000    |
| policy_entropy     | 0.0214   |
| total_timesteps    | 4880000  |
| value_loss         | 413      |
---------------------------------
---------------------------------
| avg reward         | -141     |
| explained_variance | -24.2    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61100    |
| policy_entropy     | 0.0251   |
| total_timesteps    | 4888000  |
| value_loss         | 330      |
---------------------------------
---------------------------------
| avg reward         | -510     |
| explained_variance | 0.239    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61200    |
| policy_entropy     | 0.0137   |
| total_timesteps    | 4896000  |
| value_loss         | 7.56e+03 |
---------------------------------
---------------------------------
| avg reward         | -623     |
| explained_variance | 0.235    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61300    |
| policy_entropy     | 0        |
| total_timesteps    | 4904000  |
| value_loss         | 229      |
---------------------------------
---------------------------------
| avg reward         | -538     |
| explained_variance | -0.164   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 61400    |
| policy_entropy     | 0.0361   |
| total_timesteps    | 4912000  |
| value_loss         | 1e+04    |
---------------------------------
---------------------------------
| avg reward         | -594     |
| explained_variance | 0.0176   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 61500    |
| policy_entropy     | 0        |
| total_timesteps    | 4920000  |
| value_loss         | 1.33e+04 |
---------------------------------
---------------------------------
| avg reward         | 17.6     |
| explained_variance | 0.53     |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61600    |
| policy_entropy     | 0.0336   |
| total_timesteps    | 4928000  |
| value_loss         | 12.4     |
---------------------------------
---------------------------------
| avg reward         | 350      |
| explained_variance | 0.574    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61700    |
| policy_entropy     | 0        |
| total_timesteps    | 4936000  |
| value_loss         | 70.3     |
---------------------------------
---------------------------------
| avg reward         | 438      |
| explained_variance | -13      |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61800    |
| policy_entropy     | 0        |
| total_timesteps    | 4944000  |
| value_loss         | 916      |
---------------------------------
---------------------------------
| avg reward         | 55.7     |
| explained_variance | -0.681   |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 61900    |
| policy_entropy     | 0.0659   |
| total_timesteps    | 4952000  |
| value_loss         | 198      |
---------------------------------
---------------------------------
| avg reward         | 949      |
| explained_variance | 0.441    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 62000    |
| policy_entropy     | 0        |
| total_timesteps    | 4960000  |
| value_loss         | 528      |
---------------------------------
---------------------------------
| avg reward         | 840      |
| explained_variance | 0.398    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 62100    |
| policy_entropy     | 0        |
| total_timesteps    | 4968000  |
| value_loss         | 430      |
---------------------------------
---------------------------------
| avg reward         | -303     |
| explained_variance | -46.2    |
| fps                | 2002     |
| learning rate      | 0.001    |
| nupdates           | 62200    |
| policy_entropy     | 0.00906  |
| total_timesteps    | 4976000  |
| value_loss         | 953      |
---------------------------------
---------------------------------
| avg reward         | -320     |
| explained_variance | 0.277    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62300    |
| policy_entropy     | 0.0222   |
| total_timesteps    | 4984000  |
| value_loss         | 2.38e+03 |
---------------------------------
---------------------------------
| avg reward         | 348      |
| explained_variance | 0.465    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62400    |
| policy_entropy     | 0        |
| total_timesteps    | 4992000  |
| value_loss         | 88.1     |
---------------------------------
---------------------------------
| avg reward         | -413     |
| explained_variance | 0.235    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62500    |
| policy_entropy     | 0        |
| total_timesteps    | 5000000  |
| value_loss         | 102      |
---------------------------------
---------------------------------
| avg reward         | -809     |
| explained_variance | -181     |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62600    |
| policy_entropy     | 0.0186   |
| total_timesteps    | 5008000  |
| value_loss         | 1.37e+04 |
---------------------------------
---------------------------------
| avg reward         | -648     |
| explained_variance | -0.138   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62700    |
| policy_entropy     | 0.0289   |
| total_timesteps    | 5016000  |
| value_loss         | 1.45e+04 |
---------------------------------
---------------------------------
| avg reward         | -38.3    |
| explained_variance | -1.25    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62800    |
| policy_entropy     | 0.0196   |
| total_timesteps    | 5024000  |
| value_loss         | 27       |
---------------------------------
---------------------------------
| avg reward         | 174      |
| explained_variance | -1.52    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 62900    |
| policy_entropy     | 0.0146   |
| total_timesteps    | 5032000  |
| value_loss         | 1.07e+03 |
---------------------------------
---------------------------------
| avg reward         | 559      |
| explained_variance | 0.489    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63000    |
| policy_entropy     | 0        |
| total_timesteps    | 5040000  |
| value_loss         | 194      |
---------------------------------
---------------------------------
| avg reward         | -813     |
| explained_variance | 0.19     |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63100    |
| policy_entropy     | 0        |
| total_timesteps    | 5048000  |
| value_loss         | 1.55e+04 |
---------------------------------
---------------------------------
| avg reward         | 897      |
| explained_variance | -1.66    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63200    |
| policy_entropy     | 0        |
| total_timesteps    | 5056000  |
| value_loss         | 2.8e+04  |
---------------------------------
---------------------------------
| avg reward         | 636      |
| explained_variance | -1.01    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63300    |
| policy_entropy     | 0        |
| total_timesteps    | 5064000  |
| value_loss         | 1.08e+04 |
---------------------------------
---------------------------------
| avg reward         | -312     |
| explained_variance | 0.137    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63400    |
| policy_entropy     | 0        |
| total_timesteps    | 5072000  |
| value_loss         | 2.33e+03 |
---------------------------------
---------------------------------
| avg reward         | -576     |
| explained_variance | -64.3    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63500    |
| policy_entropy     | 0        |
| total_timesteps    | 5080000  |
| value_loss         | 4.26e+03 |
---------------------------------
---------------------------------
| avg reward         | -803     |
| explained_variance | 0.258    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63600    |
| policy_entropy     | 0        |
| total_timesteps    | 5088000  |
| value_loss         | 349      |
---------------------------------
---------------------------------
| avg reward         | -664     |
| explained_variance | -0.385   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63700    |
| policy_entropy     | 0        |
| total_timesteps    | 5096000  |
| value_loss         | 3.13e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.57e+03 |
| explained_variance | -55.2     |
| fps                | 2003      |
| learning rate      | 0.001     |
| nupdates           | 63800     |
| policy_entropy     | 0         |
| total_timesteps    | 5104000   |
| value_loss         | 1.7e+04   |
----------------------------------
---------------------------------
| avg reward         | 938      |
| explained_variance | -1.16    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 63900    |
| policy_entropy     | 0        |
| total_timesteps    | 5112000  |
| value_loss         | 2.51e+04 |
---------------------------------
---------------------------------
| avg reward         | -728     |
| explained_variance | -2.27    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64000    |
| policy_entropy     | 0        |
| total_timesteps    | 5120000  |
| value_loss         | 1.13e+04 |
---------------------------------
---------------------------------
| avg reward         | 342      |
| explained_variance | 0.815    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64100    |
| policy_entropy     | 0        |
| total_timesteps    | 5128000  |
| value_loss         | 78.2     |
---------------------------------
---------------------------------
| avg reward         | 150      |
| explained_variance | 0.711    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64200    |
| policy_entropy     | 0        |
| total_timesteps    | 5136000  |
| value_loss         | 17.6     |
---------------------------------
---------------------------------
| avg reward         | -685     |
| explained_variance | 0.278    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64300    |
| policy_entropy     | 0        |
| total_timesteps    | 5144000  |
| value_loss         | 249      |
---------------------------------
---------------------------------
| avg reward         | -507     |
| explained_variance | 0.178    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64400    |
| policy_entropy     | 0        |
| total_timesteps    | 5152000  |
| value_loss         | 7.72e+03 |
---------------------------------
---------------------------------
| avg reward         | -565     |
| explained_variance | 0.295    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64500    |
| policy_entropy     | 0        |
| total_timesteps    | 5160000  |
| value_loss         | 202      |
---------------------------------
---------------------------------
| avg reward         | 633      |
| explained_variance | 0.535    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64600    |
| policy_entropy     | 0        |
| total_timesteps    | 5168000  |
| value_loss         | 223      |
---------------------------------
---------------------------------
| avg reward         | 108      |
| explained_variance | -0.107   |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64700    |
| policy_entropy     | 0        |
| total_timesteps    | 5176000  |
| value_loss         | 365      |
---------------------------------
---------------------------------
| avg reward         | -145     |
| explained_variance | -0.0387  |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64800    |
| policy_entropy     | 0        |
| total_timesteps    | 5184000  |
| value_loss         | 888      |
---------------------------------
---------------------------------
| avg reward         | -32.2    |
| explained_variance | 0.939    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 64900    |
| policy_entropy     | 0        |
| total_timesteps    | 5192000  |
| value_loss         | 2.66     |
---------------------------------
---------------------------------
| avg reward         | -358     |
| explained_variance | -0.0152  |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 65000    |
| policy_entropy     | 0        |
| total_timesteps    | 5200000  |
| value_loss         | 4.99e+03 |
---------------------------------
---------------------------------
| avg reward         | -978     |
| explained_variance | 0.114    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 65100    |
| policy_entropy     | 0        |
| total_timesteps    | 5208000  |
| value_loss         | 554      |
---------------------------------
----------------------------------
| avg reward         | -1.25e+03 |
| explained_variance | 0.0942    |
| fps                | 2003      |
| learning rate      | 0.001     |
| nupdates           | 65200     |
| policy_entropy     | 0         |
| total_timesteps    | 5216000   |
| value_loss         | 858       |
----------------------------------
---------------------------------
| avg reward         | -333     |
| explained_variance | -3.23    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 65300    |
| policy_entropy     | 0        |
| total_timesteps    | 5224000  |
| value_loss         | 3.13e+03 |
---------------------------------
---------------------------------
| avg reward         | -172     |
| explained_variance | -5.35    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 65400    |
| policy_entropy     | 0        |
| total_timesteps    | 5232000  |
| value_loss         | 291      |
---------------------------------
---------------------------------
| avg reward         | 657      |
| explained_variance | -14.9    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 65500    |
| policy_entropy     | 0        |
| total_timesteps    | 5240000  |
| value_loss         | 2.69e+03 |
---------------------------------
---------------------------------
| avg reward         | -485     |
| explained_variance | 0.348    |
| fps                | 2003     |
| learning rate      | 0.001    |
| nupdates           | 65600    |
| policy_entropy     | 0        |
| total_timesteps    | 5248000  |
| value_loss         | 149      |
---------------------------------
---------------------------------
| avg reward         | 206      |
| explained_variance | -9.83    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 65700    |
| policy_entropy     | 0        |
| total_timesteps    | 5256000  |
| value_loss         | 535      |
---------------------------------
---------------------------------
| avg reward         | 440      |
| explained_variance | 0.0265   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 65800    |
| policy_entropy     | 0        |
| total_timesteps    | 5264000  |
| value_loss         | 7.33e+03 |
---------------------------------
---------------------------------
| avg reward         | 345      |
| explained_variance | -0.8     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 65900    |
| policy_entropy     | 0        |
| total_timesteps    | 5272000  |
| value_loss         | 2.97e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.26e+03 |
| explained_variance | -44.2    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66000    |
| policy_entropy     | 0        |
| total_timesteps    | 5280000  |
| value_loss         | 1.62e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.37e+03 |
| explained_variance | 0.0568    |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 66100     |
| policy_entropy     | 0         |
| total_timesteps    | 5288000   |
| value_loss         | 5.95e+04  |
----------------------------------
---------------------------------
| avg reward         | -77.3    |
| explained_variance | 0.941    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66200    |
| policy_entropy     | 0        |
| total_timesteps    | 5296000  |
| value_loss         | 4.47     |
---------------------------------
----------------------------------
| avg reward         | -1.07e+03 |
| explained_variance | -1.72     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 66300     |
| policy_entropy     | 0         |
| total_timesteps    | 5304000   |
| value_loss         | 6.13e+04  |
----------------------------------
---------------------------------
| avg reward         | 892      |
| explained_variance | 0.0318   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66400    |
| policy_entropy     | 0        |
| total_timesteps    | 5312000  |
| value_loss         | 2.97e+04 |
---------------------------------
---------------------------------
| avg reward         | -340     |
| explained_variance | -0.0535  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66500    |
| policy_entropy     | 0        |
| total_timesteps    | 5320000  |
| value_loss         | 4.7e+03  |
---------------------------------
---------------------------------
| avg reward         | 1.7e+03  |
| explained_variance | 0.464    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66600    |
| policy_entropy     | 0        |
| total_timesteps    | 5328000  |
| value_loss         | 1.72e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.59e+03 |
| explained_variance | -41.2     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 66700     |
| policy_entropy     | 0         |
| total_timesteps    | 5336000   |
| value_loss         | 1.31e+04  |
----------------------------------
---------------------------------
| avg reward         | 41.8     |
| explained_variance | 0.917    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66800    |
| policy_entropy     | 0        |
| total_timesteps    | 5344000  |
| value_loss         | 9.7      |
---------------------------------
---------------------------------
| avg reward         | 1.66e+03 |
| explained_variance | 0.3      |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 66900    |
| policy_entropy     | 0        |
| total_timesteps    | 5352000  |
| value_loss         | 1.56e+03 |
---------------------------------
---------------------------------
| avg reward         | 6.84     |
| explained_variance | 0.892    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67000    |
| policy_entropy     | 0        |
| total_timesteps    | 5360000  |
| value_loss         | 7.96     |
---------------------------------
---------------------------------
| avg reward         | 282      |
| explained_variance | 0.903    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67100    |
| policy_entropy     | 0        |
| total_timesteps    | 5368000  |
| value_loss         | 49       |
---------------------------------
---------------------------------
| avg reward         | 1.14e+03 |
| explained_variance | -55.5    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67200    |
| policy_entropy     | 0        |
| total_timesteps    | 5376000  |
| value_loss         | 1.95e+04 |
---------------------------------
---------------------------------
| avg reward         | -336     |
| explained_variance | -6.85    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67300    |
| policy_entropy     | 0        |
| total_timesteps    | 5384000  |
| value_loss         | 856      |
---------------------------------
---------------------------------
| avg reward         | 699      |
| explained_variance | 0.134    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67400    |
| policy_entropy     | 0        |
| total_timesteps    | 5392000  |
| value_loss         | 1.45e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.13e+03 |
| explained_variance | -0.582   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67500    |
| policy_entropy     | 0        |
| total_timesteps    | 5400000  |
| value_loss         | 8.51e+04 |
---------------------------------
---------------------------------
| avg reward         | 832      |
| explained_variance | -1.42    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67600    |
| policy_entropy     | 0        |
| total_timesteps    | 5408000  |
| value_loss         | 1.13e+04 |
---------------------------------
---------------------------------
| avg reward         | -782     |
| explained_variance | 0.346    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67700    |
| policy_entropy     | 0        |
| total_timesteps    | 5416000  |
| value_loss         | 377      |
---------------------------------
---------------------------------
| avg reward         | 603      |
| explained_variance | 0.026    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67800    |
| policy_entropy     | 0        |
| total_timesteps    | 5424000  |
| value_loss         | 1.38e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.37e+03 |
| explained_variance | 0.452    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 67900    |
| policy_entropy     | 0        |
| total_timesteps    | 5432000  |
| value_loss         | 1.15e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.33e+03 |
| explained_variance | -0.195   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 68000    |
| policy_entropy     | 0        |
| total_timesteps    | 5440000  |
| value_loss         | 3.04e+05 |
---------------------------------
---------------------------------
| avg reward         | 3.08e+03 |
| explained_variance | -43.8    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 68100    |
| policy_entropy     | 0        |
| total_timesteps    | 5448000  |
| value_loss         | 8.58e+04 |
---------------------------------
---------------------------------
| avg reward         | -92.4    |
| explained_variance | 0.918    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 68200    |
| policy_entropy     | 0        |
| total_timesteps    | 5456000  |
| value_loss         | 11.6     |
---------------------------------
---------------------------------
| avg reward         | 2.29e+03 |
| explained_variance | 0.458    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 68300    |
| policy_entropy     | 0        |
| total_timesteps    | 5464000  |
| value_loss         | 2.99e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.85e+03 |
| explained_variance | -4.58    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 68400    |
| policy_entropy     | 0        |
| total_timesteps    | 5472000  |
| value_loss         | 1.35e+04 |
---------------------------------
---------------------------------
| avg reward         | -1.6e+03 |
| explained_variance | 0.0406   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 68500    |
| policy_entropy     | 0        |
| total_timesteps    | 5480000  |
| value_loss         | 1.51e+05 |
---------------------------------
---------------------------------
| avg reward         | -973     |
| explained_variance | -20.5    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 68600    |
| policy_entropy     | 0        |
| total_timesteps    | 5488000  |
| value_loss         | 4.11e+03 |
---------------------------------
---------------------------------
| avg reward         | 3.23e+03 |
| explained_variance | -0.777   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 68700    |
| policy_entropy     | 0        |
| total_timesteps    | 5496000  |
| value_loss         | 2.47e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.22e+03 |
| explained_variance | 0.562    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 68800    |
| policy_entropy     | 0        |
| total_timesteps    | 5504000  |
| value_loss         | 887      |
---------------------------------
---------------------------------
| avg reward         | 757      |
| explained_variance | 0.725    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 68900    |
| policy_entropy     | 0        |
| total_timesteps    | 5512000  |
| value_loss         | 403      |
---------------------------------
---------------------------------
| avg reward         | 1.49e+03 |
| explained_variance | 0.699    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69000    |
| policy_entropy     | 0        |
| total_timesteps    | 5520000  |
| value_loss         | 1.32e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.7e+03  |
| explained_variance | -36.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69100    |
| policy_entropy     | 0        |
| total_timesteps    | 5528000  |
| value_loss         | 7.02e+04 |
---------------------------------
---------------------------------
| avg reward         | 311      |
| explained_variance | -2.07    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69200    |
| policy_entropy     | 0        |
| total_timesteps    | 5536000  |
| value_loss         | 582      |
---------------------------------
---------------------------------
| avg reward         | 1.56e+03 |
| explained_variance | -1.53    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69300    |
| policy_entropy     | 0        |
| total_timesteps    | 5544000  |
| value_loss         | 4.08e+04 |
---------------------------------
---------------------------------
| avg reward         | -914     |
| explained_variance | 0.542    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69400    |
| policy_entropy     | 0        |
| total_timesteps    | 5552000  |
| value_loss         | 437      |
---------------------------------
---------------------------------
| avg reward         | -2.4e+03 |
| explained_variance | 0.0619   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69500    |
| policy_entropy     | 0        |
| total_timesteps    | 5560000  |
| value_loss         | 3.33e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.5e+03  |
| explained_variance | 0.639    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69600    |
| policy_entropy     | 0        |
| total_timesteps    | 5568000  |
| value_loss         | 1.32e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.47e+03 |
| explained_variance | 0.413    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69700    |
| policy_entropy     | 0        |
| total_timesteps    | 5576000  |
| value_loss         | 3.77e+03 |
---------------------------------
---------------------------------
| avg reward         | -2e+03   |
| explained_variance | -37.3    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69800    |
| policy_entropy     | 0        |
| total_timesteps    | 5584000  |
| value_loss         | 2.03e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.97e+03 |
| explained_variance | 0.567    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 69900    |
| policy_entropy     | 0        |
| total_timesteps    | 5592000  |
| value_loss         | 2.24e+03 |
---------------------------------
---------------------------------
| avg reward         | 967      |
| explained_variance | 0.0826   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 70000    |
| policy_entropy     | 0        |
| total_timesteps    | 5600000  |
| value_loss         | 2.17e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.29e+03 |
| explained_variance | -11.3     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 70100     |
| policy_entropy     | 0         |
| total_timesteps    | 5608000   |
| value_loss         | 3.34e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.56e+03 |
| explained_variance | 0.0635   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 70200    |
| policy_entropy     | 0        |
| total_timesteps    | 5616000  |
| value_loss         | 8.82e+04 |
---------------------------------
---------------------------------
| avg reward         | -860     |
| explained_variance | 0.409    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 70300    |
| policy_entropy     | 0        |
| total_timesteps    | 5624000  |
| value_loss         | 403      |
---------------------------------
---------------------------------
| avg reward         | 129      |
| explained_variance | -0.296   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 70400    |
| policy_entropy     | 0        |
| total_timesteps    | 5632000  |
| value_loss         | 240      |
---------------------------------
----------------------------------
| avg reward         | -1.99e+03 |
| explained_variance | 0.249     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 70500     |
| policy_entropy     | 0         |
| total_timesteps    | 5640000   |
| value_loss         | 2.32e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.14e+03 |
| explained_variance | 0.179     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 70600     |
| policy_entropy     | 0         |
| total_timesteps    | 5648000   |
| value_loss         | 760       |
----------------------------------
---------------------------------
| avg reward         | -377     |
| explained_variance | 0.825    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 70700    |
| policy_entropy     | 0        |
| total_timesteps    | 5656000  |
| value_loss         | 94.8     |
---------------------------------
----------------------------------
| avg reward         | -2.04e+03 |
| explained_variance | -0.354    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 70800     |
| policy_entropy     | 0         |
| total_timesteps    | 5664000   |
| value_loss         | 1.98e+05  |
----------------------------------
---------------------------------
| avg reward         | 977      |
| explained_variance | 0.719    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 70900    |
| policy_entropy     | 0        |
| total_timesteps    | 5672000  |
| value_loss         | 572      |
---------------------------------
---------------------------------
| avg reward         | -1.2e+03 |
| explained_variance | -11.2    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 71000    |
| policy_entropy     | 0        |
| total_timesteps    | 5680000  |
| value_loss         | 2.8e+03  |
---------------------------------
----------------------------------
| avg reward         | -2.14e+03 |
| explained_variance | 0.116     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 71100     |
| policy_entropy     | 0         |
| total_timesteps    | 5688000   |
| value_loss         | 2.64e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.69e+03 |
| explained_variance | -0.979    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 71200     |
| policy_entropy     | 0         |
| total_timesteps    | 5696000   |
| value_loss         | 7.39e+04  |
----------------------------------
---------------------------------
| avg reward         | 329      |
| explained_variance | 0.879    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 71300    |
| policy_entropy     | 0        |
| total_timesteps    | 5704000  |
| value_loss         | 87.3     |
---------------------------------
----------------------------------
| avg reward         | -1.25e+03 |
| explained_variance | 0.356     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 71400     |
| policy_entropy     | 0         |
| total_timesteps    | 5712000   |
| value_loss         | 894       |
----------------------------------
----------------------------------
| avg reward         | -1.31e+03 |
| explained_variance | 0.123     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 71500     |
| policy_entropy     | 0         |
| total_timesteps    | 5720000   |
| value_loss         | 5.09e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.47e+03 |
| explained_variance | 0.637    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 71600    |
| policy_entropy     | 0        |
| total_timesteps    | 5728000  |
| value_loss         | 1.13e+03 |
---------------------------------
---------------------------------
| avg reward         | -867     |
| explained_variance | -0.33    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 71700    |
| policy_entropy     | 0        |
| total_timesteps    | 5736000  |
| value_loss         | 4.35e+04 |
---------------------------------
---------------------------------
| avg reward         | 786      |
| explained_variance | 0.792    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 71800    |
| policy_entropy     | 0        |
| total_timesteps    | 5744000  |
| value_loss         | 407      |
---------------------------------
---------------------------------
| avg reward         | 471      |
| explained_variance | -6.62    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 71900    |
| policy_entropy     | 0        |
| total_timesteps    | 5752000  |
| value_loss         | 2.13e+03 |
---------------------------------
----------------------------------
| avg reward         | -2.04e+03 |
| explained_variance | 0.0747    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 72000     |
| policy_entropy     | 0         |
| total_timesteps    | 5760000   |
| value_loss         | 9.68e+04  |
----------------------------------
---------------------------------
| avg reward         | 2.15e+03 |
| explained_variance | -1.16    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72100    |
| policy_entropy     | 0        |
| total_timesteps    | 5768000  |
| value_loss         | 1.98e+05 |
---------------------------------
---------------------------------
| avg reward         | -251     |
| explained_variance | -0.0896  |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72200    |
| policy_entropy     | 0        |
| total_timesteps    | 5776000  |
| value_loss         | 2.73e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.51e+03 |
| explained_variance | 0.504    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72300    |
| policy_entropy     | 0        |
| total_timesteps    | 5784000  |
| value_loss         | 1.48e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.37e+03 |
| explained_variance | 0.59     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72400    |
| policy_entropy     | 0        |
| total_timesteps    | 5792000  |
| value_loss         | 3.24e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.93e+03 |
| explained_variance | -0.904   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72500    |
| policy_entropy     | 0        |
| total_timesteps    | 5800000  |
| value_loss         | 4.37e+05 |
---------------------------------
---------------------------------
| avg reward         | -998     |
| explained_variance | 0.00706  |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72600    |
| policy_entropy     | 0        |
| total_timesteps    | 5808000  |
| value_loss         | 3.83e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.12e+03 |
| explained_variance | -1.57    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 72700    |
| policy_entropy     | 0        |
| total_timesteps    | 5816000  |
| value_loss         | 4.22e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.71e+03 |
| explained_variance | -0.182    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 72800     |
| policy_entropy     | 0         |
| total_timesteps    | 5824000   |
| value_loss         | 1.26e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.22e+03 |
| explained_variance | -65.6     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 72900     |
| policy_entropy     | 0         |
| total_timesteps    | 5832000   |
| value_loss         | 1.42e+04  |
----------------------------------
---------------------------------
| avg reward         | -3.5e+03 |
| explained_variance | 0.105    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 73000    |
| policy_entropy     | 0        |
| total_timesteps    | 5840000  |
| value_loss         | 7.84e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.75e+03 |
| explained_variance | -10.7     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 73100     |
| policy_entropy     | 0         |
| total_timesteps    | 5848000   |
| value_loss         | 5.73e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.86e+03 |
| explained_variance | -0.00406  |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 73200     |
| policy_entropy     | 0         |
| total_timesteps    | 5856000   |
| value_loss         | 1.82e+05  |
----------------------------------
---------------------------------
| avg reward         | 2.68e+03 |
| explained_variance | -40.6    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 73300    |
| policy_entropy     | 0        |
| total_timesteps    | 5864000  |
| value_loss         | 7.16e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.83e+03 |
| explained_variance | -0.247   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 73400    |
| policy_entropy     | 0        |
| total_timesteps    | 5872000  |
| value_loss         | 1.82e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.86e+03 |
| explained_variance | -28.6    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 73500    |
| policy_entropy     | 0        |
| total_timesteps    | 5880000  |
| value_loss         | 3.51e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.49e+03 |
| explained_variance | 0.446    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 73600    |
| policy_entropy     | 0        |
| total_timesteps    | 5888000  |
| value_loss         | 4.76e+03 |
---------------------------------
---------------------------------
| avg reward         | 829      |
| explained_variance | -0.8     |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 73700    |
| policy_entropy     | 0        |
| total_timesteps    | 5896000  |
| value_loss         | 1.67e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.12e+03 |
| explained_variance | -17.9    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 73800    |
| policy_entropy     | 0        |
| total_timesteps    | 5904000  |
| value_loss         | 1.31e+04 |
---------------------------------
---------------------------------
| avg reward         | -285     |
| explained_variance | 0.873    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 73900    |
| policy_entropy     | 0        |
| total_timesteps    | 5912000  |
| value_loss         | 58.6     |
---------------------------------
----------------------------------
| avg reward         | -3.29e+03 |
| explained_variance | 0.0542    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 74000     |
| policy_entropy     | 0         |
| total_timesteps    | 5920000   |
| value_loss         | 3.95e+05  |
----------------------------------
---------------------------------
| avg reward         | -551     |
| explained_variance | -0.446   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74100    |
| policy_entropy     | 0        |
| total_timesteps    | 5928000  |
| value_loss         | 1.57e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.47e+03 |
| explained_variance | -7.18    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74200    |
| policy_entropy     | 0        |
| total_timesteps    | 5936000  |
| value_loss         | 1.29e+04 |
---------------------------------
---------------------------------
| avg reward         | 3.01e+03 |
| explained_variance | 0.0852   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74300    |
| policy_entropy     | 0        |
| total_timesteps    | 5944000  |
| value_loss         | 6.84e+05 |
---------------------------------
---------------------------------
| avg reward         | 4.43e+03 |
| explained_variance | 0.357    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74400    |
| policy_entropy     | 0        |
| total_timesteps    | 5952000  |
| value_loss         | 1.21e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.92e+03 |
| explained_variance | 0.278     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 74500     |
| policy_entropy     | 0         |
| total_timesteps    | 5960000   |
| value_loss         | 2e+03     |
----------------------------------
---------------------------------
| avg reward         | 2.49e+03 |
| explained_variance | 0.522    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74600    |
| policy_entropy     | 0        |
| total_timesteps    | 5968000  |
| value_loss         | 3.91e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.4e+03  |
| explained_variance | 0.465    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74700    |
| policy_entropy     | 0        |
| total_timesteps    | 5976000  |
| value_loss         | 3.34e+03 |
---------------------------------
----------------------------------
| avg reward         | -3.31e+03 |
| explained_variance | -39.4     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 74800     |
| policy_entropy     | 0         |
| total_timesteps    | 5984000   |
| value_loss         | 6.53e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.85e+03 |
| explained_variance | 0.579    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 74900    |
| policy_entropy     | 0        |
| total_timesteps    | 5992000  |
| value_loss         | 2.13e+03 |
---------------------------------
----------------------------------
| avg reward         | -3.91e+03 |
| explained_variance | 0.127     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 75000     |
| policy_entropy     | 0         |
| total_timesteps    | 6000000   |
| value_loss         | 4.64e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.48e+03 |
| explained_variance | 0.209    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 75100    |
| policy_entropy     | 0        |
| total_timesteps    | 6008000  |
| value_loss         | 6.14e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.36e+03 |
| explained_variance | 0.0155    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 75200     |
| policy_entropy     | 0         |
| total_timesteps    | 6016000   |
| value_loss         | 4.26e+05  |
----------------------------------
---------------------------------
| avg reward         | 3.47e+03 |
| explained_variance | 0.622    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 75300    |
| policy_entropy     | 0        |
| total_timesteps    | 6024000  |
| value_loss         | 6.54e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.93e+03 |
| explained_variance | -190     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 75400    |
| policy_entropy     | 0        |
| total_timesteps    | 6032000  |
| value_loss         | 2.99e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.63e+03 |
| explained_variance | -27.1    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 75500    |
| policy_entropy     | 0        |
| total_timesteps    | 6040000  |
| value_loss         | 3.23e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.79e+03 |
| explained_variance | 0.0861    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 75600     |
| policy_entropy     | 0         |
| total_timesteps    | 6048000   |
| value_loss         | 8.43e+03  |
----------------------------------
----------------------------------
| avg reward         | -2.87e+03 |
| explained_variance | -45.8     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 75700     |
| policy_entropy     | 0         |
| total_timesteps    | 6056000   |
| value_loss         | 5.23e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.58e+03 |
| explained_variance | -26.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 75800    |
| policy_entropy     | 0        |
| total_timesteps    | 6064000  |
| value_loss         | 8.51e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.57e+03 |
| explained_variance | 0.169    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 75900    |
| policy_entropy     | 0        |
| total_timesteps    | 6072000  |
| value_loss         | 1.95e+05 |
---------------------------------
----------------------------------
| avg reward         | -2.49e+03 |
| explained_variance | 0.0716    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76000     |
| policy_entropy     | 0         |
| total_timesteps    | 6080000   |
| value_loss         | 3.57e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.53e+03 |
| explained_variance | -1.44     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76100     |
| policy_entropy     | 0         |
| total_timesteps    | 6088000   |
| value_loss         | 1.13e+05  |
----------------------------------
---------------------------------
| avg reward         | -618     |
| explained_variance | -1.61    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 76200    |
| policy_entropy     | 0        |
| total_timesteps    | 6096000  |
| value_loss         | 7.13e+03 |
---------------------------------
----------------------------------
| avg reward         | -2.03e+03 |
| explained_variance | 0.059     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76300     |
| policy_entropy     | 0         |
| total_timesteps    | 6104000   |
| value_loss         | 2.54e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.95e+03 |
| explained_variance | 0.0505   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 76400    |
| policy_entropy     | 0        |
| total_timesteps    | 6112000  |
| value_loss         | 2.55e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.48e+03 |
| explained_variance | -1.28     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76500     |
| policy_entropy     | 0         |
| total_timesteps    | 6120000   |
| value_loss         | 6.53e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.01e+03 |
| explained_variance | 0.632     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76600     |
| policy_entropy     | 0         |
| total_timesteps    | 6128000   |
| value_loss         | 478       |
----------------------------------
----------------------------------
| avg reward         | -2.36e+03 |
| explained_variance | 0.205     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76700     |
| policy_entropy     | 0         |
| total_timesteps    | 6136000   |
| value_loss         | 2.89e+03  |
----------------------------------
---------------------------------
| avg reward         | 3.62e+03 |
| explained_variance | 0.475    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 76800    |
| policy_entropy     | 0        |
| total_timesteps    | 6144000  |
| value_loss         | 8.12e+03 |
---------------------------------
----------------------------------
| avg reward         | -3.11e+03 |
| explained_variance | 0.115     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 76900     |
| policy_entropy     | 0         |
| total_timesteps    | 6152000   |
| value_loss         | 5.64e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.37e+03 |
| explained_variance | 0.671    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 77000    |
| policy_entropy     | 0        |
| total_timesteps    | 6160000  |
| value_loss         | 1.34e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.35e+03 |
| explained_variance | 0.672    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 77100    |
| policy_entropy     | 0        |
| total_timesteps    | 6168000  |
| value_loss         | 1.18e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.09e+03 |
| explained_variance | 0.271    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 77200    |
| policy_entropy     | 0        |
| total_timesteps    | 6176000  |
| value_loss         | 3.2e+04  |
---------------------------------
----------------------------------
| avg reward         | -4.22e+03 |
| explained_variance | -0.531    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 77300     |
| policy_entropy     | 0         |
| total_timesteps    | 6184000   |
| value_loss         | 6.68e+05  |
----------------------------------
----------------------------------
| avg reward         | -2.93e+03 |
| explained_variance | 0.00158   |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 77400     |
| policy_entropy     | 0         |
| total_timesteps    | 6192000   |
| value_loss         | 5.25e+03  |
----------------------------------
---------------------------------
| avg reward         | 5e+03    |
| explained_variance | 0.583    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 77500    |
| policy_entropy     | 0        |
| total_timesteps    | 6200000  |
| value_loss         | 1.55e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.35e+03 |
| explained_variance | -1.06     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 77600     |
| policy_entropy     | 0         |
| total_timesteps    | 6208000   |
| value_loss         | 3.02e+05  |
----------------------------------
---------------------------------
| avg reward         | -4.5e+03 |
| explained_variance | 0.171    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 77700    |
| policy_entropy     | 0        |
| total_timesteps    | 6216000  |
| value_loss         | 1.19e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.86e+03 |
| explained_variance | -51.4     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 77800     |
| policy_entropy     | 0         |
| total_timesteps    | 6224000   |
| value_loss         | 1.61e+05  |
----------------------------------
---------------------------------
| avg reward         | 3.59e+03 |
| explained_variance | 0.573    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 77900    |
| policy_entropy     | 0        |
| total_timesteps    | 6232000  |
| value_loss         | 7.63e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.05e+03 |
| explained_variance | -1.7      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 78000     |
| policy_entropy     | 0         |
| total_timesteps    | 6240000   |
| value_loss         | 2.01e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.83e+03 |
| explained_variance | -6       |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 78100    |
| policy_entropy     | 0        |
| total_timesteps    | 6248000  |
| value_loss         | 3.46e+04 |
---------------------------------
---------------------------------
| avg reward         | 3.18e+03 |
| explained_variance | 0.58     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 78200    |
| policy_entropy     | 0        |
| total_timesteps    | 6256000  |
| value_loss         | 6.13e+03 |
---------------------------------
---------------------------------
| avg reward         | 3.96e+03 |
| explained_variance | 0.471    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 78300    |
| policy_entropy     | 0        |
| total_timesteps    | 6264000  |
| value_loss         | 9.95e+03 |
---------------------------------
----------------------------------
| avg reward         | -2.64e+03 |
| explained_variance | 0.147     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 78400     |
| policy_entropy     | 0         |
| total_timesteps    | 6272000   |
| value_loss         | 4.02e+03  |
----------------------------------
---------------------------------
| avg reward         | -929     |
| explained_variance | -37.1    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 78500    |
| policy_entropy     | 0        |
| total_timesteps    | 6280000  |
| value_loss         | 1.02e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.53e+03 |
| explained_variance | -1.97     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 78600     |
| policy_entropy     | 0         |
| total_timesteps    | 6288000   |
| value_loss         | 3.96e+05  |
----------------------------------
----------------------------------
| avg reward         | -3.21e+03 |
| explained_variance | -104      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 78700     |
| policy_entropy     | 0         |
| total_timesteps    | 6296000   |
| value_loss         | 1.45e+05  |
----------------------------------
----------------------------------
| avg reward         | -3.77e+03 |
| explained_variance | 0.0856    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 78800     |
| policy_entropy     | 0         |
| total_timesteps    | 6304000   |
| value_loss         | 8.24e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.51e+03 |
| explained_variance | 0.288     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 78900     |
| policy_entropy     | 0         |
| total_timesteps    | 6312000   |
| value_loss         | 1.43e+03  |
----------------------------------
---------------------------------
| avg reward         | 2.19e+03 |
| explained_variance | -42.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 79000    |
| policy_entropy     | 0        |
| total_timesteps    | 6320000  |
| value_loss         | 6.13e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.65e+03 |
| explained_variance | 0.19      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 79100     |
| policy_entropy     | 0         |
| total_timesteps    | 6328000   |
| value_loss         | 1.77e+04  |
----------------------------------
---------------------------------
| avg reward         | 6e+03    |
| explained_variance | -0.0795  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 79200    |
| policy_entropy     | 0        |
| total_timesteps    | 6336000  |
| value_loss         | 1.45e+06 |
---------------------------------
----------------------------------
| avg reward         | -4.82e+03 |
| explained_variance | 0.168     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 79300     |
| policy_entropy     | 0         |
| total_timesteps    | 6344000   |
| value_loss         | 1.24e+04  |
----------------------------------
---------------------------------
| avg reward         | 52.4     |
| explained_variance | 0.826    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 79400    |
| policy_entropy     | 0        |
| total_timesteps    | 6352000  |
| value_loss         | 83.3     |
---------------------------------
---------------------------------
| avg reward         | 1.72e+03 |
| explained_variance | -0.217   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 79500    |
| policy_entropy     | 0        |
| total_timesteps    | 6360000  |
| value_loss         | 3.03e+05 |
---------------------------------
----------------------------------
| avg reward         | -2.92e+03 |
| explained_variance | -2.13     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 79600     |
| policy_entropy     | 0         |
| total_timesteps    | 6368000   |
| value_loss         | 3.47e+05  |
----------------------------------
---------------------------------
| avg reward         | -24.5    |
| explained_variance | 0.814    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 79700    |
| policy_entropy     | 0        |
| total_timesteps    | 6376000  |
| value_loss         | 38.7     |
---------------------------------
----------------------------------
| avg reward         | -1.21e+03 |
| explained_variance | 0.427     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 79800     |
| policy_entropy     | 0         |
| total_timesteps    | 6384000   |
| value_loss         | 1.04e+03  |
----------------------------------
----------------------------------
| avg reward         | -4.69e+03 |
| explained_variance | 0.0313    |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 79900     |
| policy_entropy     | 0         |
| total_timesteps    | 6392000   |
| value_loss         | 8.17e+05  |
----------------------------------
----------------------------------
| avg reward         | -5.78e+03 |
| explained_variance | -15.1     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 80000     |
| policy_entropy     | 0         |
| total_timesteps    | 6400000   |
| value_loss         | 7.9e+04   |
----------------------------------
----------------------------------
| avg reward         | -4.07e+03 |
| explained_variance | -1.06     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 80100     |
| policy_entropy     | 0         |
| total_timesteps    | 6408000   |
| value_loss         | 4.46e+05  |
----------------------------------
---------------------------------
| avg reward         | -64.5    |
| explained_variance | 0.721    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 80200    |
| policy_entropy     | 0        |
| total_timesteps    | 6416000  |
| value_loss         | 100      |
---------------------------------
---------------------------------
| avg reward         | 1.43e+03 |
| explained_variance | 0.64     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 80300    |
| policy_entropy     | 0        |
| total_timesteps    | 6424000  |
| value_loss         | 1.62e+03 |
---------------------------------
----------------------------------
| avg reward         | -2.84e+03 |
| explained_variance | 0.136     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 80400     |
| policy_entropy     | 0         |
| total_timesteps    | 6432000   |
| value_loss         | 4.49e+03  |
----------------------------------
----------------------------------
| avg reward         | -5.18e+03 |
| explained_variance | -97.4     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 80500     |
| policy_entropy     | 0         |
| total_timesteps    | 6440000   |
| value_loss         | 3.01e+05  |
----------------------------------
----------------------------------
| avg reward         | -5.07e+03 |
| explained_variance | 0.156     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 80600     |
| policy_entropy     | 0         |
| total_timesteps    | 6448000   |
| value_loss         | 1.54e+04  |
----------------------------------
----------------------------------
| avg reward         | -3.95e+03 |
| explained_variance | -0.486    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 80700     |
| policy_entropy     | 0         |
| total_timesteps    | 6456000   |
| value_loss         | 5.42e+05  |
----------------------------------
----------------------------------
| avg reward         | -2.63e+03 |
| explained_variance | 0.0212    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 80800     |
| policy_entropy     | 0         |
| total_timesteps    | 6464000   |
| value_loss         | 2.6e+05   |
----------------------------------
----------------------------------
| avg reward         | -3.48e+03 |
| explained_variance | 0.0708    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 80900     |
| policy_entropy     | 0         |
| total_timesteps    | 6472000   |
| value_loss         | 2.86e+05  |
----------------------------------
----------------------------------
| avg reward         | -5.45e+03 |
| explained_variance | 0.182     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 81000     |
| policy_entropy     | 0         |
| total_timesteps    | 6480000   |
| value_loss         | 1.71e+04  |
----------------------------------
----------------------------------
| avg reward         | -6.16e+03 |
| explained_variance | 0.0225    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 81100     |
| policy_entropy     | 0         |
| total_timesteps    | 6488000   |
| value_loss         | 1.98e+06  |
----------------------------------
----------------------------------
| avg reward         | -4.69e+03 |
| explained_variance | 0.0816    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 81200     |
| policy_entropy     | 0         |
| total_timesteps    | 6496000   |
| value_loss         | 1.32e+04  |
----------------------------------
---------------------------------
| avg reward         | 4.61e+03 |
| explained_variance | 0.454    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 81300    |
| policy_entropy     | 0        |
| total_timesteps    | 6504000  |
| value_loss         | 1.44e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.62e+03 |
| explained_variance | 0.796    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 81400    |
| policy_entropy     | 0        |
| total_timesteps    | 6512000  |
| value_loss         | 1.46e+03 |
---------------------------------
----------------------------------
| avg reward         | -5.89e+03 |
| explained_variance | 0.117     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 81500     |
| policy_entropy     | 0         |
| total_timesteps    | 6520000   |
| value_loss         | 1.04e+06  |
----------------------------------
----------------------------------
| avg reward         | -3.41e+03 |
| explained_variance | 0.23      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 81600     |
| policy_entropy     | 0         |
| total_timesteps    | 6528000   |
| value_loss         | 6.74e+03  |
----------------------------------
----------------------------------
| avg reward         | -6.12e+03 |
| explained_variance | 0.219     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 81700     |
| policy_entropy     | 0         |
| total_timesteps    | 6536000   |
| value_loss         | 2.11e+04  |
----------------------------------
---------------------------------
| avg reward         | 6.78e+03 |
| explained_variance | -1.63    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 81800    |
| policy_entropy     | 0        |
| total_timesteps    | 6544000  |
| value_loss         | 7.95e+05 |
---------------------------------
---------------------------------
| avg reward         | 2.53e+03 |
| explained_variance | 0.609    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 81900    |
| policy_entropy     | 0        |
| total_timesteps    | 6552000  |
| value_loss         | 4.03e+03 |
---------------------------------
----------------------------------
| avg reward         | -6.41e+03 |
| explained_variance | -11.7     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 82000     |
| policy_entropy     | 0         |
| total_timesteps    | 6560000   |
| value_loss         | 7.24e+04  |
----------------------------------
---------------------------------
| avg reward         | -963     |
| explained_variance | -0.347   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 82100    |
| policy_entropy     | 0        |
| total_timesteps    | 6568000  |
| value_loss         | 5.48e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.36e+03 |
| explained_variance | -0.683    |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 82200     |
| policy_entropy     | 0         |
| total_timesteps    | 6576000   |
| value_loss         | 2.35e+06  |
----------------------------------
---------------------------------
| avg reward         | -716     |
| explained_variance | -1.24    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 82300    |
| policy_entropy     | 0        |
| total_timesteps    | 6584000  |
| value_loss         | 8.65e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.01e+03 |
| explained_variance | -0.958   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 82400    |
| policy_entropy     | 0        |
| total_timesteps    | 6592000  |
| value_loss         | 6.95e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.91e+03 |
| explained_variance | 0.798    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 82500    |
| policy_entropy     | 0        |
| total_timesteps    | 6600000  |
| value_loss         | 2.15e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.29e+03 |
| explained_variance | 0.825     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 82600     |
| policy_entropy     | 0         |
| total_timesteps    | 6608000   |
| value_loss         | 967       |
----------------------------------
----------------------------------
| avg reward         | -5.01e+03 |
| explained_variance | 0.155     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 82700     |
| policy_entropy     | 0         |
| total_timesteps    | 6616000   |
| value_loss         | 1.47e+04  |
----------------------------------
---------------------------------
| avg reward         | 2.22e+03 |
| explained_variance | -1.41    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 82800    |
| policy_entropy     | 0        |
| total_timesteps    | 6624000  |
| value_loss         | 8.26e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.43e+03 |
| explained_variance | -1.59     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 82900     |
| policy_entropy     | 0         |
| total_timesteps    | 6632000   |
| value_loss         | 1e+05     |
----------------------------------
---------------------------------
| avg reward         | 2.94e+03 |
| explained_variance | 0.0698   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 83000    |
| policy_entropy     | 0        |
| total_timesteps    | 6640000  |
| value_loss         | 2.69e+05 |
---------------------------------
---------------------------------
| avg reward         | 6.84e+03 |
| explained_variance | 0.0509   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 83100    |
| policy_entropy     | 0        |
| total_timesteps    | 6648000  |
| value_loss         | 1.71e+06 |
---------------------------------
----------------------------------
| avg reward         | -3.49e+03 |
| explained_variance | 0.212     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 83200     |
| policy_entropy     | 0         |
| total_timesteps    | 6656000   |
| value_loss         | 7.15e+03  |
----------------------------------
---------------------------------
| avg reward         | -965     |
| explained_variance | 0.848    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 83300    |
| policy_entropy     | 0        |
| total_timesteps    | 6664000  |
| value_loss         | 451      |
---------------------------------
---------------------------------
| avg reward         | 2e+03    |
| explained_variance | 0.721    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 83400    |
| policy_entropy     | 0        |
| total_timesteps    | 6672000  |
| value_loss         | 2.78e+03 |
---------------------------------
----------------------------------
| avg reward         | -7.19e+03 |
| explained_variance | 0.101     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 83500     |
| policy_entropy     | 0         |
| total_timesteps    | 6680000   |
| value_loss         | 1.57e+06  |
----------------------------------
----------------------------------
| avg reward         | -7.27e+03 |
| explained_variance | -1.59     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 83600     |
| policy_entropy     | 0         |
| total_timesteps    | 6688000   |
| value_loss         | 1.78e+06  |
----------------------------------
----------------------------------
| avg reward         | -7.07e+03 |
| explained_variance | 0.108     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 83700     |
| policy_entropy     | 0         |
| total_timesteps    | 6696000   |
| value_loss         | 2.98e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.54e+03 |
| explained_variance | -1.47     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 83800     |
| policy_entropy     | 0         |
| total_timesteps    | 6704000   |
| value_loss         | 3.86e+04  |
----------------------------------
---------------------------------
| avg reward         | 2.81e+03 |
| explained_variance | 0.629    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 83900    |
| policy_entropy     | 0        |
| total_timesteps    | 6712000  |
| value_loss         | 4.25e+03 |
---------------------------------
----------------------------------
| avg reward         | -7.02e+03 |
| explained_variance | 0.141     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 84000     |
| policy_entropy     | 0         |
| total_timesteps    | 6720000   |
| value_loss         | 2.84e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.01e+03 |
| explained_variance | -10.8    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 84100    |
| policy_entropy     | 0        |
| total_timesteps    | 6728000  |
| value_loss         | 4.53e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.44e+03 |
| explained_variance | -8.94     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 84200     |
| policy_entropy     | 0         |
| total_timesteps    | 6736000   |
| value_loss         | 3.18e+04  |
----------------------------------
----------------------------------
| avg reward         | -4.66e+03 |
| explained_variance | 0.122     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 84300     |
| policy_entropy     | 0         |
| total_timesteps    | 6744000   |
| value_loss         | 1.3e+04   |
----------------------------------
----------------------------------
| avg reward         | -3.54e+03 |
| explained_variance | 0.306     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 84400     |
| policy_entropy     | 0         |
| total_timesteps    | 6752000   |
| value_loss         | 7.68e+03  |
----------------------------------
---------------------------------
| avg reward         | 7.47e+03 |
| explained_variance | -0.0516  |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 84500    |
| policy_entropy     | 0        |
| total_timesteps    | 6760000  |
| value_loss         | 1.42e+06 |
---------------------------------
---------------------------------
| avg reward         | 8.87e+03 |
| explained_variance | -0.847   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 84600    |
| policy_entropy     | 0        |
| total_timesteps    | 6768000  |
| value_loss         | 1.92e+06 |
---------------------------------
---------------------------------
| avg reward         | 7.4e+03  |
| explained_variance | 0.318    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 84700    |
| policy_entropy     | 0        |
| total_timesteps    | 6776000  |
| value_loss         | 3.36e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.28e+03 |
| explained_variance | -5.25     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 84800     |
| policy_entropy     | 0         |
| total_timesteps    | 6784000   |
| value_loss         | 9.05e+03  |
----------------------------------
----------------------------------
| avg reward         | -6.12e+03 |
| explained_variance | -34.7     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 84900     |
| policy_entropy     | 0         |
| total_timesteps    | 6792000   |
| value_loss         | 1.78e+05  |
----------------------------------
---------------------------------
| avg reward         | 8.05e+03 |
| explained_variance | 0.469    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 85000    |
| policy_entropy     | 0        |
| total_timesteps    | 6800000  |
| value_loss         | 3.81e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.09e+03 |
| explained_variance | -6.51    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 85100    |
| policy_entropy     | 0        |
| total_timesteps    | 6808000  |
| value_loss         | 2.11e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.83e+03 |
| explained_variance | -10.8     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 85200     |
| policy_entropy     | 0         |
| total_timesteps    | 6816000   |
| value_loss         | 5.63e+04  |
----------------------------------
----------------------------------
| avg reward         | -6.12e+03 |
| explained_variance | 0.134     |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 85300     |
| policy_entropy     | 0         |
| total_timesteps    | 6824000   |
| value_loss         | 2.18e+04  |
----------------------------------
---------------------------------
| avg reward         | 5.27e+03 |
| explained_variance | 0.465    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 85400    |
| policy_entropy     | 0        |
| total_timesteps    | 6832000  |
| value_loss         | 1.7e+04  |
---------------------------------
---------------------------------
| avg reward         | 6.46e+03 |
| explained_variance | 0.0449   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 85500    |
| policy_entropy     | 0        |
| total_timesteps    | 6840000  |
| value_loss         | 9.69e+05 |
---------------------------------
---------------------------------
| avg reward         | 735      |
| explained_variance | 0.902    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 85600    |
| policy_entropy     | 0        |
| total_timesteps    | 6848000  |
| value_loss         | 428      |
---------------------------------
----------------------------------
| avg reward         | -7.94e+03 |
| explained_variance | -9.59     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 85700     |
| policy_entropy     | 0         |
| total_timesteps    | 6856000   |
| value_loss         | 1.05e+05  |
----------------------------------
---------------------------------
| avg reward         | -4.1e+03 |
| explained_variance | 0.1      |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 85800    |
| policy_entropy     | 0        |
| total_timesteps    | 6864000  |
| value_loss         | 1.03e+04 |
---------------------------------
---------------------------------
| avg reward         | 3.08e+03 |
| explained_variance | 0.799    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 85900    |
| policy_entropy     | 0        |
| total_timesteps    | 6872000  |
| value_loss         | 6.11e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.5e+03  |
| explained_variance | -1.54    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86000    |
| policy_entropy     | 0        |
| total_timesteps    | 6880000  |
| value_loss         | 1.15e+04 |
---------------------------------
----------------------------------
| avg reward         | -7.55e+03 |
| explained_variance | 0.178     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 86100     |
| policy_entropy     | 0         |
| total_timesteps    | 6888000   |
| value_loss         | 3.51e+04  |
----------------------------------
---------------------------------
| avg reward         | 234      |
| explained_variance | 0.761    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86200    |
| policy_entropy     | 0        |
| total_timesteps    | 6896000  |
| value_loss         | 181      |
---------------------------------
----------------------------------
| avg reward         | -1.34e+03 |
| explained_variance | -22.7     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 86300     |
| policy_entropy     | 0         |
| total_timesteps    | 6904000   |
| value_loss         | 1.53e+04  |
----------------------------------
---------------------------------
| avg reward         | 7.26e+03 |
| explained_variance | 0.396    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86400    |
| policy_entropy     | 0        |
| total_timesteps    | 6912000  |
| value_loss         | 3.2e+04  |
---------------------------------
---------------------------------
| avg reward         | -5.4e+03 |
| explained_variance | 0.117    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86500    |
| policy_entropy     | 0        |
| total_timesteps    | 6920000  |
| value_loss         | 1.7e+04  |
---------------------------------
---------------------------------
| avg reward         | 5.55e+03 |
| explained_variance | 0.0715   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86600    |
| policy_entropy     | 0        |
| total_timesteps    | 6928000  |
| value_loss         | 6.97e+05 |
---------------------------------
---------------------------------
| avg reward         | 7.29e+03 |
| explained_variance | -0.202   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86700    |
| policy_entropy     | 0        |
| total_timesteps    | 6936000  |
| value_loss         | 1.47e+06 |
---------------------------------
----------------------------------
| avg reward         | -3.02e+03 |
| explained_variance | 0.251     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 86800     |
| policy_entropy     | 0         |
| total_timesteps    | 6944000   |
| value_loss         | 5.53e+03  |
----------------------------------
---------------------------------
| avg reward         | -674     |
| explained_variance | 0.118    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 86900    |
| policy_entropy     | 0        |
| total_timesteps    | 6952000  |
| value_loss         | 1.43e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.94e+03 |
| explained_variance | 0.687    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 87000    |
| policy_entropy     | 0        |
| total_timesteps    | 6960000  |
| value_loss         | 2.53e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.66e+03 |
| explained_variance | -0.758   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 87100    |
| policy_entropy     | 0        |
| total_timesteps    | 6968000  |
| value_loss         | 1.68e+05 |
---------------------------------
---------------------------------
| avg reward         | 8.46e+03 |
| explained_variance | 0.46     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 87200    |
| policy_entropy     | 0        |
| total_timesteps    | 6976000  |
| value_loss         | 4.08e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.49e+03 |
| explained_variance | 0.625    |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 87300    |
| policy_entropy     | 0        |
| total_timesteps    | 6984000  |
| value_loss         | 2.62e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.64e+03 |
| explained_variance | -0.198    |
| fps                | 2004      |
| learning rate      | 0.001     |
| nupdates           | 87400     |
| policy_entropy     | 0         |
| total_timesteps    | 6992000   |
| value_loss         | 2.63e+06  |
----------------------------------
---------------------------------
| avg reward         | 7.16e+03 |
| explained_variance | 0.0824   |
| fps                | 2004     |
| learning rate      | 0.001    |
| nupdates           | 87500    |
| policy_entropy     | 0        |
| total_timesteps    | 7000000  |
| value_loss         | 1.82e+06 |
---------------------------------
----------------------------------
| avg reward         | -8.04e+03 |
| explained_variance | -2.08     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 87600     |
| policy_entropy     | 0         |
| total_timesteps    | 7008000   |
| value_loss         | 1.28e+06  |
----------------------------------
---------------------------------
| avg reward         | 1.23e+03 |
| explained_variance | 0.786    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 87700    |
| policy_entropy     | 0        |
| total_timesteps    | 7016000  |
| value_loss         | 1.32e+03 |
---------------------------------
---------------------------------
| avg reward         | 2.74e+03 |
| explained_variance | 0.0806   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 87800    |
| policy_entropy     | 0        |
| total_timesteps    | 7024000  |
| value_loss         | 1.69e+05 |
---------------------------------
---------------------------------
| avg reward         | 6.02e+03 |
| explained_variance | 0.643    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 87900    |
| policy_entropy     | 0        |
| total_timesteps    | 7032000  |
| value_loss         | 2.13e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.37e+04 |
| explained_variance | -9.44     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 88000     |
| policy_entropy     | 0         |
| total_timesteps    | 7040000   |
| value_loss         | 2.92e+05  |
----------------------------------
----------------------------------
| avg reward         | -6.34e+03 |
| explained_variance | -1.47     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 88100     |
| policy_entropy     | 0         |
| total_timesteps    | 7048000   |
| value_loss         | 6.47e+05  |
----------------------------------
----------------------------------
| avg reward         | -4.55e+03 |
| explained_variance | 0.116     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 88200     |
| policy_entropy     | 0         |
| total_timesteps    | 7056000   |
| value_loss         | 1.18e+04  |
----------------------------------
---------------------------------
| avg reward         | 2.68e+03 |
| explained_variance | 0.628    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 88300    |
| policy_entropy     | 0        |
| total_timesteps    | 7064000  |
| value_loss         | 4.6e+03  |
---------------------------------
----------------------------------
| avg reward         | -3.33e+03 |
| explained_variance | 0.107     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 88400     |
| policy_entropy     | 0         |
| total_timesteps    | 7072000   |
| value_loss         | 3.36e+05  |
----------------------------------
----------------------------------
| avg reward         | -7.61e+03 |
| explained_variance | -70.6     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 88500     |
| policy_entropy     | 0         |
| total_timesteps    | 7080000   |
| value_loss         | 5.33e+05  |
----------------------------------
---------------------------------
| avg reward         | -440     |
| explained_variance | 0.949    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 88600    |
| policy_entropy     | 0        |
| total_timesteps    | 7088000  |
| value_loss         | 187      |
---------------------------------
---------------------------------
| avg reward         | 3.23e+03 |
| explained_variance | -3.57    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 88700    |
| policy_entropy     | 0        |
| total_timesteps    | 7096000  |
| value_loss         | 1.89e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.57e+03 |
| explained_variance | 0.114    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 88800    |
| policy_entropy     | 0        |
| total_timesteps    | 7104000  |
| value_loss         | 3.65e+05 |
---------------------------------
---------------------------------
| avg reward         | -5.8e+03 |
| explained_variance | 0.061    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 88900    |
| policy_entropy     | 0        |
| total_timesteps    | 7112000  |
| value_loss         | 1.99e+06 |
---------------------------------
---------------------------------
| avg reward         | -868     |
| explained_variance | 0.0509   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89000    |
| policy_entropy     | 0        |
| total_timesteps    | 7120000  |
| value_loss         | 2.54e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.27e+03 |
| explained_variance | -14.3    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89100    |
| policy_entropy     | 0        |
| total_timesteps    | 7128000  |
| value_loss         | 5.59e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.83e+03 |
| explained_variance | 0.0215    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 89200     |
| policy_entropy     | 0         |
| total_timesteps    | 7136000   |
| value_loss         | 8.24e+05  |
----------------------------------
---------------------------------
| avg reward         | 8.52e+03 |
| explained_variance | 0.553    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89300    |
| policy_entropy     | 0        |
| total_timesteps    | 7144000  |
| value_loss         | 4.39e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.83e+03 |
| explained_variance | 0.418     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 89400     |
| policy_entropy     | 0         |
| total_timesteps    | 7152000   |
| value_loss         | 4.29e+03  |
----------------------------------
---------------------------------
| avg reward         | 2.94e+03 |
| explained_variance | -1.45    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89500    |
| policy_entropy     | 0        |
| total_timesteps    | 7160000  |
| value_loss         | 1.43e+05 |
---------------------------------
---------------------------------
| avg reward         | 3.31e+03 |
| explained_variance | -9.28    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89600    |
| policy_entropy     | 0        |
| total_timesteps    | 7168000  |
| value_loss         | 6.07e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.83e+03 |
| explained_variance | 0.43     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89700    |
| policy_entropy     | 0        |
| total_timesteps    | 7176000  |
| value_loss         | 2.7e+04  |
---------------------------------
---------------------------------
| avg reward         | 5.5e+03  |
| explained_variance | 0.175    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89800    |
| policy_entropy     | 0        |
| total_timesteps    | 7184000  |
| value_loss         | 8.61e+05 |
---------------------------------
---------------------------------
| avg reward         | 2.3e+03  |
| explained_variance | -0.327   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 89900    |
| policy_entropy     | 0        |
| total_timesteps    | 7192000  |
| value_loss         | 2.48e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.97e+03 |
| explained_variance | -2.82    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 90000    |
| policy_entropy     | 0        |
| total_timesteps    | 7200000  |
| value_loss         | 1.05e+05 |
---------------------------------
----------------------------------
| avg reward         | -2.79e+03 |
| explained_variance | -0.243    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 90100     |
| policy_entropy     | 0         |
| total_timesteps    | 7208000   |
| value_loss         | 4.61e+05  |
----------------------------------
----------------------------------
| avg reward         | -3.47e+03 |
| explained_variance | 0.306     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 90200     |
| policy_entropy     | 0         |
| total_timesteps    | 7216000   |
| value_loss         | 6.99e+03  |
----------------------------------
---------------------------------
| avg reward         | -414     |
| explained_variance | -0.324   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 90300    |
| policy_entropy     | 0        |
| total_timesteps    | 7224000  |
| value_loss         | 1.48e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.68e+03 |
| explained_variance | -12.5    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 90400    |
| policy_entropy     | 0        |
| total_timesteps    | 7232000  |
| value_loss         | 3.43e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.67e+03 |
| explained_variance | 0.0717   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 90500    |
| policy_entropy     | 0        |
| total_timesteps    | 7240000  |
| value_loss         | 1.81e+05 |
---------------------------------
----------------------------------
| avg reward         | -4.73e+03 |
| explained_variance | -11.3     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 90600     |
| policy_entropy     | 0         |
| total_timesteps    | 7248000   |
| value_loss         | 4.23e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.8e+03  |
| explained_variance | -1.65    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 90700    |
| policy_entropy     | 0        |
| total_timesteps    | 7256000  |
| value_loss         | 2.56e+05 |
---------------------------------
---------------------------------
| avg reward         | 442      |
| explained_variance | -0.101   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 90800    |
| policy_entropy     | 0        |
| total_timesteps    | 7264000  |
| value_loss         | 6.87e+03 |
---------------------------------
----------------------------------
| avg reward         | -4.27e+03 |
| explained_variance | 0.12      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 90900     |
| policy_entropy     | 0         |
| total_timesteps    | 7272000   |
| value_loss         | 5.59e+05  |
----------------------------------
----------------------------------
| avg reward         | -5.64e+03 |
| explained_variance | 0.178     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 91000     |
| policy_entropy     | 0         |
| total_timesteps    | 7280000   |
| value_loss         | 1.75e+04  |
----------------------------------
----------------------------------
| avg reward         | -3.08e+03 |
| explained_variance | -0.271    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 91100     |
| policy_entropy     | 0         |
| total_timesteps    | 7288000   |
| value_loss         | 4.78e+05  |
----------------------------------
---------------------------------
| avg reward         | 391      |
| explained_variance | 0.943    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 91200    |
| policy_entropy     | 0        |
| total_timesteps    | 7296000  |
| value_loss         | 175      |
---------------------------------
----------------------------------
| avg reward         | -6.35e+03 |
| explained_variance | -0.928    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 91300     |
| policy_entropy     | 0         |
| total_timesteps    | 7304000   |
| value_loss         | 1.02e+06  |
----------------------------------
---------------------------------
| avg reward         | 7.91e+03 |
| explained_variance | 0.499    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 91400    |
| policy_entropy     | 0        |
| total_timesteps    | 7312000  |
| value_loss         | 3.7e+04  |
---------------------------------
---------------------------------
| avg reward         | 860      |
| explained_variance | -4.92    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 91500    |
| policy_entropy     | 0        |
| total_timesteps    | 7320000  |
| value_loss         | 4.94e+03 |
---------------------------------
---------------------------------
| avg reward         | 3.05e+03 |
| explained_variance | 0.0347   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 91600    |
| policy_entropy     | 0        |
| total_timesteps    | 7328000  |
| value_loss         | 3.39e+05 |
---------------------------------
----------------------------------
| avg reward         | -6.68e+03 |
| explained_variance | -42.9     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 91700     |
| policy_entropy     | 0         |
| total_timesteps    | 7336000   |
| value_loss         | 2.47e+05  |
----------------------------------
---------------------------------
| avg reward         | 7.18e+03 |
| explained_variance | 0.468    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 91800    |
| policy_entropy     | 0        |
| total_timesteps    | 7344000  |
| value_loss         | 3.2e+04  |
---------------------------------
----------------------------------
| avg reward         | -3.16e+03 |
| explained_variance | 0.508     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 91900     |
| policy_entropy     | 0         |
| total_timesteps    | 7352000   |
| value_loss         | 5.33e+03  |
----------------------------------
---------------------------------
| avg reward         | 8.64e+03 |
| explained_variance | 0.316    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 92000    |
| policy_entropy     | 0        |
| total_timesteps    | 7360000  |
| value_loss         | 4.33e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.26e+03 |
| explained_variance | 0.572    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 92100    |
| policy_entropy     | 0        |
| total_timesteps    | 7368000  |
| value_loss         | 2.45e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.94e+03 |
| explained_variance | 0.656     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 92200     |
| policy_entropy     | 0         |
| total_timesteps    | 7376000   |
| value_loss         | 2.4e+03   |
----------------------------------
---------------------------------
| avg reward         | 2.07e+03 |
| explained_variance | 0.756    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 92300    |
| policy_entropy     | 0        |
| total_timesteps    | 7384000  |
| value_loss         | 3.05e+03 |
---------------------------------
---------------------------------
| avg reward         | 3.36e+03 |
| explained_variance | 0.734    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 92400    |
| policy_entropy     | 0        |
| total_timesteps    | 7392000  |
| value_loss         | 7.13e+03 |
---------------------------------
----------------------------------
| avg reward         | -9.33e+03 |
| explained_variance | -37       |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 92500     |
| policy_entropy     | 0         |
| total_timesteps    | 7400000   |
| value_loss         | 4.74e+05  |
----------------------------------
----------------------------------
| avg reward         | -3.51e+03 |
| explained_variance | -1.72     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 92600     |
| policy_entropy     | 0         |
| total_timesteps    | 7408000   |
| value_loss         | 2.2e+05   |
----------------------------------
----------------------------------
| avg reward         | -7.88e+03 |
| explained_variance | 0.048     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 92700     |
| policy_entropy     | 0         |
| total_timesteps    | 7416000   |
| value_loss         | 1.47e+06  |
----------------------------------
---------------------------------
| avg reward         | -3.4e+03 |
| explained_variance | 0.302    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 92800    |
| policy_entropy     | 0        |
| total_timesteps    | 7424000  |
| value_loss         | 6.89e+03 |
---------------------------------
---------------------------------
| avg reward         | 7.56e+03 |
| explained_variance | 0.315    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 92900    |
| policy_entropy     | 0        |
| total_timesteps    | 7432000  |
| value_loss         | 3.39e+04 |
---------------------------------
---------------------------------
| avg reward         | -590     |
| explained_variance | -2.65    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 93000    |
| policy_entropy     | 0        |
| total_timesteps    | 7440000  |
| value_loss         | 3.46e+03 |
---------------------------------
----------------------------------
| avg reward         | -2.45e+03 |
| explained_variance | 0.559     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 93100     |
| policy_entropy     | 0         |
| total_timesteps    | 7448000   |
| value_loss         | 3.67e+03  |
----------------------------------
----------------------------------
| avg reward         | -3.34e+03 |
| explained_variance | 0.0547    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 93200     |
| policy_entropy     | 0         |
| total_timesteps    | 7456000   |
| value_loss         | 2.66e+05  |
----------------------------------
----------------------------------
| avg reward         | -7.36e+03 |
| explained_variance | -11.4     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 93300     |
| policy_entropy     | 0         |
| total_timesteps    | 7464000   |
| value_loss         | 1.09e+05  |
----------------------------------
---------------------------------
| avg reward         | 6.4e+03  |
| explained_variance | 0.175    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 93400    |
| policy_entropy     | 0        |
| total_timesteps    | 7472000  |
| value_loss         | 1.18e+06 |
---------------------------------
----------------------------------
| avg reward         | -5.58e+03 |
| explained_variance | 0.0296    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 93500     |
| policy_entropy     | 0         |
| total_timesteps    | 7480000   |
| value_loss         | 1.17e+06  |
----------------------------------
---------------------------------
| avg reward         | 2.46e+03 |
| explained_variance | 0.824    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 93600    |
| policy_entropy     | 0        |
| total_timesteps    | 7488000  |
| value_loss         | 3.77e+03 |
---------------------------------
---------------------------------
| avg reward         | 5.12e+03 |
| explained_variance | 0.0838   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 93700    |
| policy_entropy     | 0        |
| total_timesteps    | 7496000  |
| value_loss         | 9.34e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.21e+03 |
| explained_variance | -0.493    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 93800     |
| policy_entropy     | 0         |
| total_timesteps    | 7504000   |
| value_loss         | 5.34e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.8e+03  |
| explained_variance | 0.505    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 93900    |
| policy_entropy     | 0        |
| total_timesteps    | 7512000  |
| value_loss         | 9.25e+03 |
---------------------------------
---------------------------------
| avg reward         | -156     |
| explained_variance | 0.535    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94000    |
| policy_entropy     | 0        |
| total_timesteps    | 7520000  |
| value_loss         | 592      |
---------------------------------
---------------------------------
| avg reward         | -1.3e+03 |
| explained_variance | 0.865    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94100    |
| policy_entropy     | 0        |
| total_timesteps    | 7528000  |
| value_loss         | 1.01e+03 |
---------------------------------
----------------------------------
| avg reward         | -4.53e+03 |
| explained_variance | -1.07     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 94200     |
| policy_entropy     | 0         |
| total_timesteps    | 7536000   |
| value_loss         | 5.55e+05  |
----------------------------------
---------------------------------
| avg reward         | 3.2e+03  |
| explained_variance | -2.45    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94300    |
| policy_entropy     | 0        |
| total_timesteps    | 7544000  |
| value_loss         | 2.27e+04 |
---------------------------------
---------------------------------
| avg reward         | 7.79e+03 |
| explained_variance | -1.67    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94400    |
| policy_entropy     | 0        |
| total_timesteps    | 7552000  |
| value_loss         | 1.08e+06 |
---------------------------------
----------------------------------
| avg reward         | -5.77e+03 |
| explained_variance | 0.0453    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 94500     |
| policy_entropy     | 0         |
| total_timesteps    | 7560000   |
| value_loss         | 8e+05     |
----------------------------------
---------------------------------
| avg reward         | 4.61e+03 |
| explained_variance | 0.112    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94600    |
| policy_entropy     | 0        |
| total_timesteps    | 7568000  |
| value_loss         | 4.8e+05  |
---------------------------------
---------------------------------
| avg reward         | 501      |
| explained_variance | 0.0268   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94700    |
| policy_entropy     | 0        |
| total_timesteps    | 7576000  |
| value_loss         | 1.2e+04  |
---------------------------------
---------------------------------
| avg reward         | 3.6e+03  |
| explained_variance | -0.812   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 94800    |
| policy_entropy     | 0        |
| total_timesteps    | 7584000  |
| value_loss         | 3.15e+05 |
---------------------------------
----------------------------------
| avg reward         | -3.41e+03 |
| explained_variance | 0.121     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 94900     |
| policy_entropy     | 0         |
| total_timesteps    | 7592000   |
| value_loss         | 6.85e+03  |
----------------------------------
---------------------------------
| avg reward         | 6.12e+03 |
| explained_variance | -49.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 95000    |
| policy_entropy     | 0        |
| total_timesteps    | 7600000  |
| value_loss         | 4.01e+05 |
---------------------------------
----------------------------------
| avg reward         | -8.17e+03 |
| explained_variance | 0.109     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 95100     |
| policy_entropy     | 0         |
| total_timesteps    | 7608000   |
| value_loss         | 3.81e+04  |
----------------------------------
----------------------------------
| avg reward         | -2.75e+03 |
| explained_variance | 0.597     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 95200     |
| policy_entropy     | 0         |
| total_timesteps    | 7616000   |
| value_loss         | 4.18e+03  |
----------------------------------
---------------------------------
| avg reward         | 7.03e+03 |
| explained_variance | -0.877   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 95300    |
| policy_entropy     | 0        |
| total_timesteps    | 7624000  |
| value_loss         | 1.22e+06 |
---------------------------------
---------------------------------
| avg reward         | 7.3e+03  |
| explained_variance | 0.699    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 95400    |
| policy_entropy     | 0        |
| total_timesteps    | 7632000  |
| value_loss         | 3.13e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.14e+03 |
| explained_variance | 0.126     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 95500     |
| policy_entropy     | 0         |
| total_timesteps    | 7640000   |
| value_loss         | 3.01e+05  |
----------------------------------
---------------------------------
| avg reward         | 2.47e+03 |
| explained_variance | -0.878   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 95600    |
| policy_entropy     | 0        |
| total_timesteps    | 7648000  |
| value_loss         | 1.32e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.46e+03 |
| explained_variance | 0.854     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 95700     |
| policy_entropy     | 0         |
| total_timesteps    | 7656000   |
| value_loss         | 1.36e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.73e+03 |
| explained_variance | -24.7    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 95800    |
| policy_entropy     | 0        |
| total_timesteps    | 7664000  |
| value_loss         | 3.4e+04  |
---------------------------------
---------------------------------
| avg reward         | 3.84e+03 |
| explained_variance | 0.719    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 95900    |
| policy_entropy     | 0        |
| total_timesteps    | 7672000  |
| value_loss         | 9.4e+03  |
---------------------------------
---------------------------------
| avg reward         | 3.5e+03  |
| explained_variance | -2.4     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96000    |
| policy_entropy     | 0        |
| total_timesteps    | 7680000  |
| value_loss         | 2.84e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.26e+03 |
| explained_variance | 0.277    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96100    |
| policy_entropy     | 0        |
| total_timesteps    | 7688000  |
| value_loss         | 4.46e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.6e+03  |
| explained_variance | 0.0839   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96200    |
| policy_entropy     | 0        |
| total_timesteps    | 7696000  |
| value_loss         | 1.56e+05 |
---------------------------------
---------------------------------
| avg reward         | 8.04e+03 |
| explained_variance | 0.582    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96300    |
| policy_entropy     | 0        |
| total_timesteps    | 7704000  |
| value_loss         | 3.93e+04 |
---------------------------------
---------------------------------
| avg reward         | 9.69e+03 |
| explained_variance | 0.467    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96400    |
| policy_entropy     | 0        |
| total_timesteps    | 7712000  |
| value_loss         | 5.28e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.74e+03 |
| explained_variance | 0.852    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96500    |
| policy_entropy     | 0        |
| total_timesteps    | 7720000  |
| value_loss         | 5.34e+03 |
---------------------------------
---------------------------------
| avg reward         | -3e+03   |
| explained_variance | 0.589    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96600    |
| policy_entropy     | 0        |
| total_timesteps    | 7728000  |
| value_loss         | 5.49e+03 |
---------------------------------
---------------------------------
| avg reward         | 5.95e+03 |
| explained_variance | -3.58    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96700    |
| policy_entropy     | 0        |
| total_timesteps    | 7736000  |
| value_loss         | 1.1e+06  |
---------------------------------
---------------------------------
| avg reward         | -8.5e+03 |
| explained_variance | -0.0179  |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 96800    |
| policy_entropy     | 0        |
| total_timesteps    | 7744000  |
| value_loss         | 1.85e+06 |
---------------------------------
----------------------------------
| avg reward         | -3.98e+03 |
| explained_variance | -0.303    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 96900     |
| policy_entropy     | 0         |
| total_timesteps    | 7752000   |
| value_loss         | 6.7e+05   |
----------------------------------
---------------------------------
| avg reward         | -5e+03   |
| explained_variance | 0.452    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 97000    |
| policy_entropy     | 0        |
| total_timesteps    | 7760000  |
| value_loss         | 1.4e+04  |
---------------------------------
----------------------------------
| avg reward         | -2.38e+03 |
| explained_variance | -1.01     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 97100     |
| policy_entropy     | 0         |
| total_timesteps    | 7768000   |
| value_loss         | 1.51e+05  |
----------------------------------
---------------------------------
| avg reward         | 7.13e+03 |
| explained_variance | 0.492    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 97200    |
| policy_entropy     | 0        |
| total_timesteps    | 7776000  |
| value_loss         | 3.44e+04 |
---------------------------------
---------------------------------
| avg reward         | 0.549    |
| explained_variance | 0.717    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 97300    |
| policy_entropy     | 0        |
| total_timesteps    | 7784000  |
| value_loss         | 533      |
---------------------------------
---------------------------------
| avg reward         | -4.9e+03 |
| explained_variance | 0.319    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 97400    |
| policy_entropy     | 0        |
| total_timesteps    | 7792000  |
| value_loss         | 1.28e+04 |
---------------------------------
----------------------------------
| avg reward         | -6.95e+03 |
| explained_variance | 0.117     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 97500     |
| policy_entropy     | 0         |
| total_timesteps    | 7800000   |
| value_loss         | 2.72e+04  |
----------------------------------
----------------------------------
| avg reward         | -2.17e+03 |
| explained_variance | 0.726     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 97600     |
| policy_entropy     | 0         |
| total_timesteps    | 7808000   |
| value_loss         | 2.78e+03  |
----------------------------------
----------------------------------
| avg reward         | -7.35e+03 |
| explained_variance | 0.141     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 97700     |
| policy_entropy     | 0         |
| total_timesteps    | 7816000   |
| value_loss         | 3.03e+04  |
----------------------------------
----------------------------------
| avg reward         | -2.18e+03 |
| explained_variance | -0.391    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 97800     |
| policy_entropy     | 0         |
| total_timesteps    | 7824000   |
| value_loss         | 2.63e+05  |
----------------------------------
---------------------------------
| avg reward         | 7.24e+03 |
| explained_variance | 0.202    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 97900    |
| policy_entropy     | 0        |
| total_timesteps    | 7832000  |
| value_loss         | 1.51e+06 |
---------------------------------
----------------------------------
| avg reward         | -2.39e+03 |
| explained_variance | 0.705     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 98000     |
| policy_entropy     | 0         |
| total_timesteps    | 7840000   |
| value_loss         | 3.25e+03  |
----------------------------------
---------------------------------
| avg reward         | 2.01e+03 |
| explained_variance | -1.37    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 98100    |
| policy_entropy     | 0        |
| total_timesteps    | 7848000  |
| value_loss         | 1.13e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.22e+03 |
| explained_variance | -2.88    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 98200    |
| policy_entropy     | 0        |
| total_timesteps    | 7856000  |
| value_loss         | 2.68e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.65e+03 |
| explained_variance | -36.5     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 98300     |
| policy_entropy     | 0         |
| total_timesteps    | 7864000   |
| value_loss         | 8.54e+04  |
----------------------------------
----------------------------------
| avg reward         | -7.51e+03 |
| explained_variance | -89.4     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 98400     |
| policy_entropy     | 0         |
| total_timesteps    | 7872000   |
| value_loss         | 7.29e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.41e+03 |
| explained_variance | 0.137    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 98500    |
| policy_entropy     | 0        |
| total_timesteps    | 7880000  |
| value_loss         | 6.74e+04 |
---------------------------------
---------------------------------
| avg reward         | 4.1e+03  |
| explained_variance | -44.9    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 98600    |
| policy_entropy     | 0        |
| total_timesteps    | 7888000  |
| value_loss         | 2.38e+05 |
---------------------------------
---------------------------------
| avg reward         | 7.66e+03 |
| explained_variance | 0.546    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 98700    |
| policy_entropy     | 0        |
| total_timesteps    | 7896000  |
| value_loss         | 3.21e+04 |
---------------------------------
----------------------------------
| avg reward         | -7.87e+03 |
| explained_variance | 0.189     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 98800     |
| policy_entropy     | 0         |
| total_timesteps    | 7904000   |
| value_loss         | 3.43e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.54e+03 |
| explained_variance | 0.719    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 98900    |
| policy_entropy     | 0        |
| total_timesteps    | 7912000  |
| value_loss         | 9.24e+03 |
---------------------------------
---------------------------------
| avg reward         | 9.48e+03 |
| explained_variance | -1.15    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 99000    |
| policy_entropy     | 0        |
| total_timesteps    | 7920000  |
| value_loss         | 2.55e+06 |
---------------------------------
---------------------------------
| avg reward         | 4.28e+03 |
| explained_variance | 0.637    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 99100    |
| policy_entropy     | 0        |
| total_timesteps    | 7928000  |
| value_loss         | 1.09e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.09e+03 |
| explained_variance | -2.65     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 99200     |
| policy_entropy     | 0         |
| total_timesteps    | 7936000   |
| value_loss         | 9.17e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.58e+03 |
| explained_variance | -4.62    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 99300    |
| policy_entropy     | 0        |
| total_timesteps    | 7944000  |
| value_loss         | 3.89e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.92e+03 |
| explained_variance | 0.812    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 99400    |
| policy_entropy     | 0        |
| total_timesteps    | 7952000  |
| value_loss         | 5.7e+03  |
---------------------------------
---------------------------------
| avg reward         | 1.25e+03 |
| explained_variance | -1.04    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 99500    |
| policy_entropy     | 0        |
| total_timesteps    | 7960000  |
| value_loss         | 4.78e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.01e+04 |
| explained_variance | 0.219     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 99600     |
| policy_entropy     | 0         |
| total_timesteps    | 7968000   |
| value_loss         | 5.72e+04  |
----------------------------------
----------------------------------
| avg reward         | -8.41e+03 |
| explained_variance | 0.206     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 99700     |
| policy_entropy     | 0         |
| total_timesteps    | 7976000   |
| value_loss         | 3.98e+04  |
----------------------------------
----------------------------------
| avg reward         | -8.85e+03 |
| explained_variance | -0.413    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 99800     |
| policy_entropy     | 0.0274    |
| total_timesteps    | 7984000   |
| value_loss         | 4.49e+06  |
----------------------------------
----------------------------------
| avg reward         | -4.11e+03 |
| explained_variance | 0.0485    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 99900     |
| policy_entropy     | 0.0137    |
| total_timesteps    | 7992000   |
| value_loss         | 1.16e+06  |
----------------------------------
---------------------------------
| avg reward         | 3.98e+03 |
| explained_variance | 0.0282   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 100000   |
| policy_entropy     | 0.0235   |
| total_timesteps    | 8000000  |
| value_loss         | 1.7e+06  |
---------------------------------
---------------------------------
| avg reward         | -506     |
| explained_variance | 0.882    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 100100   |
| policy_entropy     | 0        |
| total_timesteps    | 8008000  |
| value_loss         | 313      |
---------------------------------
----------------------------------
| avg reward         | -3.87e+03 |
| explained_variance | -0.546    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 100200    |
| policy_entropy     | 0.0213    |
| total_timesteps    | 8016000   |
| value_loss         | 6.08e+05  |
----------------------------------
----------------------------------
| avg reward         | -2.49e+03 |
| explained_variance | 0.599     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 100300    |
| policy_entropy     | 0         |
| total_timesteps    | 8024000   |
| value_loss         | 3.84e+03  |
----------------------------------
----------------------------------
| avg reward         | -6.28e+03 |
| explained_variance | 0.2       |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 100400    |
| policy_entropy     | 0.0028    |
| total_timesteps    | 8032000   |
| value_loss         | 1.2e+06   |
----------------------------------
---------------------------------
| avg reward         | -3.5e+03 |
| explained_variance | 0.307    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 100500   |
| policy_entropy     | 0        |
| total_timesteps    | 8040000  |
| value_loss         | 6.52e+03 |
---------------------------------
---------------------------------
| avg reward         | 8.09e+03 |
| explained_variance | 0.23     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 100600   |
| policy_entropy     | 0.00675  |
| total_timesteps    | 8048000  |
| value_loss         | 1.93e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.37e+03 |
| explained_variance | 0.735     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 100700    |
| policy_entropy     | 0         |
| total_timesteps    | 8056000   |
| value_loss         | 918       |
----------------------------------
---------------------------------
| avg reward         | 5.36e+03 |
| explained_variance | -1.27    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 100800   |
| policy_entropy     | 0.0114   |
| total_timesteps    | 8064000  |
| value_loss         | 8.55e+05 |
---------------------------------
----------------------------------
| avg reward         | -5.01e+03 |
| explained_variance | 0.0246    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 100900    |
| policy_entropy     | 0.00914   |
| total_timesteps    | 8072000   |
| value_loss         | 6.76e+05  |
----------------------------------
---------------------------------
| avg reward         | 4.14e+03 |
| explained_variance | -54.2    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 101000   |
| policy_entropy     | 0.0109   |
| total_timesteps    | 8080000  |
| value_loss         | 3.17e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.03e+04 |
| explained_variance | 0.315    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 101100   |
| policy_entropy     | 0        |
| total_timesteps    | 8088000  |
| value_loss         | 6.68e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.43e+03 |
| explained_variance | 0.122     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 101200    |
| policy_entropy     | 0.0271    |
| total_timesteps    | 8096000   |
| value_loss         | 3.66e+05  |
----------------------------------
---------------------------------
| avg reward         | 4.87e+03 |
| explained_variance | -2.42    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 101300   |
| policy_entropy     | 0.0131   |
| total_timesteps    | 8104000  |
| value_loss         | 5.5e+05  |
---------------------------------
---------------------------------
| avg reward         | 2.35e+03 |
| explained_variance | 0.686    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 101400   |
| policy_entropy     | 0        |
| total_timesteps    | 8112000  |
| value_loss         | 3.93e+03 |
---------------------------------
----------------------------------
| avg reward         | -7.73e+03 |
| explained_variance | 0.154     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 101500    |
| policy_entropy     | 0.0115    |
| total_timesteps    | 8120000   |
| value_loss         | 1.43e+06  |
----------------------------------
---------------------------------
| avg reward         | 6.83e+03 |
| explained_variance | 0.527    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 101600   |
| policy_entropy     | 0        |
| total_timesteps    | 8128000  |
| value_loss         | 2.78e+04 |
---------------------------------
---------------------------------
| avg reward         | 4.59e+03 |
| explained_variance | 0.681    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 101700   |
| policy_entropy     | 0        |
| total_timesteps    | 8136000  |
| value_loss         | 1.14e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.62e+03 |
| explained_variance | -2.49     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 101800    |
| policy_entropy     | 0.00877   |
| total_timesteps    | 8144000   |
| value_loss         | 7.14e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.88e+03 |
| explained_variance | 0.185     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 101900    |
| policy_entropy     | 0.0117    |
| total_timesteps    | 8152000   |
| value_loss         | 1.1e+05   |
----------------------------------
----------------------------------
| avg reward         | -7.04e+03 |
| explained_variance | -21.6     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 102000    |
| policy_entropy     | 0         |
| total_timesteps    | 8160000   |
| value_loss         | 1.49e+05  |
----------------------------------
---------------------------------
| avg reward         | 2.45e+03 |
| explained_variance | 0.212    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 102100   |
| policy_entropy     | 0.014    |
| total_timesteps    | 8168000  |
| value_loss         | 1.35e+05 |
---------------------------------
---------------------------------
| avg reward         | 7.69e+03 |
| explained_variance | -54.7    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 102200   |
| policy_entropy     | 4.86e-16 |
| total_timesteps    | 8176000  |
| value_loss         | 9.21e+05 |
---------------------------------
---------------------------------
| avg reward         | 3.73e+03 |
| explained_variance | 0.615    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 102300   |
| policy_entropy     | 0        |
| total_timesteps    | 8184000  |
| value_loss         | 8.32e+03 |
---------------------------------
---------------------------------
| avg reward         | -258     |
| explained_variance | 0.919    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 102400   |
| policy_entropy     | 0        |
| total_timesteps    | 8192000  |
| value_loss         | 327      |
---------------------------------
----------------------------------
| avg reward         | -5.77e+03 |
| explained_variance | 0.155     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 102500    |
| policy_entropy     | 0         |
| total_timesteps    | 8200000   |
| value_loss         | 1.03e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.21e+03 |
| explained_variance | -4.25     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 102600    |
| policy_entropy     | 0         |
| total_timesteps    | 8208000   |
| value_loss         | 1.05e+04  |
----------------------------------
---------------------------------
| avg reward         | 2.95e+03 |
| explained_variance | 0.243    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 102700   |
| policy_entropy     | 0        |
| total_timesteps    | 8216000  |
| value_loss         | 2.48e+05 |
---------------------------------
---------------------------------
| avg reward         | 7.6e+03  |
| explained_variance | 0.386    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 102800   |
| policy_entropy     | 0        |
| total_timesteps    | 8224000  |
| value_loss         | 3.87e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.22e+03 |
| explained_variance | -5.34    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 102900   |
| policy_entropy     | 0        |
| total_timesteps    | 8232000  |
| value_loss         | 1.18e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.06e+04 |
| explained_variance | 0.0831    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103000    |
| policy_entropy     | 0         |
| total_timesteps    | 8240000   |
| value_loss         | 6.95e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.01e+04 |
| explained_variance | 0.14      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 103100    |
| policy_entropy     | 0         |
| total_timesteps    | 8248000   |
| value_loss         | 5.77e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.34e+03 |
| explained_variance | 0.77     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 103200   |
| policy_entropy     | 0        |
| total_timesteps    | 8256000  |
| value_loss         | 6.63e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.05e+04 |
| explained_variance | -17.7     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103300    |
| policy_entropy     | 0         |
| total_timesteps    | 8264000   |
| value_loss         | 3.16e+05  |
----------------------------------
----------------------------------
| avg reward         | -4.86e+03 |
| explained_variance | 0.474     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103400    |
| policy_entropy     | 0         |
| total_timesteps    | 8272000   |
| value_loss         | 1.25e+04  |
----------------------------------
---------------------------------
| avg reward         | -51.5    |
| explained_variance | 0.79     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 103500   |
| policy_entropy     | 0        |
| total_timesteps    | 8280000  |
| value_loss         | 444      |
---------------------------------
----------------------------------
| avg reward         | -6.06e+03 |
| explained_variance | 0.108     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103600    |
| policy_entropy     | 0         |
| total_timesteps    | 8288000   |
| value_loss         | 2.24e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.15e+04 |
| explained_variance | 0.114     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103700    |
| policy_entropy     | 0         |
| total_timesteps    | 8296000   |
| value_loss         | 7.55e+04  |
----------------------------------
----------------------------------
| avg reward         | -6.66e+03 |
| explained_variance | 0.12      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103800    |
| policy_entropy     | 0         |
| total_timesteps    | 8304000   |
| value_loss         | 2.52e+04  |
----------------------------------
----------------------------------
| avg reward         | -8.46e+03 |
| explained_variance | -19       |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 103900    |
| policy_entropy     | 0         |
| total_timesteps    | 8312000   |
| value_loss         | 1.89e+05  |
----------------------------------
---------------------------------
| avg reward         | 6.38e+03 |
| explained_variance | 0.728    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104000   |
| policy_entropy     | 0        |
| total_timesteps    | 8320000  |
| value_loss         | 2.14e+04 |
---------------------------------
---------------------------------
| avg reward         | 4.5e+03  |
| explained_variance | 0.753    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104100   |
| policy_entropy     | 0        |
| total_timesteps    | 8328000  |
| value_loss         | 1.36e+04 |
---------------------------------
---------------------------------
| avg reward         | 4.32e+03 |
| explained_variance | 0.78     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104200   |
| policy_entropy     | 0        |
| total_timesteps    | 8336000  |
| value_loss         | 1.06e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.51e+03 |
| explained_variance | 0.897    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104300   |
| policy_entropy     | 0        |
| total_timesteps    | 8344000  |
| value_loss         | 1.75e+03 |
---------------------------------
---------------------------------
| avg reward         | -346     |
| explained_variance | 0.183    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104400   |
| policy_entropy     | 0        |
| total_timesteps    | 8352000  |
| value_loss         | 2.9e+03  |
---------------------------------
---------------------------------
| avg reward         | 1.28e+04 |
| explained_variance | -1.94    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104500   |
| policy_entropy     | 0        |
| total_timesteps    | 8360000  |
| value_loss         | 1.28e+07 |
---------------------------------
---------------------------------
| avg reward         | 8.56e+03 |
| explained_variance | -30.5    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104600   |
| policy_entropy     | 0        |
| total_timesteps    | 8368000  |
| value_loss         | 5.57e+05 |
---------------------------------
---------------------------------
| avg reward         | -266     |
| explained_variance | 0.723    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 104700   |
| policy_entropy     | 0        |
| total_timesteps    | 8376000  |
| value_loss         | 1.53e+03 |
---------------------------------
----------------------------------
| avg reward         | -4.65e+03 |
| explained_variance | -0.432    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 104800    |
| policy_entropy     | 0         |
| total_timesteps    | 8384000   |
| value_loss         | 1.33e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.17e+04 |
| explained_variance | -1.1      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 104900    |
| policy_entropy     | 0         |
| total_timesteps    | 8392000   |
| value_loss         | 3.73e+06  |
----------------------------------
----------------------------------
| avg reward         | -4.17e+03 |
| explained_variance | -0.471    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 105000    |
| policy_entropy     | 0         |
| total_timesteps    | 8400000   |
| value_loss         | 1.85e+06  |
----------------------------------
----------------------------------
| avg reward         | -3.45e+03 |
| explained_variance | 0.398     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 105100    |
| policy_entropy     | 0         |
| total_timesteps    | 8408000   |
| value_loss         | 7.83e+03  |
----------------------------------
----------------------------------
| avg reward         | -3.99e+03 |
| explained_variance | -61.1     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 105200    |
| policy_entropy     | 0         |
| total_timesteps    | 8416000   |
| value_loss         | 2.05e+05  |
----------------------------------
----------------------------------
| avg reward         | -9.67e+03 |
| explained_variance | 0.218     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 105300    |
| policy_entropy     | 0         |
| total_timesteps    | 8424000   |
| value_loss         | 5.34e+04  |
----------------------------------
---------------------------------
| avg reward         | 2.62e+03 |
| explained_variance | -0.964   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 105400   |
| policy_entropy     | 0        |
| total_timesteps    | 8432000  |
| value_loss         | 1.89e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.05e+04 |
| explained_variance | 0.12      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 105500    |
| policy_entropy     | 0         |
| total_timesteps    | 8440000   |
| value_loss         | 6.22e+04  |
----------------------------------
----------------------------------
| avg reward         | -3.08e+03 |
| explained_variance | -2.01     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 105600    |
| policy_entropy     | 0         |
| total_timesteps    | 8448000   |
| value_loss         | 1.94e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.85e+03 |
| explained_variance | -5.21    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 105700   |
| policy_entropy     | 0        |
| total_timesteps    | 8456000  |
| value_loss         | 4.78e+04 |
---------------------------------
---------------------------------
| avg reward         | -546     |
| explained_variance | 0.868    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 105800   |
| policy_entropy     | 0        |
| total_timesteps    | 8464000  |
| value_loss         | 404      |
---------------------------------
---------------------------------
| avg reward         | 2.39e+03 |
| explained_variance | 0.696    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 105900   |
| policy_entropy     | 0        |
| total_timesteps    | 8472000  |
| value_loss         | 3.11e+03 |
---------------------------------
----------------------------------
| avg reward         | -6.84e+03 |
| explained_variance | 0.0516    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 106000    |
| policy_entropy     | 0         |
| total_timesteps    | 8480000   |
| value_loss         | 2.67e+04  |
----------------------------------
---------------------------------
| avg reward         | 8.49e+03 |
| explained_variance | -1.26    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 106100   |
| policy_entropy     | 0.0137   |
| total_timesteps    | 8488000  |
| value_loss         | 2.13e+06 |
---------------------------------
----------------------------------
| avg reward         | -9.06e+03 |
| explained_variance | 0.171     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 106200    |
| policy_entropy     | 0         |
| total_timesteps    | 8496000   |
| value_loss         | 4.63e+04  |
----------------------------------
----------------------------------
| avg reward         | -4.63e+03 |
| explained_variance | 0.0189    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 106300    |
| policy_entropy     | 0.023     |
| total_timesteps    | 8504000   |
| value_loss         | 2.36e+06  |
----------------------------------
---------------------------------
| avg reward         | 1.12e+04 |
| explained_variance | 0.517    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 106400   |
| policy_entropy     | 0        |
| total_timesteps    | 8512000  |
| value_loss         | 7.54e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.33e+03 |
| explained_variance | -0.363   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 106500   |
| policy_entropy     | 0.0249   |
| total_timesteps    | 8520000  |
| value_loss         | 2.57e+05 |
---------------------------------
---------------------------------
| avg reward         | 9.16e+03 |
| explained_variance | 0.659    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 106600   |
| policy_entropy     | 0        |
| total_timesteps    | 8528000  |
| value_loss         | 4.93e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.04e+04 |
| explained_variance | 0.533    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 106700   |
| policy_entropy     | 0        |
| total_timesteps    | 8536000  |
| value_loss         | 7.58e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.23e+03 |
| explained_variance | 0.0976    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 106800    |
| policy_entropy     | 0.0128    |
| total_timesteps    | 8544000   |
| value_loss         | 1.67e+05  |
----------------------------------
---------------------------------
| avg reward         | -629     |
| explained_variance | 0.829    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 106900   |
| policy_entropy     | 0        |
| total_timesteps    | 8552000  |
| value_loss         | 831      |
---------------------------------
----------------------------------
| avg reward         | -2.24e+03 |
| explained_variance | -2.1      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 107000    |
| policy_entropy     | 0.026     |
| total_timesteps    | 8560000   |
| value_loss         | 2.12e+05  |
----------------------------------
---------------------------------
| avg reward         | 4.95e+03 |
| explained_variance | 0.703    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 107100   |
| policy_entropy     | 0        |
| total_timesteps    | 8568000  |
| value_loss         | 1.52e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.67e+03 |
| explained_variance | -0.116   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 107200   |
| policy_entropy     | 0.0121   |
| total_timesteps    | 8576000  |
| value_loss         | 8.68e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.02e+04 |
| explained_variance | -0.538    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 107300    |
| policy_entropy     | 0.027     |
| total_timesteps    | 8584000   |
| value_loss         | 4.12e+06  |
----------------------------------
----------------------------------
| avg reward         | -9.39e+03 |
| explained_variance | -1.46     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 107400    |
| policy_entropy     | 0.0131    |
| total_timesteps    | 8592000   |
| value_loss         | 2.82e+06  |
----------------------------------
---------------------------------
| avg reward         | 5.93e+03 |
| explained_variance | 0.0136   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 107500   |
| policy_entropy     | 0        |
| total_timesteps    | 8600000  |
| value_loss         | 1.35e+06 |
---------------------------------
----------------------------------
| avg reward         | -7.69e+03 |
| explained_variance | 0.125     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 107600    |
| policy_entropy     | 0.012     |
| total_timesteps    | 8608000   |
| value_loss         | 1.43e+06  |
----------------------------------
---------------------------------
| avg reward         | 899      |
| explained_variance | -0.961   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 107700   |
| policy_entropy     | 0.0126   |
| total_timesteps    | 8616000  |
| value_loss         | 2.15e+04 |
---------------------------------
---------------------------------
| avg reward         | -942     |
| explained_variance | -1.81    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 107800   |
| policy_entropy     | 0.0107   |
| total_timesteps    | 8624000  |
| value_loss         | 1.21e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.47e+03 |
| explained_variance | 0.27     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 107900   |
| policy_entropy     | 0.00967  |
| total_timesteps    | 8632000  |
| value_loss         | 1.16e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.24e+04 |
| explained_variance | 0.272     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 108000    |
| policy_entropy     | 0         |
| total_timesteps    | 8640000   |
| value_loss         | 8.86e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.02e+04 |
| explained_variance | -0.211   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 108100   |
| policy_entropy     | 0.0105   |
| total_timesteps    | 8648000  |
| value_loss         | 3.36e+06 |
---------------------------------
----------------------------------
| avg reward         | -9.89e+03 |
| explained_variance | -73.6     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 108200    |
| policy_entropy     | 0         |
| total_timesteps    | 8656000   |
| value_loss         | 8.23e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.01e+04 |
| explained_variance | -64.9     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 108300    |
| policy_entropy     | 0         |
| total_timesteps    | 8664000   |
| value_loss         | 8.59e+05  |
----------------------------------
---------------------------------
| avg reward         | 5.27e+03 |
| explained_variance | -4.4     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 108400   |
| policy_entropy     | 0.0267   |
| total_timesteps    | 8672000  |
| value_loss         | 1.01e+06 |
---------------------------------
---------------------------------
| avg reward         | 9.21e+03 |
| explained_variance | -1.31    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 108500   |
| policy_entropy     | 0.0107   |
| total_timesteps    | 8680000  |
| value_loss         | 2.59e+06 |
---------------------------------
----------------------------------
| avg reward         | -6.49e+03 |
| explained_variance | 0.395     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 108600    |
| policy_entropy     | 0         |
| total_timesteps    | 8688000   |
| value_loss         | 2.29e+04  |
----------------------------------
---------------------------------
| avg reward         | 422      |
| explained_variance | 0.916    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 108700   |
| policy_entropy     | 0        |
| total_timesteps    | 8696000  |
| value_loss         | 654      |
---------------------------------
---------------------------------
| avg reward         | 286      |
| explained_variance | 0.927    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 108800   |
| policy_entropy     | 0        |
| total_timesteps    | 8704000  |
| value_loss         | 413      |
---------------------------------
----------------------------------
| avg reward         | -5.38e+03 |
| explained_variance | -2.43     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 108900    |
| policy_entropy     | 0.00856   |
| total_timesteps    | 8712000   |
| value_loss         | 6.46e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.03e+04 |
| explained_variance | -2.53    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109000   |
| policy_entropy     | 0.0092   |
| total_timesteps    | 8720000  |
| value_loss         | 2.47e+06 |
---------------------------------
---------------------------------
| avg reward         | 2.08e+03 |
| explained_variance | -1.01    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109100   |
| policy_entropy     | 0.00765  |
| total_timesteps    | 8728000  |
| value_loss         | 1.27e+05 |
---------------------------------
---------------------------------
| avg reward         | 8.71e+03 |
| explained_variance | -0.348   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109200   |
| policy_entropy     | 0.0142   |
| total_timesteps    | 8736000  |
| value_loss         | 4.31e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.17e+03 |
| explained_variance | 0.825     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 109300    |
| policy_entropy     | 0         |
| total_timesteps    | 8744000   |
| value_loss         | 1.03e+03  |
----------------------------------
---------------------------------
| avg reward         | 8.23e+03 |
| explained_variance | 0.602    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109400   |
| policy_entropy     | 0        |
| total_timesteps    | 8752000  |
| value_loss         | 4.9e+04  |
---------------------------------
---------------------------------
| avg reward         | 4.26e+03 |
| explained_variance | -19      |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109500   |
| policy_entropy     | 0        |
| total_timesteps    | 8760000  |
| value_loss         | 1.81e+05 |
---------------------------------
---------------------------------
| avg reward         | 6.11e+03 |
| explained_variance | -2.38    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109600   |
| policy_entropy     | 0.00818  |
| total_timesteps    | 8768000  |
| value_loss         | 8.46e+05 |
---------------------------------
---------------------------------
| avg reward         | 8.07e+03 |
| explained_variance | -1.32    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109700   |
| policy_entropy     | 0.00769  |
| total_timesteps    | 8776000  |
| value_loss         | 2.01e+06 |
---------------------------------
---------------------------------
| avg reward         | 9.43e+03 |
| explained_variance | 0.053    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 109800   |
| policy_entropy     | 0        |
| total_timesteps    | 8784000  |
| value_loss         | 3.27e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.03e+04 |
| explained_variance | 0.0821    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 109900    |
| policy_entropy     | 0         |
| total_timesteps    | 8792000   |
| value_loss         | 6.12e+04  |
----------------------------------
---------------------------------
| avg reward         | 4.48e+03 |
| explained_variance | -4.07    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 110000   |
| policy_entropy     | 0.0262   |
| total_timesteps    | 8800000  |
| value_loss         | 7.22e+05 |
---------------------------------
---------------------------------
| avg reward         | 2.93e+03 |
| explained_variance | -13.8    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 110100   |
| policy_entropy     | 0.0177   |
| total_timesteps    | 8808000  |
| value_loss         | 1.57e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.07e+04 |
| explained_variance | 0.189     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 110200    |
| policy_entropy     | 0         |
| total_timesteps    | 8816000   |
| value_loss         | 6.96e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.65e+03 |
| explained_variance | -0.321   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 110300   |
| policy_entropy     | 0.0257   |
| total_timesteps    | 8824000  |
| value_loss         | 6.08e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.03e+04 |
| explained_variance | 0.208    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 110400   |
| policy_entropy     | 0.0249   |
| total_timesteps    | 8832000  |
| value_loss         | 6.18e+06 |
---------------------------------
----------------------------------
| avg reward         | -8.75e+03 |
| explained_variance | -0.355    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 110500    |
| policy_entropy     | 0.00944   |
| total_timesteps    | 8840000   |
| value_loss         | 3.69e+06  |
----------------------------------
---------------------------------
| avg reward         | 1.08e+04 |
| explained_variance | 0.44     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 110600   |
| policy_entropy     | 0        |
| total_timesteps    | 8848000  |
| value_loss         | 7.18e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.05e+03 |
| explained_variance | 0.91      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 110700    |
| policy_entropy     | 0         |
| total_timesteps    | 8856000   |
| value_loss         | 1.01e+03  |
----------------------------------
---------------------------------
| avg reward         | -1.2e+04 |
| explained_variance | 0.0122   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 110800   |
| policy_entropy     | 0        |
| total_timesteps    | 8864000  |
| value_loss         | 9.04e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.55e+03 |
| explained_variance | -2.4      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 110900    |
| policy_entropy     | 0.00454   |
| total_timesteps    | 8872000   |
| value_loss         | 2.83e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.09e+04 |
| explained_variance | 0.103     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 111000    |
| policy_entropy     | 0         |
| total_timesteps    | 8880000   |
| value_loss         | 7.19e+04  |
----------------------------------
----------------------------------
| avg reward         | -7.93e+03 |
| explained_variance | -4.92     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 111100    |
| policy_entropy     | 0.00904   |
| total_timesteps    | 8888000   |
| value_loss         | 2.43e+06  |
----------------------------------
---------------------------------
| avg reward         | 2.56e+03 |
| explained_variance | 0.73     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 111200   |
| policy_entropy     | 0        |
| total_timesteps    | 8896000  |
| value_loss         | 6.68e+03 |
---------------------------------
---------------------------------
| avg reward         | 4.34e+03 |
| explained_variance | 0.76     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 111300   |
| policy_entropy     | 0        |
| total_timesteps    | 8904000  |
| value_loss         | 1.32e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.54e+03 |
| explained_variance | 0.363     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 111400    |
| policy_entropy     | 0         |
| total_timesteps    | 8912000   |
| value_loss         | 1.8e+04   |
----------------------------------
----------------------------------
| avg reward         | -7.51e+03 |
| explained_variance | 0.19      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 111500    |
| policy_entropy     | 0.00339   |
| total_timesteps    | 8920000   |
| value_loss         | 1.73e+06  |
----------------------------------
----------------------------------
| avg reward         | -3.63e+03 |
| explained_variance | 0.6       |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 111600    |
| policy_entropy     | 0         |
| total_timesteps    | 8928000   |
| value_loss         | 6.91e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.11e+04 |
| explained_variance | -1.41    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 111700   |
| policy_entropy     | 0.0131   |
| total_timesteps    | 8936000  |
| value_loss         | 3.94e+06 |
---------------------------------
---------------------------------
| avg reward         | 8.13e+03 |
| explained_variance | 0.202    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 111800   |
| policy_entropy     | 0.00844  |
| total_timesteps    | 8944000  |
| value_loss         | 1.54e+06 |
---------------------------------
---------------------------------
| avg reward         | 4.82e+03 |
| explained_variance | 0.84     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 111900   |
| policy_entropy     | 0        |
| total_timesteps    | 8952000  |
| value_loss         | 1.51e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.39e+03 |
| explained_variance | -1.34     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112000    |
| policy_entropy     | 0.0331    |
| total_timesteps    | 8960000   |
| value_loss         | 1.1e+06   |
----------------------------------
----------------------------------
| avg reward         | -1.19e+04 |
| explained_variance | 0.195     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112100    |
| policy_entropy     | 0         |
| total_timesteps    | 8968000   |
| value_loss         | 7.91e+04  |
----------------------------------
----------------------------------
| avg reward         | -5.61e+03 |
| explained_variance | 0.282     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112200    |
| policy_entropy     | 0         |
| total_timesteps    | 8976000   |
| value_loss         | 1.83e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.04e+04 |
| explained_variance | -61.9    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 112300   |
| policy_entropy     | 0.0129   |
| total_timesteps    | 8984000  |
| value_loss         | 1.77e+06 |
---------------------------------
---------------------------------
| avg reward         | 8.18e+03 |
| explained_variance | -0.0577  |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 112400   |
| policy_entropy     | 0.0257   |
| total_timesteps    | 8992000  |
| value_loss         | 4.86e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.28e+04 |
| explained_variance | 0.16      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112500    |
| policy_entropy     | 0         |
| total_timesteps    | 9000000   |
| value_loss         | 9.28e+04  |
----------------------------------
----------------------------------
| avg reward         | -4.79e+03 |
| explained_variance | 0.594     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112600    |
| policy_entropy     | 0         |
| total_timesteps    | 9008000   |
| value_loss         | 1.32e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.33e+04 |
| explained_variance | -86.6     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112700    |
| policy_entropy     | 0.0064    |
| total_timesteps    | 9016000   |
| value_loss         | 1.7e+06   |
----------------------------------
---------------------------------
| avg reward         | 1.07e+04 |
| explained_variance | 0.213    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 112800   |
| policy_entropy     | 0.00523  |
| total_timesteps    | 9024000  |
| value_loss         | 3.44e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.03e+04 |
| explained_variance | 0.0823    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 112900    |
| policy_entropy     | 0         |
| total_timesteps    | 9032000   |
| value_loss         | 6.33e+04  |
----------------------------------
----------------------------------
| avg reward         | -4.44e+03 |
| explained_variance | -0.0433   |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113000    |
| policy_entropy     | 0.0203    |
| total_timesteps    | 9040000   |
| value_loss         | 1.63e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.03e+04 |
| explained_variance | -67.8     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113100    |
| policy_entropy     | 0         |
| total_timesteps    | 9048000   |
| value_loss         | 1.01e+06  |
----------------------------------
----------------------------------
| avg reward         | -4.95e+03 |
| explained_variance | 0.399     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113200    |
| policy_entropy     | 0         |
| total_timesteps    | 9056000   |
| value_loss         | 1.4e+04   |
----------------------------------
----------------------------------
| avg reward         | -1.35e+04 |
| explained_variance | 0.0931    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113300    |
| policy_entropy     | 0         |
| total_timesteps    | 9064000   |
| value_loss         | 1.08e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.25e+04 |
| explained_variance | -117     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 113400   |
| policy_entropy     | 0.0078   |
| total_timesteps    | 9072000  |
| value_loss         | 5.31e+06 |
---------------------------------
----------------------------------
| avg reward         | -3.32e+03 |
| explained_variance | -46.9     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113500    |
| policy_entropy     | 0.0159    |
| total_timesteps    | 9080000   |
| value_loss         | 1.65e+05  |
----------------------------------
----------------------------------
| avg reward         | -5.08e+03 |
| explained_variance | 0.568     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113600    |
| policy_entropy     | 0         |
| total_timesteps    | 9088000   |
| value_loss         | 1.41e+04  |
----------------------------------
----------------------------------
| avg reward         | -7.37e+03 |
| explained_variance | 0.00527   |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 113700    |
| policy_entropy     | 0         |
| total_timesteps    | 9096000   |
| value_loss         | 4.73e+06  |
----------------------------------
---------------------------------
| avg reward         | 543      |
| explained_variance | 0.908    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 113800   |
| policy_entropy     | 0        |
| total_timesteps    | 9104000  |
| value_loss         | 1.12e+03 |
---------------------------------
---------------------------------
| avg reward         | 4.98e+03 |
| explained_variance | -5.84    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 113900   |
| policy_entropy     | 0.0169   |
| total_timesteps    | 9112000  |
| value_loss         | 1.18e+06 |
---------------------------------
---------------------------------
| avg reward         | 8.08e+03 |
| explained_variance | 0.438    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 114000   |
| policy_entropy     | 0        |
| total_timesteps    | 9120000  |
| value_loss         | 4.35e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.43e+04 |
| explained_variance | 0.129     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 114100    |
| policy_entropy     | 0         |
| total_timesteps    | 9128000   |
| value_loss         | 1.19e+05  |
----------------------------------
----------------------------------
| avg reward         | -8.75e+03 |
| explained_variance | -0.503    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 114200    |
| policy_entropy     | 0.00712   |
| total_timesteps    | 9136000   |
| value_loss         | 4.91e+06  |
----------------------------------
---------------------------------
| avg reward         | 4.63e+03 |
| explained_variance | 0.763    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 114300   |
| policy_entropy     | 0        |
| total_timesteps    | 9144000  |
| value_loss         | 1.77e+04 |
---------------------------------
----------------------------------
| avg reward         | -9.83e+03 |
| explained_variance | -19.4     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 114400    |
| policy_entropy     | 0         |
| total_timesteps    | 9152000   |
| value_loss         | 3.09e+05  |
----------------------------------
---------------------------------
| avg reward         | -2.4e+03 |
| explained_variance | -1.15    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 114500   |
| policy_entropy     | 0.0107   |
| total_timesteps    | 9160000  |
| value_loss         | 1.72e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.39e+04 |
| explained_variance | 0.251     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 114600    |
| policy_entropy     | 0         |
| total_timesteps    | 9168000   |
| value_loss         | 1.09e+05  |
----------------------------------
---------------------------------
| avg reward         | 2.44e+03 |
| explained_variance | -6.08    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 114700   |
| policy_entropy     | 0        |
| total_timesteps    | 9176000  |
| value_loss         | 6.2e+04  |
---------------------------------
----------------------------------
| avg reward         | -8.75e+03 |
| explained_variance | -105      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 114800    |
| policy_entropy     | 0.0127    |
| total_timesteps    | 9184000   |
| value_loss         | 1.12e+06  |
----------------------------------
----------------------------------
| avg reward         | -9.23e+03 |
| explained_variance | 0.28      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 114900    |
| policy_entropy     | 0         |
| total_timesteps    | 9192000   |
| value_loss         | 4.92e+04  |
----------------------------------
---------------------------------
| avg reward         | 8.19e+03 |
| explained_variance | 0.124    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 115000   |
| policy_entropy     | 0.0132   |
| total_timesteps    | 9200000  |
| value_loss         | 4.3e+06  |
---------------------------------
---------------------------------
| avg reward         | -1.9e+03 |
| explained_variance | 0.781    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 115100   |
| policy_entropy     | 0        |
| total_timesteps    | 9208000  |
| value_loss         | 2.53e+03 |
---------------------------------
---------------------------------
| avg reward         | 6.47e+03 |
| explained_variance | 0.764    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 115200   |
| policy_entropy     | 0        |
| total_timesteps    | 9216000  |
| value_loss         | 2.59e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.14e+04 |
| explained_variance | 0.63     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 115300   |
| policy_entropy     | 0        |
| total_timesteps    | 9224000  |
| value_loss         | 8.04e+04 |
---------------------------------
----------------------------------
| avg reward         | -2.56e+03 |
| explained_variance | 0.823     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 115400    |
| policy_entropy     | 0         |
| total_timesteps    | 9232000   |
| value_loss         | 4.24e+03  |
----------------------------------
----------------------------------
| avg reward         | -5.43e+03 |
| explained_variance | 0.518     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 115500    |
| policy_entropy     | 0         |
| total_timesteps    | 9240000   |
| value_loss         | 1.72e+04  |
----------------------------------
----------------------------------
| avg reward         | -4.33e+03 |
| explained_variance | 0.764     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 115600    |
| policy_entropy     | 0         |
| total_timesteps    | 9248000   |
| value_loss         | 9.75e+03  |
----------------------------------
----------------------------------
| avg reward         | -6.29e+03 |
| explained_variance | -0.495    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 115700    |
| policy_entropy     | 0.0129    |
| total_timesteps    | 9256000   |
| value_loss         | 2.53e+06  |
----------------------------------
---------------------------------
| avg reward         | 8.05e+03 |
| explained_variance | 0.744    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 115800   |
| policy_entropy     | 0        |
| total_timesteps    | 9264000  |
| value_loss         | 3.91e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.29e+04 |
| explained_variance | -1.24    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 115900   |
| policy_entropy     | 0        |
| total_timesteps    | 9272000  |
| value_loss         | 4.95e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.43e+03 |
| explained_variance | 0.288     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 116000    |
| policy_entropy     | 0         |
| total_timesteps    | 9280000   |
| value_loss         | 5.7e+03   |
----------------------------------
---------------------------------
| avg reward         | 4.03e+03 |
| explained_variance | 0.759    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 116100   |
| policy_entropy     | 0        |
| total_timesteps    | 9288000  |
| value_loss         | 1.06e+04 |
---------------------------------
---------------------------------
| avg reward         | 3.96e+03 |
| explained_variance | 0.768    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 116200   |
| policy_entropy     | 0        |
| total_timesteps    | 9296000  |
| value_loss         | 1.15e+04 |
---------------------------------
---------------------------------
| avg reward         | -700     |
| explained_variance | 0.871    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 116300   |
| policy_entropy     | 0        |
| total_timesteps    | 9304000  |
| value_loss         | 1.15e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.33e+04 |
| explained_variance | -58.7     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 116400    |
| policy_entropy     | 0         |
| total_timesteps    | 9312000   |
| value_loss         | 1.48e+06  |
----------------------------------
----------------------------------
| avg reward         | -6.85e+03 |
| explained_variance | -48.8     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 116500    |
| policy_entropy     | 0         |
| total_timesteps    | 9320000   |
| value_loss         | 3.83e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.11e+04 |
| explained_variance | 0.251     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 116600    |
| policy_entropy     | 0         |
| total_timesteps    | 9328000   |
| value_loss         | 6.66e+04  |
----------------------------------
----------------------------------
| avg reward         | -5.44e+03 |
| explained_variance | 0.165     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 116700    |
| policy_entropy     | 0.0126    |
| total_timesteps    | 9336000   |
| value_loss         | 9.15e+05  |
----------------------------------
----------------------------------
| avg reward         | -8.89e+03 |
| explained_variance | -18.9     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 116800    |
| policy_entropy     | 0         |
| total_timesteps    | 9344000   |
| value_loss         | 2.41e+05  |
----------------------------------
---------------------------------
| avg reward         | 2.11e+03 |
| explained_variance | 0.826    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 116900   |
| policy_entropy     | 0        |
| total_timesteps    | 9352000  |
| value_loss         | 5.01e+03 |
---------------------------------
----------------------------------
| avg reward         | -6.96e+03 |
| explained_variance | -1.25     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 117000    |
| policy_entropy     | 0.0136    |
| total_timesteps    | 9360000   |
| value_loss         | 1.43e+06  |
----------------------------------
----------------------------------
| avg reward         | -8.02e+03 |
| explained_variance | -2.39     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 117100    |
| policy_entropy     | 0.0122    |
| total_timesteps    | 9368000   |
| value_loss         | 1.41e+06  |
----------------------------------
---------------------------------
| avg reward         | 5.54e+03 |
| explained_variance | 0.749    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 117200   |
| policy_entropy     | 0        |
| total_timesteps    | 9376000  |
| value_loss         | 2.09e+04 |
---------------------------------
---------------------------------
| avg reward         | 4.72e+03 |
| explained_variance | 0.788    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 117300   |
| policy_entropy     | 0        |
| total_timesteps    | 9384000  |
| value_loss         | 1.39e+04 |
---------------------------------
----------------------------------
| avg reward         | -6.41e+03 |
| explained_variance | 0.549     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 117400    |
| policy_entropy     | 0         |
| total_timesteps    | 9392000   |
| value_loss         | 2.24e+04  |
----------------------------------
---------------------------------
| avg reward         | -5.8e+03 |
| explained_variance | -0.0107  |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 117500   |
| policy_entropy     | 0        |
| total_timesteps    | 9400000  |
| value_loss         | 1.31e+06 |
---------------------------------
----------------------------------
| avg reward         | -2.24e+03 |
| explained_variance | -0.128    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 117600    |
| policy_entropy     | 0         |
| total_timesteps    | 9408000   |
| value_loss         | 2.24e+05  |
----------------------------------
---------------------------------
| avg reward         | -5.8e+03 |
| explained_variance | 0.49     |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 117700   |
| policy_entropy     | 0        |
| total_timesteps    | 9416000  |
| value_loss         | 1.96e+04 |
---------------------------------
---------------------------------
| avg reward         | 4.01e+03 |
| explained_variance | 0.813    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 117800   |
| policy_entropy     | 0        |
| total_timesteps    | 9424000  |
| value_loss         | 1.07e+04 |
---------------------------------
---------------------------------
| avg reward         | 5.95e+03 |
| explained_variance | -3.71    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 117900   |
| policy_entropy     | 0        |
| total_timesteps    | 9432000  |
| value_loss         | 1.21e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.62e+04 |
| explained_variance | -72       |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 118000    |
| policy_entropy     | 0         |
| total_timesteps    | 9440000   |
| value_loss         | 2.18e+06  |
----------------------------------
---------------------------------
| avg reward         | 9.48e+03 |
| explained_variance | 0.114    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 118100   |
| policy_entropy     | 0        |
| total_timesteps    | 9448000  |
| value_loss         | 3.12e+06 |
---------------------------------
---------------------------------
| avg reward         | 5.98e+03 |
| explained_variance | 0.763    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 118200   |
| policy_entropy     | 0        |
| total_timesteps    | 9456000  |
| value_loss         | 2.09e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.42e+03 |
| explained_variance | 0.173     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 118300    |
| policy_entropy     | 0.013     |
| total_timesteps    | 9464000   |
| value_loss         | 6.01e+05  |
----------------------------------
---------------------------------
| avg reward         | 854      |
| explained_variance | -0.69    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 118400   |
| policy_entropy     | 0.0237   |
| total_timesteps    | 9472000  |
| value_loss         | 3e+04    |
---------------------------------
---------------------------------
| avg reward         | 2.91e+03 |
| explained_variance | 0.829    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 118500   |
| policy_entropy     | 0        |
| total_timesteps    | 9480000  |
| value_loss         | 5.29e+03 |
---------------------------------
---------------------------------
| avg reward         | 5.69e+03 |
| explained_variance | 0.0493   |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 118600   |
| policy_entropy     | 0        |
| total_timesteps    | 9488000  |
| value_loss         | 1.21e+06 |
---------------------------------
---------------------------------
| avg reward         | 4.44e+03 |
| explained_variance | -21.4    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 118700   |
| policy_entropy     | 0.0112   |
| total_timesteps    | 9496000  |
| value_loss         | 3.31e+05 |
---------------------------------
----------------------------------
| avg reward         | -2.47e+03 |
| explained_variance | -0.476    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 118800    |
| policy_entropy     | 0.0223    |
| total_timesteps    | 9504000   |
| value_loss         | 3.17e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.21e+04 |
| explained_variance | -134      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 118900    |
| policy_entropy     | 0.00925   |
| total_timesteps    | 9512000   |
| value_loss         | 2.32e+06  |
----------------------------------
---------------------------------
| avg reward         | 8.93e+03 |
| explained_variance | 0.635    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 119000   |
| policy_entropy     | 0        |
| total_timesteps    | 9520000  |
| value_loss         | 4.59e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.69e+03 |
| explained_variance | -2.46     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 119100    |
| policy_entropy     | 0.00494   |
| total_timesteps    | 9528000   |
| value_loss         | 7.36e+05  |
----------------------------------
----------------------------------
| avg reward         | -5.52e+03 |
| explained_variance | -0.475    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 119200    |
| policy_entropy     | 0.00737   |
| total_timesteps    | 9536000   |
| value_loss         | 2.29e+06  |
----------------------------------
----------------------------------
| avg reward         | -6.16e+03 |
| explained_variance | 0.325     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 119300    |
| policy_entropy     | 0         |
| total_timesteps    | 9544000   |
| value_loss         | 2.1e+04   |
----------------------------------
---------------------------------
| avg reward         | 1.19e+04 |
| explained_variance | -40.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 119400   |
| policy_entropy     | 0.00929  |
| total_timesteps    | 9552000  |
| value_loss         | 1.41e+06 |
---------------------------------
---------------------------------
| avg reward         | 5.09e+03 |
| explained_variance | 0.111    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 119500   |
| policy_entropy     | 0        |
| total_timesteps    | 9560000  |
| value_loss         | 8.83e+05 |
---------------------------------
----------------------------------
| avg reward         | -2.83e+03 |
| explained_variance | -1.33     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 119600    |
| policy_entropy     | 0.0121    |
| total_timesteps    | 9568000   |
| value_loss         | 2.6e+05   |
----------------------------------
---------------------------------
| avg reward         | 1.75e+04 |
| explained_variance | -100     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 119700   |
| policy_entropy     | 0.014    |
| total_timesteps    | 9576000  |
| value_loss         | 5.07e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.03e+03 |
| explained_variance | -1.07     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 119800    |
| policy_entropy     | 0.00561   |
| total_timesteps    | 9584000   |
| value_loss         | 1.54e+04  |
----------------------------------
---------------------------------
| avg reward         | 8.16e+03 |
| explained_variance | -25.3    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 119900   |
| policy_entropy     | 0        |
| total_timesteps    | 9592000  |
| value_loss         | 8.91e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.11e+04 |
| explained_variance | -0.0537  |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120000   |
| policy_entropy     | 0        |
| total_timesteps    | 9600000  |
| value_loss         | 4.85e+06 |
---------------------------------
---------------------------------
| avg reward         | 2.83e+03 |
| explained_variance | 0.83     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120100   |
| policy_entropy     | 0        |
| total_timesteps    | 9608000  |
| value_loss         | 4.81e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.3e+04  |
| explained_variance | 0.66     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120200   |
| policy_entropy     | 0        |
| total_timesteps    | 9616000  |
| value_loss         | 1.02e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.58e+03 |
| explained_variance | 0.904    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120300   |
| policy_entropy     | 0        |
| total_timesteps    | 9624000  |
| value_loss         | 2.79e+03 |
---------------------------------
---------------------------------
| avg reward         | 7.3e+03  |
| explained_variance | -2.33    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120400   |
| policy_entropy     | 0.00751  |
| total_timesteps    | 9632000  |
| value_loss         | 1.21e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.41e+04 |
| explained_variance | 0.167     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 120500    |
| policy_entropy     | 0         |
| total_timesteps    | 9640000   |
| value_loss         | 1.09e+05  |
----------------------------------
---------------------------------
| avg reward         | 4.81e+03 |
| explained_variance | -4.52    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120600   |
| policy_entropy     | 0        |
| total_timesteps    | 9648000  |
| value_loss         | 8.81e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.79e+03 |
| explained_variance | 0.141     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 120700    |
| policy_entropy     | 0.00464   |
| total_timesteps    | 9656000   |
| value_loss         | 3.61e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.28e+04 |
| explained_variance | -12.9    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 120800   |
| policy_entropy     | 0        |
| total_timesteps    | 9664000  |
| value_loss         | 5.99e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.64e+04 |
| explained_variance | 0.251     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 120900    |
| policy_entropy     | 0         |
| total_timesteps    | 9672000   |
| value_loss         | 1.51e+05  |
----------------------------------
---------------------------------
| avg reward         | 8.28e+03 |
| explained_variance | 0.766    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 121000   |
| policy_entropy     | 0        |
| total_timesteps    | 9680000  |
| value_loss         | 4.17e+04 |
---------------------------------
---------------------------------
| avg reward         | 7.45e+03 |
| explained_variance | -0.178   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 121100   |
| policy_entropy     | 0.00467  |
| total_timesteps    | 9688000  |
| value_loss         | 2.3e+06  |
---------------------------------
----------------------------------
| avg reward         | -1.59e+04 |
| explained_variance | -2.5      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 121200    |
| policy_entropy     | 0.005     |
| total_timesteps    | 9696000   |
| value_loss         | 5.72e+06  |
----------------------------------
---------------------------------
| avg reward         | 1.32e+04 |
| explained_variance | 0.391    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 121300   |
| policy_entropy     | 0        |
| total_timesteps    | 9704000  |
| value_loss         | 1.13e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.43e+04 |
| explained_variance | -0.419    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 121400    |
| policy_entropy     | 0.0122    |
| total_timesteps    | 9712000   |
| value_loss         | 1.21e+07  |
----------------------------------
---------------------------------
| avg reward         | -2.5e+03 |
| explained_variance | -13      |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 121500   |
| policy_entropy     | 0.0101   |
| total_timesteps    | 9720000  |
| value_loss         | 9.57e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.16e+03 |
| explained_variance | 0.679    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 121600   |
| policy_entropy     | 0        |
| total_timesteps    | 9728000  |
| value_loss         | 2.51e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.31e+03 |
| explained_variance | -0.85     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 121700    |
| policy_entropy     | 0.00471   |
| total_timesteps    | 9736000   |
| value_loss         | 2.38e+04  |
----------------------------------
----------------------------------
| avg reward         | -6.72e+03 |
| explained_variance | -131      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 121800    |
| policy_entropy     | 0.00827   |
| total_timesteps    | 9744000   |
| value_loss         | 1.72e+06  |
----------------------------------
----------------------------------
| avg reward         | -9.81e+03 |
| explained_variance | 0.287     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 121900    |
| policy_entropy     | 0         |
| total_timesteps    | 9752000   |
| value_loss         | 5.51e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.25e+04 |
| explained_variance | 0.193     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 122000    |
| policy_entropy     | 0.00163   |
| total_timesteps    | 9760000   |
| value_loss         | 4.83e+06  |
----------------------------------
----------------------------------
| avg reward         | -3.58e+03 |
| explained_variance | -0.769    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 122100    |
| policy_entropy     | 0.0175    |
| total_timesteps    | 9768000   |
| value_loss         | 1.11e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.38e+04 |
| explained_variance | -3.97     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 122200    |
| policy_entropy     | 0.00321   |
| total_timesteps    | 9776000   |
| value_loss         | 6.08e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.34e+04 |
| explained_variance | -67.7     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 122300    |
| policy_entropy     | 0         |
| total_timesteps    | 9784000   |
| value_loss         | 1.63e+06  |
----------------------------------
---------------------------------
| avg reward         | 894      |
| explained_variance | 0.66     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 122400   |
| policy_entropy     | 0        |
| total_timesteps    | 9792000  |
| value_loss         | 4.95e+03 |
---------------------------------
---------------------------------
| avg reward         | 1.38e+04 |
| explained_variance | 0.236    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 122500   |
| policy_entropy     | 0.00395  |
| total_timesteps    | 9800000  |
| value_loss         | 5.53e+06 |
---------------------------------
---------------------------------
| avg reward         | 6.02e+03 |
| explained_variance | -22.4    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 122600   |
| policy_entropy     | 0.00591  |
| total_timesteps    | 9808000  |
| value_loss         | 6.04e+05 |
---------------------------------
----------------------------------
| avg reward         | -9.46e+03 |
| explained_variance | -2.61     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 122700    |
| policy_entropy     | 0.00217   |
| total_timesteps    | 9816000   |
| value_loss         | 2.08e+06  |
----------------------------------
---------------------------------
| avg reward         | 1.12e+04 |
| explained_variance | 0.547    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 122800   |
| policy_entropy     | 0        |
| total_timesteps    | 9824000  |
| value_loss         | 8.26e+04 |
---------------------------------
---------------------------------
| avg reward         | 8.49e+03 |
| explained_variance | 0.746    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 122900   |
| policy_entropy     | 0        |
| total_timesteps    | 9832000  |
| value_loss         | 4.45e+04 |
---------------------------------
----------------------------------
| avg reward         | -5.68e+03 |
| explained_variance | 0.616     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 123000    |
| policy_entropy     | 0         |
| total_timesteps    | 9840000   |
| value_loss         | 1.7e+04   |
----------------------------------
---------------------------------
| avg reward         | 1.26e+04 |
| explained_variance | 0.412    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 123100   |
| policy_entropy     | 0        |
| total_timesteps    | 9848000  |
| value_loss         | 9.59e+04 |
---------------------------------
---------------------------------
| avg reward         | -1.1e+04 |
| explained_variance | 0.282    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 123200   |
| policy_entropy     | 0        |
| total_timesteps    | 9856000  |
| value_loss         | 6.94e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.06e+04 |
| explained_variance | 0.648    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 123300   |
| policy_entropy     | 0        |
| total_timesteps    | 9864000  |
| value_loss         | 7.29e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.36e+04 |
| explained_variance | -1.96     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 123400    |
| policy_entropy     | 0.00921   |
| total_timesteps    | 9872000   |
| value_loss         | 7.09e+06  |
----------------------------------
----------------------------------
| avg reward         | -5.22e+03 |
| explained_variance | -0.019    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 123500    |
| policy_entropy     | 0         |
| total_timesteps    | 9880000   |
| value_loss         | 1.08e+06  |
----------------------------------
---------------------------------
| avg reward         | 6.1e+03  |
| explained_variance | -0.219   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 123600   |
| policy_entropy     | 0.0181   |
| total_timesteps    | 9888000  |
| value_loss         | 3.91e+06 |
---------------------------------
---------------------------------
| avg reward         | 9.24e+03 |
| explained_variance | 0.711    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 123700   |
| policy_entropy     | 0        |
| total_timesteps    | 9896000  |
| value_loss         | 5.49e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.34e+04 |
| explained_variance | 0.176     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 123800    |
| policy_entropy     | 0         |
| total_timesteps    | 9904000   |
| value_loss         | 1.03e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.54e+03 |
| explained_variance | 0.799     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 123900    |
| policy_entropy     | 0         |
| total_timesteps    | 9912000   |
| value_loss         | 1.74e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.08e+04 |
| explained_variance | 0.229    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 124000   |
| policy_entropy     | 0.00703  |
| total_timesteps    | 9920000  |
| value_loss         | 3.4e+06  |
---------------------------------
---------------------------------
| avg reward         | -1.3e+04 |
| explained_variance | 0.138    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 124100   |
| policy_entropy     | 0        |
| total_timesteps    | 9928000  |
| value_loss         | 9.84e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.55e+04 |
| explained_variance | 0.217     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 124200    |
| policy_entropy     | 0         |
| total_timesteps    | 9936000   |
| value_loss         | 1.37e+05  |
----------------------------------
---------------------------------
| avg reward         | -58.4    |
| explained_variance | 0.585    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 124300   |
| policy_entropy     | 0.0216   |
| total_timesteps    | 9944000  |
| value_loss         | 6.14e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.16e+04 |
| explained_variance | -70.5     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 124400    |
| policy_entropy     | 0         |
| total_timesteps    | 9952000   |
| value_loss         | 1.14e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.56e+03 |
| explained_variance | 0.227     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 124500    |
| policy_entropy     | 0         |
| total_timesteps    | 9960000   |
| value_loss         | 7.63e+03  |
----------------------------------
----------------------------------
| avg reward         | -3.98e+03 |
| explained_variance | -2.25     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 124600    |
| policy_entropy     | 0         |
| total_timesteps    | 9968000   |
| value_loss         | 4.56e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.43e+04 |
| explained_variance | -38.5    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 124700   |
| policy_entropy     | 0.0106   |
| total_timesteps    | 9976000  |
| value_loss         | 3.52e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.13e+04 |
| explained_variance | -1.28     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 124800    |
| policy_entropy     | 0.0124    |
| total_timesteps    | 9984000   |
| value_loss         | 3.79e+06  |
----------------------------------
---------------------------------
| avg reward         | 7.81e+03 |
| explained_variance | 0.822    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 124900   |
| policy_entropy     | 0        |
| total_timesteps    | 9992000  |
| value_loss         | 4.13e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.32e+04 |
| explained_variance | -1.82     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125000    |
| policy_entropy     | 0         |
| total_timesteps    | 10000000  |
| value_loss         | 9.7e+06   |
----------------------------------
---------------------------------
| avg reward         | 1.7e+04  |
| explained_variance | 0.636    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 125100   |
| policy_entropy     | 0        |
| total_timesteps    | 10008000 |
| value_loss         | 1.64e+05 |
---------------------------------
---------------------------------
| avg reward         | 1.45e+04 |
| explained_variance | -44.8    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 125200   |
| policy_entropy     | 0        |
| total_timesteps    | 10016000 |
| value_loss         | 3.51e+06 |
---------------------------------
----------------------------------
| avg reward         | -8.63e+03 |
| explained_variance | 0.407     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125300    |
| policy_entropy     | 0         |
| total_timesteps    | 10024000  |
| value_loss         | 4.16e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.25e+04 |
| explained_variance | -1.03     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125400    |
| policy_entropy     | 0         |
| total_timesteps    | 10032000  |
| value_loss         | 1.06e+07  |
----------------------------------
----------------------------------
| avg reward         | -8.19e+03 |
| explained_variance | 0.35      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125500    |
| policy_entropy     | 0         |
| total_timesteps    | 10040000  |
| value_loss         | 3.88e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.21e+04 |
| explained_variance | 0.135     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125600    |
| policy_entropy     | 0         |
| total_timesteps    | 10048000  |
| value_loss         | 8.95e+04  |
----------------------------------
----------------------------------
| avg reward         | -9.08e+03 |
| explained_variance | 0.436     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125700    |
| policy_entropy     | 0         |
| total_timesteps    | 10056000  |
| value_loss         | 4.76e+04  |
----------------------------------
----------------------------------
| avg reward         | -6.69e+03 |
| explained_variance | -8.03     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 125800    |
| policy_entropy     | 0         |
| total_timesteps    | 10064000  |
| value_loss         | 1.29e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.4e+04  |
| explained_variance | -8.56    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 125900   |
| policy_entropy     | 0        |
| total_timesteps    | 10072000 |
| value_loss         | 6.04e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.04e+04 |
| explained_variance | 0.478     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126000    |
| policy_entropy     | 0         |
| total_timesteps    | 10080000  |
| value_loss         | 6.31e+04  |
----------------------------------
----------------------------------
| avg reward         | -3.38e+03 |
| explained_variance | 0.875     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126100    |
| policy_entropy     | 0         |
| total_timesteps    | 10088000  |
| value_loss         | 4.63e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.01e+04 |
| explained_variance | -11.8     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126200    |
| policy_entropy     | 0         |
| total_timesteps    | 10096000  |
| value_loss         | 2.96e+05  |
----------------------------------
----------------------------------
| avg reward         | -6.53e+03 |
| explained_variance | -0.237    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126300    |
| policy_entropy     | 0         |
| total_timesteps    | 10104000  |
| value_loss         | 1.39e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.27e+04 |
| explained_variance | 0.147     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126400    |
| policy_entropy     | 0         |
| total_timesteps    | 10112000  |
| value_loss         | 3.83e+06  |
----------------------------------
----------------------------------
| avg reward         | -5.18e+03 |
| explained_variance | 0.786     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126500    |
| policy_entropy     | 0         |
| total_timesteps    | 10120000  |
| value_loss         | 1.23e+04  |
----------------------------------
---------------------------------
| avg reward         | 9.31e+03 |
| explained_variance | -0.00177 |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 126600   |
| policy_entropy     | 0        |
| total_timesteps    | 10128000 |
| value_loss         | 3.25e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.04e+04 |
| explained_variance | -0.00779  |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 126700    |
| policy_entropy     | 0         |
| total_timesteps    | 10136000  |
| value_loss         | 4.16e+06  |
----------------------------------
---------------------------------
| avg reward         | -8.3e+03 |
| explained_variance | -0.309   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 126800   |
| policy_entropy     | 0.0133   |
| total_timesteps    | 10144000 |
| value_loss         | 6.06e+06 |
---------------------------------
---------------------------------
| avg reward         | 5.55e+03 |
| explained_variance | -10.8    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 126900   |
| policy_entropy     | 0        |
| total_timesteps    | 10152000 |
| value_loss         | 3.2e+05  |
---------------------------------
----------------------------------
| avg reward         | -4.42e+03 |
| explained_variance | 0.708     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 127000    |
| policy_entropy     | 0         |
| total_timesteps    | 10160000  |
| value_loss         | 1.2e+04   |
----------------------------------
---------------------------------
| avg reward         | 9.69e+03 |
| explained_variance | 0.671    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 127100   |
| policy_entropy     | 0        |
| total_timesteps    | 10168000 |
| value_loss         | 5.17e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.36e+03 |
| explained_variance | -1.18    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 127200   |
| policy_entropy     | 0.00596  |
| total_timesteps    | 10176000 |
| value_loss         | 4.36e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.38e+04 |
| explained_variance | 0.224     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 127300    |
| policy_entropy     | 0         |
| total_timesteps    | 10184000  |
| value_loss         | 1.03e+05  |
----------------------------------
---------------------------------
| avg reward         | 2.65e+03 |
| explained_variance | 0.926    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 127400   |
| policy_entropy     | 0        |
| total_timesteps    | 10192000 |
| value_loss         | 4.94e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.12e+04 |
| explained_variance | 0.324     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 127500    |
| policy_entropy     | 0         |
| total_timesteps    | 10200000  |
| value_loss         | 7.01e+04  |
----------------------------------
---------------------------------
| avg reward         | 558      |
| explained_variance | 0.879    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 127600   |
| policy_entropy     | 0        |
| total_timesteps    | 10208000 |
| value_loss         | 2.38e+03 |
---------------------------------
----------------------------------
| avg reward         | -1.05e+04 |
| explained_variance | 0.333     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 127700    |
| policy_entropy     | 0         |
| total_timesteps    | 10216000  |
| value_loss         | 5.77e+04  |
----------------------------------
---------------------------------
| avg reward         | 6.66e+03 |
| explained_variance | 0.137    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 127800   |
| policy_entropy     | 0        |
| total_timesteps    | 10224000 |
| value_loss         | 1.53e+06 |
---------------------------------
---------------------------------
| avg reward         | 1.13e+04 |
| explained_variance | 0.526    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 127900   |
| policy_entropy     | 0        |
| total_timesteps    | 10232000 |
| value_loss         | 7.99e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.43e+04 |
| explained_variance | 0.755    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 128000   |
| policy_entropy     | 0        |
| total_timesteps    | 10240000 |
| value_loss         | 1.11e+05 |
---------------------------------
---------------------------------
| avg reward         | 2.79e+03 |
| explained_variance | -0.878   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 128100   |
| policy_entropy     | 0.0128   |
| total_timesteps    | 10248000 |
| value_loss         | 2.29e+05 |
---------------------------------
---------------------------------
| avg reward         | 4.77e+03 |
| explained_variance | -0.0368  |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 128200   |
| policy_entropy     | 0.0126   |
| total_timesteps    | 10256000 |
| value_loss         | 1.63e+06 |
---------------------------------
---------------------------------
| avg reward         | 2.1e+03  |
| explained_variance | 0.437    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 128300   |
| policy_entropy     | 0.0105   |
| total_timesteps    | 10264000 |
| value_loss         | 8.08e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.49e+04 |
| explained_variance | 0.208    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 128400   |
| policy_entropy     | 0.00912  |
| total_timesteps    | 10272000 |
| value_loss         | 6.67e+06 |
---------------------------------
---------------------------------
| avg reward         | 8.34e+03 |
| explained_variance | 0.663    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 128500   |
| policy_entropy     | 0        |
| total_timesteps    | 10280000 |
| value_loss         | 4.19e+04 |
---------------------------------
----------------------------------
| avg reward         | -4.36e+03 |
| explained_variance | 0.849     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 128600    |
| policy_entropy     | 0         |
| total_timesteps    | 10288000  |
| value_loss         | 7.77e+03  |
----------------------------------
----------------------------------
| avg reward         | -7.93e+03 |
| explained_variance | -14.3     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 128700    |
| policy_entropy     | 0         |
| total_timesteps    | 10296000  |
| value_loss         | 1.95e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.42e+04 |
| explained_variance | -56       |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 128800    |
| policy_entropy     | 0         |
| total_timesteps    | 10304000  |
| value_loss         | 1.69e+06  |
----------------------------------
----------------------------------
| avg reward         | -5.56e+03 |
| explained_variance | 0.144     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 128900    |
| policy_entropy     | 0         |
| total_timesteps    | 10312000  |
| value_loss         | 9.77e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.23e+04 |
| explained_variance | 0.701    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129000   |
| policy_entropy     | 0        |
| total_timesteps    | 10320000 |
| value_loss         | 8.3e+04  |
---------------------------------
----------------------------------
| avg reward         | -1.32e+04 |
| explained_variance | -0.542    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 129100    |
| policy_entropy     | 0         |
| total_timesteps    | 10328000  |
| value_loss         | 9.32e+06  |
----------------------------------
---------------------------------
| avg reward         | 5.56e+03 |
| explained_variance | 0.815    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129200   |
| policy_entropy     | 0        |
| total_timesteps    | 10336000 |
| value_loss         | 1.99e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.32e+03 |
| explained_variance | -0.77    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129300   |
| policy_entropy     | 0.00921  |
| total_timesteps    | 10344000 |
| value_loss         | 3.5e+04  |
---------------------------------
---------------------------------
| avg reward         | 6.63e+03 |
| explained_variance | 0.78     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129400   |
| policy_entropy     | 0        |
| total_timesteps    | 10352000 |
| value_loss         | 2.85e+04 |
---------------------------------
----------------------------------
| avg reward         | -6.12e+03 |
| explained_variance | 0.619     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 129500    |
| policy_entropy     | 0         |
| total_timesteps    | 10360000  |
| value_loss         | 2.16e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.52e+04 |
| explained_variance | 0.609    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129600   |
| policy_entropy     | 0        |
| total_timesteps    | 10368000 |
| value_loss         | 1.41e+05 |
---------------------------------
---------------------------------
| avg reward         | -308     |
| explained_variance | 0.544    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129700   |
| policy_entropy     | 0        |
| total_timesteps    | 10376000 |
| value_loss         | 1.09e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.37e+04 |
| explained_variance | 0.6      |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 129800   |
| policy_entropy     | 0        |
| total_timesteps    | 10384000 |
| value_loss         | 1.16e+05 |
---------------------------------
----------------------------------
| avg reward         | -1.19e+03 |
| explained_variance | 0.671     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 129900    |
| policy_entropy     | 0         |
| total_timesteps    | 10392000  |
| value_loss         | 6.82e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.34e+04 |
| explained_variance | 0.125     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 130000    |
| policy_entropy     | 0         |
| total_timesteps    | 10400000  |
| value_loss         | 4.37e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.07e+04 |
| explained_variance | -70.6     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 130100    |
| policy_entropy     | 0         |
| total_timesteps    | 10408000  |
| value_loss         | 1.62e+06  |
----------------------------------
---------------------------------
| avg reward         | 5.24e+03 |
| explained_variance | -1.76    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 130200   |
| policy_entropy     | 0        |
| total_timesteps    | 10416000 |
| value_loss         | 6.3e+05  |
---------------------------------
---------------------------------
| avg reward         | 1.56e+04 |
| explained_variance | 0.552    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 130300   |
| policy_entropy     | 0        |
| total_timesteps    | 10424000 |
| value_loss         | 1.63e+05 |
---------------------------------
----------------------------------
| avg reward         | -9.84e+03 |
| explained_variance | 0.154     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 130400    |
| policy_entropy     | 0.00988   |
| total_timesteps    | 10432000  |
| value_loss         | 2.33e+06  |
----------------------------------
----------------------------------
| avg reward         | -9.69e+03 |
| explained_variance | -1.72     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 130500    |
| policy_entropy     | 0.0165    |
| total_timesteps    | 10440000  |
| value_loss         | 5.03e+06  |
----------------------------------
---------------------------------
| avg reward         | 1.52e+04 |
| explained_variance | 0.689    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 130600   |
| policy_entropy     | 0        |
| total_timesteps    | 10448000 |
| value_loss         | 1.6e+05  |
---------------------------------
----------------------------------
| avg reward         | -8.54e+03 |
| explained_variance | -4.62     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 130700    |
| policy_entropy     | 0.00747   |
| total_timesteps    | 10456000  |
| value_loss         | 2.71e+06  |
----------------------------------
---------------------------------
| avg reward         | 5.38e+03 |
| explained_variance | 0.322    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 130800   |
| policy_entropy     | 0.000263 |
| total_timesteps    | 10464000 |
| value_loss         | 7.87e+05 |
---------------------------------
---------------------------------
| avg reward         | -2e+03   |
| explained_variance | -0.0199  |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 130900   |
| policy_entropy     | 0        |
| total_timesteps    | 10472000 |
| value_loss         | 1.76e+05 |
---------------------------------
---------------------------------
| avg reward         | -5.7e+03 |
| explained_variance | 0.812    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131000   |
| policy_entropy     | 0        |
| total_timesteps    | 10480000 |
| value_loss         | 2.04e+04 |
---------------------------------
---------------------------------
| avg reward         | 6.85e+03 |
| explained_variance | 0.719    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131100   |
| policy_entropy     | 0        |
| total_timesteps    | 10488000 |
| value_loss         | 3.25e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.2e+04  |
| explained_variance | 0.682    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131200   |
| policy_entropy     | 0        |
| total_timesteps    | 10496000 |
| value_loss         | 8.57e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.23e+04 |
| explained_variance | -0.6      |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 131300    |
| policy_entropy     | 0.00233   |
| total_timesteps    | 10504000  |
| value_loss         | 8.38e+06  |
----------------------------------
---------------------------------
| avg reward         | 6.89e+03 |
| explained_variance | 0.84     |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131400   |
| policy_entropy     | 0        |
| total_timesteps    | 10512000 |
| value_loss         | 3.38e+04 |
---------------------------------
---------------------------------
| avg reward         | 9.74e+03 |
| explained_variance | -27.1    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131500   |
| policy_entropy     | 0.00197  |
| total_timesteps    | 10520000 |
| value_loss         | 1.53e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.04e+04 |
| explained_variance | 0.376     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 131600    |
| policy_entropy     | 0         |
| total_timesteps    | 10528000  |
| value_loss         | 6.08e+04  |
----------------------------------
----------------------------------
| avg reward         | -7.59e+03 |
| explained_variance | 0.668     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 131700    |
| policy_entropy     | 0         |
| total_timesteps    | 10536000  |
| value_loss         | 3.34e+04  |
----------------------------------
---------------------------------
| avg reward         | 7.87e+03 |
| explained_variance | 0.259    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131800   |
| policy_entropy     | 0.00122  |
| total_timesteps    | 10544000 |
| value_loss         | 1.78e+06 |
---------------------------------
---------------------------------
| avg reward         | 1.16e+04 |
| explained_variance | 0.509    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 131900   |
| policy_entropy     | 0        |
| total_timesteps    | 10552000 |
| value_loss         | 7.95e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.32e+04 |
| explained_variance | -15.3    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 132000   |
| policy_entropy     | 0        |
| total_timesteps    | 10560000 |
| value_loss         | 1.69e+06 |
---------------------------------
---------------------------------
| avg reward         | 6.13e+03 |
| explained_variance | 0.686    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 132100   |
| policy_entropy     | 0        |
| total_timesteps    | 10568000 |
| value_loss         | 2.41e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.57e+03 |
| explained_variance | -0.0527  |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 132200   |
| policy_entropy     | 0.00144  |
| total_timesteps    | 10576000 |
| value_loss         | 9.25e+04 |
---------------------------------
----------------------------------
| avg reward         | -6.61e+03 |
| explained_variance | 0.717     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 132300    |
| policy_entropy     | 0         |
| total_timesteps    | 10584000  |
| value_loss         | 2.53e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.16e+04 |
| explained_variance | -62.7    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 132400   |
| policy_entropy     | 0.00083  |
| total_timesteps    | 10592000 |
| value_loss         | 2.34e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.69e+03 |
| explained_variance | 0.0728    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 132500    |
| policy_entropy     | 8.77e-05  |
| total_timesteps    | 10600000  |
| value_loss         | 1.16e+05  |
----------------------------------
---------------------------------
| avg reward         | -191     |
| explained_variance | 0.892    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 132600   |
| policy_entropy     | 0        |
| total_timesteps    | 10608000 |
| value_loss         | 1.86e+03 |
---------------------------------
---------------------------------
| avg reward         | 9.03e+03 |
| explained_variance | -2.32    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 132700   |
| policy_entropy     | 0.000368 |
| total_timesteps    | 10616000 |
| value_loss         | 1.93e+06 |
---------------------------------
----------------------------------
| avg reward         | -8.29e+03 |
| explained_variance | -0.631    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 132800    |
| policy_entropy     | 0.00152   |
| total_timesteps    | 10624000  |
| value_loss         | 3.91e+06  |
----------------------------------
----------------------------------
| avg reward         | -9.77e+03 |
| explained_variance | 0.448     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 132900    |
| policy_entropy     | 0         |
| total_timesteps    | 10632000  |
| value_loss         | 5.72e+04  |
----------------------------------
---------------------------------
| avg reward         | 1.01e+04 |
| explained_variance | -1.37    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133000   |
| policy_entropy     | 0.00197  |
| total_timesteps    | 10640000 |
| value_loss         | 3.25e+06 |
---------------------------------
----------------------------------
| avg reward         | -2.56e+03 |
| explained_variance | 0.759     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 133100    |
| policy_entropy     | 0         |
| total_timesteps    | 10648000  |
| value_loss         | 5.53e+03  |
----------------------------------
---------------------------------
| avg reward         | 1.14e+04 |
| explained_variance | -36.6    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133200   |
| policy_entropy     | 0.00812  |
| total_timesteps    | 10656000 |
| value_loss         | 2.2e+06  |
---------------------------------
---------------------------------
| avg reward         | 7.91e+03 |
| explained_variance | -32.1    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133300   |
| policy_entropy     | 0.0163   |
| total_timesteps    | 10664000 |
| value_loss         | 2.01e+06 |
---------------------------------
---------------------------------
| avg reward         | 1.08e+04 |
| explained_variance | 0.794    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133400   |
| policy_entropy     | 0        |
| total_timesteps    | 10672000 |
| value_loss         | 7.28e+04 |
---------------------------------
----------------------------------
| avg reward         | -3.06e+03 |
| explained_variance | -1.92     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 133500    |
| policy_entropy     | 0         |
| total_timesteps    | 10680000  |
| value_loss         | 7.51e+04  |
----------------------------------
---------------------------------
| avg reward         | 3.55e+03 |
| explained_variance | -7.17    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133600   |
| policy_entropy     | 0.0026   |
| total_timesteps    | 10688000 |
| value_loss         | 2.21e+05 |
---------------------------------
---------------------------------
| avg reward         | -9.8e+03 |
| explained_variance | 0.341    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133700   |
| policy_entropy     | 0        |
| total_timesteps    | 10696000 |
| value_loss         | 5.6e+04  |
---------------------------------
---------------------------------
| avg reward         | 1.13e+03 |
| explained_variance | 0.691    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133800   |
| policy_entropy     | 0        |
| total_timesteps    | 10704000 |
| value_loss         | 2.33e+04 |
---------------------------------
---------------------------------
| avg reward         | 1.09e+04 |
| explained_variance | -1.22    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 133900   |
| policy_entropy     | 0.00243  |
| total_timesteps    | 10712000 |
| value_loss         | 3.66e+06 |
---------------------------------
----------------------------------
| avg reward         | -4.95e+03 |
| explained_variance | -15.1     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 134000    |
| policy_entropy     | 0.0041    |
| total_timesteps    | 10720000  |
| value_loss         | 3.48e+05  |
----------------------------------
---------------------------------
| avg reward         | 5.2e+03  |
| explained_variance | 0.789    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 134100   |
| policy_entropy     | 0        |
| total_timesteps    | 10728000 |
| value_loss         | 2.22e+04 |
---------------------------------
---------------------------------
| avg reward         | 2.81e+03 |
| explained_variance | 0.918    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 134200   |
| policy_entropy     | 0        |
| total_timesteps    | 10736000 |
| value_loss         | 7.28e+03 |
---------------------------------
----------------------------------
| avg reward         | -8.13e+03 |
| explained_variance | -8.74     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 134300    |
| policy_entropy     | 0         |
| total_timesteps    | 10744000  |
| value_loss         | 2.17e+05  |
----------------------------------
---------------------------------
| avg reward         | 7.25e+03 |
| explained_variance | 0.103    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 134400   |
| policy_entropy     | 0.00206  |
| total_timesteps    | 10752000 |
| value_loss         | 1.35e+06 |
---------------------------------
---------------------------------
| avg reward         | 6.51e+03 |
| explained_variance | -2.56    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 134500   |
| policy_entropy     | 0        |
| total_timesteps    | 10760000 |
| value_loss         | 1.68e+05 |
---------------------------------
----------------------------------
| avg reward         | -5.34e+03 |
| explained_variance | 0.679     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 134600    |
| policy_entropy     | 0         |
| total_timesteps    | 10768000  |
| value_loss         | 1.83e+04  |
----------------------------------
----------------------------------
| avg reward         | -2.65e+03 |
| explained_variance | 0.0546    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 134700    |
| policy_entropy     | 0.00546   |
| total_timesteps    | 10776000  |
| value_loss         | 2.07e+05  |
----------------------------------
---------------------------------
| avg reward         | 5.84e+03 |
| explained_variance | -2.17    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 134800   |
| policy_entropy     | 0.00447  |
| total_timesteps    | 10784000 |
| value_loss         | 1.58e+06 |
---------------------------------
----------------------------------
| avg reward         | -9.87e+03 |
| explained_variance | 0.562     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 134900    |
| policy_entropy     | 0         |
| total_timesteps    | 10792000  |
| value_loss         | 5.76e+04  |
----------------------------------
---------------------------------
| avg reward         | 6.35e+03 |
| explained_variance | 0.356    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 135000   |
| policy_entropy     | 0.00231  |
| total_timesteps    | 10800000 |
| value_loss         | 1.04e+06 |
---------------------------------
---------------------------------
| avg reward         | 1.07e+04 |
| explained_variance | -40.2    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 135100   |
| policy_entropy     | 0        |
| total_timesteps    | 10808000 |
| value_loss         | 2.22e+06 |
---------------------------------
---------------------------------
| avg reward         | -1.1e+04 |
| explained_variance | 0.163    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 135200   |
| policy_entropy     | 0.000215 |
| total_timesteps    | 10816000 |
| value_loss         | 3.82e+06 |
---------------------------------
---------------------------------
| avg reward         | 7.53e+03 |
| explained_variance | 0.867    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 135300   |
| policy_entropy     | 0        |
| total_timesteps    | 10824000 |
| value_loss         | 4.15e+04 |
---------------------------------
----------------------------------
| avg reward         | -9.51e+03 |
| explained_variance | 0.634     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 135400    |
| policy_entropy     | 0         |
| total_timesteps    | 10832000  |
| value_loss         | 4.91e+04  |
----------------------------------
----------------------------------
| avg reward         | -1.47e+04 |
| explained_variance | -110      |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 135500    |
| policy_entropy     | 0.000977  |
| total_timesteps    | 10840000  |
| value_loss         | 3.3e+06   |
----------------------------------
---------------------------------
| avg reward         | 7.72e+03 |
| explained_variance | 0.863    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 135600   |
| policy_entropy     | 0        |
| total_timesteps    | 10848000 |
| value_loss         | 3.51e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.53e+04 |
| explained_variance | 0.313     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 135700    |
| policy_entropy     | 0         |
| total_timesteps    | 10856000  |
| value_loss         | 1.4e+05   |
----------------------------------
----------------------------------
| avg reward         | -1.56e+04 |
| explained_variance | 0.102     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 135800    |
| policy_entropy     | 0         |
| total_timesteps    | 10864000  |
| value_loss         | 1.39e+05  |
----------------------------------
---------------------------------
| avg reward         | -449     |
| explained_variance | 0.926    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 135900   |
| policy_entropy     | 0        |
| total_timesteps    | 10872000 |
| value_loss         | 2.32e+03 |
---------------------------------
---------------------------------
| avg reward         | -851     |
| explained_variance | 0.742    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 136000   |
| policy_entropy     | 1.36e-06 |
| total_timesteps    | 10880000 |
| value_loss         | 6.14e+03 |
---------------------------------
----------------------------------
| avg reward         | -9.23e+03 |
| explained_variance | -34.5     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 136100    |
| policy_entropy     | 2.35e-05  |
| total_timesteps    | 10888000  |
| value_loss         | 8.11e+05  |
----------------------------------
----------------------------------
| avg reward         | -1.01e+04 |
| explained_variance | 0.307     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 136200    |
| policy_entropy     | 0         |
| total_timesteps    | 10896000  |
| value_loss         | 6.1e+04   |
----------------------------------
---------------------------------
| avg reward         | 8.65e+03 |
| explained_variance | 0.133    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 136300   |
| policy_entropy     | 0        |
| total_timesteps    | 10904000 |
| value_loss         | 2.55e+06 |
---------------------------------
----------------------------------
| avg reward         | -8.76e+03 |
| explained_variance | 0.641     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 136400    |
| policy_entropy     | 0         |
| total_timesteps    | 10912000  |
| value_loss         | 4.01e+04  |
----------------------------------
----------------------------------
| avg reward         | -7.33e+03 |
| explained_variance | -40.5     |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 136500    |
| policy_entropy     | 2.96e-07  |
| total_timesteps    | 10920000  |
| value_loss         | 8.44e+05  |
----------------------------------
----------------------------------
| avg reward         | -2.93e+03 |
| explained_variance | -0.196    |
| fps                | 2005      |
| learning rate      | 0.001     |
| nupdates           | 136600    |
| policy_entropy     | 6.23e-07  |
| total_timesteps    | 10928000  |
| value_loss         | 8.39e+05  |
----------------------------------
---------------------------------
| avg reward         | 1.23e+04 |
| explained_variance | -0.17    |
| fps                | 2005     |
| learning rate      | 0.001    |
| nupdates           | 136700   |
| policy_entropy     | 9.18e-08 |
| total_timesteps    | 10936000 |
| value_loss         | 6.23e+06 |
---------------------------------
----------------------------------
| avg reward         | -1.16e+04 |
| explained_variance | -0.545    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 136800    |
| policy_entropy     | 1.53e-06  |
| total_timesteps    | 10944000  |
| value_loss         | 8.78e+06  |
----------------------------------
---------------------------------
| avg reward         | -1e+04   |
| explained_variance | 0.501    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 136900   |
| policy_entropy     | 0        |
| total_timesteps    | 10952000 |
| value_loss         | 5.81e+04 |
---------------------------------
----------------------------------
| avg reward         | -1.19e+03 |
| explained_variance | 0.656     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 137000    |
| policy_entropy     | 0         |
| total_timesteps    | 10960000  |
| value_loss         | 5.47e+03  |
----------------------------------
----------------------------------
| avg reward         | -1.07e+03 |
| explained_variance | -0.385    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 137100    |
| policy_entropy     | 2.79e-07  |
| total_timesteps    | 10968000  |
| value_loss         | 5.14e+04  |
----------------------------------
----------------------------------
| avg reward         | -7.24e+03 |
| explained_variance | 0.157     |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 137200    |
| policy_entropy     | 2.05e-08  |
| total_timesteps    | 10976000  |
| value_loss         | 1.67e+06  |
----------------------------------
----------------------------------
| avg reward         | -1.15e+04 |
| explained_variance | -0.384    |
| fps                | 2006      |
| learning rate      | 0.001     |
| nupdates           | 137300    |
| policy_entropy     | 1.78e-07  |
| total_timesteps    | 10984000  |
| value_loss         | 8.04e+06  |
----------------------------------
---------------------------------
| avg reward         | 7.24e+03 |
| explained_variance | -0.117   |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 137400   |
| policy_entropy     | 8.58e-09 |
| total_timesteps    | 10992000 |
| value_loss         | 1.75e+06 |
---------------------------------
---------------------------------
| avg reward         | 4.31e+03 |
| explained_variance | 0.237    |
| fps                | 2006     |
| learning rate      | 0.001    |
| nupdates           | 137500   |
| policy_entropy     | 7.17e-09 |
| total_timesteps    | 11000000 |
| value_loss         | 1.23e+06 |
---------------------------------
