Logging to /tmp/openai-2018-05-11-09-24-49-896852
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 100      |
| mean 100 episode reward | -20.9    |
| steps                   | 76810    |
--------------------------------------
Saving model due to mean reward increase: None -> -20.9
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 200      |
| mean 100 episode reward | -20.9    |
| steps                   | 154769   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 300      |
| mean 100 episode reward | -20.9    |
| steps                   | 235322   |
--------------------------------------
Saving model due to mean reward increase: -20.9 -> -20.8
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 400      |
| mean 100 episode reward | -20.8    |
| steps                   | 315500   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 500      |
| mean 100 episode reward | -20.7    |
| steps                   | 397290   |
--------------------------------------
Saving model due to mean reward increase: -20.8 -> -20.7
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 600      |
| mean 100 episode reward | -20.7    |
| steps                   | 479726   |
--------------------------------------
Saving model due to mean reward increase: -20.7 -> -20.6
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 700      |
| mean 100 episode reward | -20.6    |
| steps                   | 565015   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 800      |
| mean 100 episode reward | -20.7    |
| steps                   | 649364   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 900      |
| mean 100 episode reward | -20.6    |
| steps                   | 736268   |
--------------------------------------
Saving model due to mean reward increase: -20.6 -> -20.5
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 1000     |
| mean 100 episode reward | -20.5    |
| steps                   | 824314   |
--------------------------------------
Saving model due to mean reward increase: -20.5 -> -20.4
Saving model due to mean reward increase: -20.4 -> -20.3
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 1100     |
| mean 100 episode reward | -20.3    |
| steps                   | 915782   |
--------------------------------------
Saving model due to mean reward increase: -20.3 -> -20.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1200     |
| mean 100 episode reward | -20.2    |
| steps                   | 1011278  |
--------------------------------------
Saving model due to mean reward increase: -20.2 -> -20.0
Saving model due to mean reward increase: -20.0 -> -19.9
Saving model due to mean reward increase: -19.9 -> -19.8
Saving model due to mean reward increase: -19.8 -> -19.7
Saving model due to mean reward increase: -19.7 -> -19.5
Saving model due to mean reward increase: -19.5 -> -19.3
Saving model due to mean reward increase: -19.3 -> -19.2
Saving model due to mean reward increase: -19.2 -> -19.1
Saving model due to mean reward increase: -19.1 -> -19.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1300     |
| mean 100 episode reward | -19      |
| steps                   | 1128046  |
--------------------------------------
Saving model due to mean reward increase: -19.0 -> -18.9
Saving model due to mean reward increase: -18.9 -> -18.8
Saving model due to mean reward increase: -18.8 -> -18.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1400     |
| mean 100 episode reward | -19.1    |
| steps                   | 1344056  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1500     |
| mean 100 episode reward | -18.7    |
| steps                   | 1470863  |
--------------------------------------
Saving model due to mean reward increase: -18.7 -> -18.6
Saving model due to mean reward increase: -18.6 -> -18.5
Saving model due to mean reward increase: -18.5 -> -18.3
Saving model due to mean reward increase: -18.3 -> -18.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1600     |
| mean 100 episode reward | -18.2    |
| steps                   | 1700206  |
--------------------------------------
Saving model due to mean reward increase: -18.2 -> -18.0
Saving model due to mean reward increase: -18.0 -> -17.9
Saving model due to mean reward increase: -17.9 -> -17.6
Saving model due to mean reward increase: -17.6 -> -17.3
Saving model due to mean reward increase: -17.3 -> -17.2
Saving model due to mean reward increase: -17.2 -> -17.1
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1700     |
| mean 100 episode reward | -17.3    |
| steps                   | 1851676  |
--------------------------------------
Saving model due to mean reward increase: -17.1 -> -17.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1800     |
| mean 100 episode reward | -17      |
| steps                   | 2002644  |
--------------------------------------
Saving model due to mean reward increase: -17.0 -> -16.9
Saving model due to mean reward increase: -16.9 -> -16.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1900     |
| mean 100 episode reward | -16.8    |
| steps                   | 2156316  |
--------------------------------------
Saving model due to mean reward increase: -16.8 -> -16.6
Saving model due to mean reward increase: -16.6 -> -16.5
Saving model due to mean reward increase: -16.5 -> -16.3
Saving model due to mean reward increase: -16.3 -> -16.2
Saving model due to mean reward increase: -16.2 -> -16.1
Saving model due to mean reward increase: -16.1 -> -15.8
Saving model due to mean reward increase: -15.8 -> -15.7
Saving model due to mean reward increase: -15.7 -> -15.4
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2000     |
| mean 100 episode reward | -15.7    |
| steps                   | 2334684  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2100     |
| mean 100 episode reward | -16.6    |
| steps                   | 2587858  |
--------------------------------------
Saving model due to mean reward increase: -15.4 -> -15.2
Saving model due to mean reward increase: -15.2 -> -14.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2200     |
| mean 100 episode reward | -14.6    |
| steps                   | 2763092  |
--------------------------------------
Saving model due to mean reward increase: -14.8 -> -14.6
Saving model due to mean reward increase: -14.6 -> -14.4
Saving model due to mean reward increase: -14.4 -> -14.3
Saving model due to mean reward increase: -14.3 -> -14.1
Saving model due to mean reward increase: -14.1 -> -14.0
Saving model due to mean reward increase: -14.0 -> -13.9
Saving model due to mean reward increase: -13.9 -> -13.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2300     |
| mean 100 episode reward | -14.2    |
| steps                   | 2952498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2400     |
| mean 100 episode reward | -14.1    |
| steps                   | 3138689  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2500     |
| mean 100 episode reward | -14.1    |
| steps                   | 3323721  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2600     |
| mean 100 episode reward | -15      |
| steps                   | 3496843  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2700     |
| mean 100 episode reward | -14.1    |
| steps                   | 3676141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2800     |
| mean 100 episode reward | -13.9    |
| steps                   | 3861559  |
--------------------------------------
Saving model due to mean reward increase: -13.7 -> -13.6
Saving model due to mean reward increase: -13.6 -> -13.3
Saving model due to mean reward increase: -13.3 -> -13.2
Saving model due to mean reward increase: -13.2 -> -13.1
Saving model due to mean reward increase: -13.1 -> -13.0
Saving model due to mean reward increase: -13.0 -> -12.8
Saving model due to mean reward increase: -12.8 -> -12.6
Saving model due to mean reward increase: -12.6 -> -12.5
Saving model due to mean reward increase: -12.5 -> -12.3
Saving model due to mean reward increase: -12.3 -> -12.2
Saving model due to mean reward increase: -12.2 -> -11.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2900     |
| mean 100 episode reward | -11.5    |
| steps                   | 4057109  |
--------------------------------------
Saving model due to mean reward increase: -11.8 -> -11.5
Saving model due to mean reward increase: -11.5 -> -11.2
Saving model due to mean reward increase: -11.2 -> -11.0
Saving model due to mean reward increase: -11.0 -> -10.5
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3000     |
| mean 100 episode reward | -13.5    |
| steps                   | 4323579  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3100     |
| mean 100 episode reward | -12.7    |
| steps                   | 4511974  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3200     |
| mean 100 episode reward | -10.4    |
| steps                   | 4713084  |
--------------------------------------
Saving model due to mean reward increase: -10.5 -> -10.0
Saving model due to mean reward increase: -10.0 -> -9.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3300     |
| mean 100 episode reward | -10.9    |
| steps                   | 4907123  |
--------------------------------------
Saving model due to mean reward increase: -9.9 -> -9.8
Saving model due to mean reward increase: -9.8 -> -9.7
Saving model due to mean reward increase: -9.7 -> -9.6
Saving model due to mean reward increase: -9.6 -> -9.5
Saving model due to mean reward increase: -9.5 -> -9.1
Saving model due to mean reward increase: -9.1 -> -9.0
Saving model due to mean reward increase: -9.0 -> -8.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3400     |
| mean 100 episode reward | -9.2     |
| steps                   | 5123035  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3500     |
| mean 100 episode reward | -11.9    |
| steps                   | 5308359  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3600     |
| mean 100 episode reward | -11.2    |
| steps                   | 5499097  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3700     |
| mean 100 episode reward | -11.4    |
| steps                   | 5689484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3800     |
| mean 100 episode reward | -9.9     |
| steps                   | 5891675  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3900     |
| mean 100 episode reward | -11.4    |
| steps                   | 6083400  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4000     |
| mean 100 episode reward | -13.8    |
| steps                   | 6248244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4100     |
| mean 100 episode reward | -11.3    |
| steps                   | 6532256  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4200     |
| mean 100 episode reward | -11.5    |
| steps                   | 6725091  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4300     |
| mean 100 episode reward | -12      |
| steps                   | 6912946  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4400     |
| mean 100 episode reward | -9.9     |
| steps                   | 7116815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4500     |
| mean 100 episode reward | -11.1    |
| steps                   | 7302484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4600     |
| mean 100 episode reward | -9.9     |
| steps                   | 7503661  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4700     |
| mean 100 episode reward | -10.3    |
| steps                   | 7703402  |
--------------------------------------
Saving model due to mean reward increase: -8.9 -> -8.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4800     |
| mean 100 episode reward | -9.3     |
| steps                   | 7893791  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 4900     |
| mean 100 episode reward | -13.2    |
| steps                   | 8160606  |
--------------------------------------
Saving model due to mean reward increase: -8.7 -> -8.6
Saving model due to mean reward increase: -8.6 -> -8.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5000     |
| mean 100 episode reward | -8.1     |
| steps                   | 8373523  |
--------------------------------------
Saving model due to mean reward increase: -8.2 -> -7.8
Saving model due to mean reward increase: -7.8 -> -7.4
Saving model due to mean reward increase: -7.4 -> -7.3
Saving model due to mean reward increase: -7.3 -> -7.2
Saving model due to mean reward increase: -7.2 -> -7.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5100     |
| mean 100 episode reward | -9.4     |
| steps                   | 8564546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5200     |
| mean 100 episode reward | -9       |
| steps                   | 8761224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5300     |
| mean 100 episode reward | -9.4     |
| steps                   | 8943035  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5400     |
| mean 100 episode reward | -8       |
| steps                   | 9147701  |
--------------------------------------
Saving model due to mean reward increase: -7.0 -> -6.9
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5500     |
| mean 100 episode reward | -7.5     |
| steps                   | 9354744  |
--------------------------------------
Saving model due to mean reward increase: -6.9 -> -6.3
Saving model due to mean reward increase: -6.3 -> -6.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5600     |
| mean 100 episode reward | -7.6     |
| steps                   | 9562994  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5700     |
| mean 100 episode reward | -9.4     |
| steps                   | 9738770  |
--------------------------------------
Saving model due to mean reward increase: -6.2 -> -6.0
Saving model due to mean reward increase: -6.0 -> -5.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 5800     |
| mean 100 episode reward | -5.8     |
| steps                   | 9940283  |
--------------------------------------
Saving model due to mean reward increase: -5.7 -> -5.6
Restored model with mean reward: -5.6
